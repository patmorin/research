\documentclass{patmorin}
\usepackage{amsmath,amsthm,graphicx}
\listfiles
\usepackage[mathlines]{lineno}
\linenumbers
\usepackage{pat}

\newtheorem{cor}{Corollary}
\DeclareMathOperator{\range}{range}

\title{Maximum Interference for Transmitters Uniformly Distributed on a Segment}
\author{Evangelos Kranakis, Danny Krizanc, and Pat Morin}

\begin{document}
\maketitle

\begin{abstract}
We consider the following problem: A set of $n$ transmitters are
place independently and uniformly at random on a unit interval.  Each
transmitter, except the two extreme ones, adjust their transmission ranges
so that they can be heard by the further of their left neighbour and right
neighbour.  What is the maximum number of transmitters that can be heard
by any individual transmitter?  We show that, with high probability,
there exists some transmitter that hears $\Omega(\sqrt{\log n})$
transmitters and all transmitters hear $O(\sqrt{\log n})$ transmitters.
\end{abstract}

\section{Introduction}

We consider the following problem: A set of $n$ transmitters are
place independently and uniformly at random on a unit interval.  Each
transmitter, except the two extreme ones, adjust their transmission ranges
so that they can be heard by the further of their left neighbour and right
neighbour.  What is the maximum number of transmitters that can be heard
by any individual transmitter? 

More formally, let $S=\{x_1,\ldots,x_n\}$ be a set of values chosen
indepdently and uniformly at random from the real interval $[0,1]$
and reordered so that $x_1<\cdots<x_n$.  For each
$i\in\{2,\ldots,n-1\}$, define the \emph{broadcast range} 
\[
   R_i = \max\{x_i - x_{i-1}, x_{i+1}-x_i\}
\]
and the \emph{broadcast interval}
\[
   I_i = [x_i-R_i,x_i+R_i] \enspace .
\]
The \emph{interference at $x_i$} is then given by
\[
   Z_i = |\{j\in\{1,\ldots,n\}\setminus\{i\} : x_i \in I_j\}| \enspace .
\]
The \emph{maximum interference} in $S$, is given by
\[
   Z_S=\max\{Z_i:i\in\{1,\ldots,n\}\} \enspace .
\]
We prove the following result:

\begin{thm}
With probability $1-o(1)$, $Z_S\in \Theta(\sqrt{\log n})$.
\end{thm}

This result is an immediate consequence of \lemref{lower-bound} and
\lemref{upper-bound} which are proven in the next section.

\section{The Proof}

In this section we prove our main result, namely that the maximum
interference is $\Theta(\sqrt{\log n})$ with high probability.
Throughout this section, we will make use of the relationship between
uniformly distributed point sets and exponential random variables
\cite[Chapter~V, Theorem~2.2]{d86}.  Suppose $S$ is a set of $n$ points
independently and uniformly distributed in $[0,1]$ whose elements are
$x_1,\ldots,x_n$ in sorted order.  Let $X_0,\ldots,X_n$ be Exponential(1)
random variables, let $x'_i=\sum_{j=0}^{i-1}X_j$, and let $x_i''=x_i/x_n$.
Then $x_1'',\ldots,x_n''$ have the same distribution as $x_1,\ldots,x_n$.

Because of the above relationship we will, throughout this section, use
the convention that $X_0,\ldots,X_n$ are Exponential(1) random variables,
$x_i=\sum_{j=0}^{i-1}X_j$, and $S=\{x_1,\ldots,x_n\}$.  This definition
of $S$, $x_1,\ldots,x_n$, and $X_0,\ldots,X_n$ will be implicit in the
statements of all subsequent results and in all proofs.

\subsection{The Lower Bound}

We prove our lower-bound by by defining a configuration of points that
leads to an element with interference $\Omega(\sqrt{\log n})$ and then
showing that, with high probability, this configuration occurs somewhere
in our point set.

A sequence of numbers $X_0,\ldots,X_k$ forms a \emph{$k$-frame} if
\[
     X_0 \le 1
\]
and
\[
     X_{i-1}/4 \le X_i \le X_{i-1}/2 \enspace ,
\]
for all $i\in\{1,\ldots,k\}$.  Notice that, if $X_0,\ldots,X_k$ form a
$k$-frame, then $x_{k+1}$ is a node that has interference at least $k$.
The next lemma shows that this situation is not too unlikely:

\begin{lem}\lemlabel{frame}
If $X_0,\ldots,X_k$ are a sequence of independent Exponential(1) random
variables, then the probability that $X_0,\ldots,X_k$ form a $k$-frame
is at least $(1-1/e)2^{-(k+1)^2}$.
\end{lem}

\begin{proof}
Recall that an Exponential(1) random variable $X$ has cumulative
distribution function
\[
   \Pr\{X \le x\} = 1-e^{-x} \enspace .
\]
Next, observe that, in a frame,
\[
                 4^{-i} \le X_i \le 2^{-i}  \enspace ,
\]
for all $i\in\{0,\ldots,k\}$.  Let $F(X)$ be the event ``$X$ is a frame.''
Then,
\begin{align*}
     \Pr\{F(X_0,\ldots,X_{i+1}) \mid F(X_0,\ldots,X_{i})\} 
        & = \Pr\{X_{i+1} \in [X_{i}/4,X_{i}/2] \mid F(X_0,\ldots,X_{i})\} \\
        & \ge \Pr\{X_{i+1} \in [4^{-i}/4,4^{-i}/2]\} \\
        & = \Pr\{X_{i+1} \in [2^{-(2i+2)},2^{-(2i+1)}]\} \\
        & = \exp(-2^{-(2i+2)}) - \exp(2^{-(2i+1)}) \\
        & \ge 2^{-(2i+3)} \enspace ,
\end{align*}
where the last inequality holds for all $i\ge 0$.  Therefore,
\begin{align*}
     \Pr\{F(X_0,\ldots,X_{k})\}
   & = \Pr\{X_0\le 1\}
         \cdot\prod_{i=1}^k \Pr\{F(X_0,\ldots,X_{i})
                                 \mid F(X_0,\ldots,X_{i-1})\} \\
   & = (1-1/e)
         \cdot\prod_{i=1}^k \Pr\{F(X_0,\ldots,X_{i})
                                 \mid F(X_0,\ldots,X_{i-1})\} \\
   & \ge (1-1/e)\cdot\prod_{i=1}^k 2^{-(2i+1)} \\
   & = (1-1/e)\cdot2^{-\sum_{i=1}^k(2i+1)} \\
   & = (1-1/e)\cdot2^{-(k^2+2k)} \\
   & \ge (1-1/e)\cdot2^{-(k+1)^2} \\
\end{align*}
as required.
\end{proof}


\begin{lem}[Lower Bound]\lemlabel{lower-bound}
With probability at least $1-\exp(-n^{1-c}/\sqrt{c\log n})$, there exists
an some element of $S$ that has interference at least $\lfloor\sqrt{c\log
n}\rfloor-2$.
\end{lem}

\begin{proof}
Let $k=\lfloor \sqrt{c\log n} \rfloor-1$.  By \lemref{frame},
$X_{jk},\ldots,X_{jk+k}$ have probability at least $2^{-(k+1)^2}\ge
n^{-c}$ of forming a $k$-frame, in which case $x_{jk+k}$ has
interference at least $k$.  Since this is true, independently, for any
$j\in\{0,\ldots,\lfloor n/k\rfloor\}$, the probability that there is no
element of $S$ with with interference greater than $k$ is at most
\[
   (1-n^{-c})^{\lfloor n/k\rfloor} \le \exp(-\lfloor n^{1-c}/k\rfloor) \enspace ,
\]
as required.
\end{proof}


\subsection{The Upper Bound}

We begin our upper-bound proof by studying a variant of interference that
is 1-sided and that considers only interference generated by transmitters
that are nearby.  The \emph{left-interference} of an element $x_t\in
S$ is the number of elements $x_i\in S$ such that $x_i < x_t$ and
$x_t-x_i \le \max\{x_i-x_{i-1},x_{i+1}-x_i\}$.  The \emph{short-range
left-interference} of $x_t$ is defined in the same way, except only
counting those elements $x_i$ such that $X_{i-1} \le 1$. (Note that this
implies $x_t-x_i \le 1$.)

\begin{lem}\lemlabel{squeaker}
The maximum short-range left-interference of any element in $S$ is at
most $\sqrt{c\log n}$ with probability at least $1-n^{-\Omega(c)}$.
\end{lem}

\begin{proof}
Consider an element $x_t$ that has short-range left-interference $k+1$
and suppose that this inteference comes from $x_{i_0},\ldots,x_{i_{k}}$
with $x_{i_{k}} <\cdots<x_{i_0}<x_t$.  This implies that, for all $j\in\{1,\ldots,k\}$,
\[
   X_{i_j-1} > x_t - x_{i_j} \enspace ,
\]
or, equivalently
\[
   X_{i_j-1} > (x_t - x_{i_j-1})/2 
\]
(see \figref{upper-bound}).  There are other requirements on the values
of $X_{i_k},\ldots,X_{i_0}$, but the above condition is enough to prove
our upper-bound.

\begin{figure}
  \begin{center}\includegraphics{upper-bound}\end{center}  
  \caption{$x_t\in R_{i_j}$ implies $X_{i_j-1} > (x_t - x_{i_j-1})/2$.}
  \figlabel{upper-bound}
\end{figure}

Consider the following process: Start with a \emph{length} $\ell_0 \le 1$
and generate i.i.d.\ Exponential(1) random variables $X_1,\ldots,X_i$
until $\sum_{j=1}^i {X_j} \ge \ell_0/2$. If $\sum_{j=1}^i {X_j} \ge
\ell_0$ then the process stops.  Otherwise, the process begins another
round with a new input length $\ell_1=\ell_0-\sum_{j=1}^i {X_j}$, and
the process continues in this manner until the stopping condition is met.

Observe that, in this process, the length $\ell_i$ during the $i$th
round (starting at round 0) satisfies $\ell_i\le (1/2)^i$.  Therefore,
the probability of continuing onto round $i+1$ from round $i$ is at most
\[
   \Pr\{X_1 \le 2^{-i}\} = 1-e^{-1/2^i} \le 2^{-i} \enspace .
\]
Therefore, the probability that this process continues beyond round $k$
is at most
\[
    \prod_{i=0}^{k} 2^{-i} = 2^{-\sum_{i=0}^{k} i} = 2^{-k(k+1)/2}
\enspace .
\]
The relationship between the above process and interference is the
following:  Suppose that some element $x_t\in S$ has interference $k$
and $x_i$ contributes to the left-interference of $x_t$ and $X_{i-1}\le
1$.  Then, we let $\ell_0=X_{i-1}$ and observe that the elements
$x_{i_1}=x_i,\ldots,x_{i_k}$ that contribute the left-interference of
$x_t$ correspond to elements that terminate a round in the above process,
with the next-to-last round being terminated by $x_t$ itself.

By setting $k=\sqrt{c\log n}$, we find that the probability that $X_{1}$
starts a process leading to an $x_t$ whose short-range left-interference is
greater than $k$ is at most $n^{-\Omega(c)}$.  Therefore, the probability that
there exists \emph{any} $X_i$ that starts a process leading an $x_t$ with
short-range left-interference greater than $k$ is at most
$n^{1-\Omega(c)}=n^{-\Omega(c)}$, completing the proof.
\end{proof}


Finally, we have all the pieces needed to complete the upper bound

\begin{lem}[Upper Bound]\lemlabel{upper-bound}
With probability at least $1-n^{-\Omega(c)}$, the maximum interference of
any element in $S$ is at most $\sqrt{c\log n}$.
\end{lem}

\begin{proof}
We consider only left-interference, since the right-interference
can be bounded in a symmetric way.  Consider some element $x_t$.  The
left-interference of $x_t$ is generated by some elements
$x_{i_0},\ldots,x_{i_k}$ where $x_{i_k}<\cdots<
x_{i_0}<x_t$.  \lemref{squeaker} already bounds the number of elements of this
sequence where $X_{i_j-1} \le 1$.  Thus, all that remains is to bound
the number of elements $x_{i_j}$ where $X_{i_j} > 1$.

Observe again that, for any $j\in\{1,\ldots,k\}$, in order for $x_{i_j}$
to interfere with $x_t$ we must have
\[
   X_{i_j-1} \ge x_t - x_{i_j} 
\enspace ,
\]
which implies that $X_{i_j} \ge 2 X_{i_{j-1}}$ for all
$j\in\{1,\ldots,k\}$.  Therefore, if we have $2^r$ elements with
$X_{i_j}>1$, then we have some element $X_{i_k-1} > 2^r$.  The probability
that a particular $X_i$ is greater than $2^r$ is $e^{-2^r}$. Therefore,
the probability that there exists any $X_i$ greater than $2^r$ is at most
$ne^{-2^r}$.  Setting $r=d\log\ln n$ for a sufficiently large constant
$d$ makes this probability at most $n^{-d}$, and completes the proof.
\end{proof}

\bibliographystyle{plain}
\bibliography{interference}



\end{document}

