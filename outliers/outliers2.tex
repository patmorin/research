\documentclass[lotsofwhite]{patmorin}
\usepackage{graphicx,amsthm,amsfonts}

\usepackage[noend]{algorithmic}

\input{pat}


\title{
\MakeUppercase{Removing Outliers}%
\thanks{School of Computer Science. Carleton University. This work was partly funded by NSERC.}}

\author{Carleton Open Problems Group}

\date{}

\newcommand{\ch}{\mathrm{CH}}
\newcommand{\lbl}{\mathrm{label}}
\newcommand{\lft}{\mathrm{left}}
\newcommand{\rt}{\mathrm{root}}
\newcommand{\RETURN}[1]{\STATE{\textbf{return} #1}}

\newcommand{\ntypes}{C(2c)}
\newcommand{\timepertype}{(3c)^c n}
\newcommand{\runtime}{n\left({4c\choose 2c}(3c)^c + \log n\right)}
\newcommand{\Oruntime}{O\left(\runtime\right)}

\begin{document}

\maketitle

\begin{abstract}
We consider the problem of removing $c$ points from a set $S$ of $n$
points so that the remaining point set is optimal in some sense.
Definitions of optimality we consider include having minimum diameter,
having minimum area (perimeter) bounding box, having minimum area
(perimeter) convex hull.  For constant values of $c$, all our
algorithms run in $O(n\log n)$ time.
\end{abstract}

\newpage
\tableofcontents
\newpage

\section{Introduction}

Motivated by the problem of removing outliers in a data set, this
paper considers the following problem: Let $S$ be a set of $n$ points
in $\mathbb{R}^2$ and let $f:2^{\mathbb{R}^2}\mapsto \mathbb{R}$ be a
function mapping point sets onto real values.  We consider the problem
of selecting a subset $S'\subseteq S$, $|S'|=c$ such that
$f(S\setminus S')$ is minimum.  The objective functions $f$ that we
consider are:
\begin{enumerate}
\item $f(X)$ is the diameter of $X$,
\item $f(X)$ is the area/perimeter of the smallest axes-parallel
rectangle containing $X$, and
\item $f(X)$ is the area/perimeter of the convex hull of $X$.
\end{enumerate}  

We call these problems the \emph{$f$-based outlier removal problems}.
We are particularly interested in the case when $c$ (the number of
outliers) is small.

\subsection{Previous Work.} 

The outlier removal problems stated above and similar problems are
fairly well-studied problems in computational geometry.  However, most
work thus far has focused on the case when $c$ is large. More
specifically, most research has been on the problem of finding a $k$
point subset (a $k$-cluster) $X\subseteq S$, $|X|=k$, such that $f(X)$
is minimum. These are the same problems studied in the current paper
with $k=n-c$ except that our focus is on large values of $k$ (small
$c$) and most existing research focuses on designing efficient
algorithms for small values of $k$.

\paragraph{Minimum Diameter.} The problem of finding a subset of $S$ of size
$k$ with minimum diameter has been studied by Aggarwal \etal\
\cite{aiks89} who give an $O(k^{2.5}n\log k+n\log n)$ time algorithm.

\paragraph{Minimum Perimeter Enclosing Rectangle.} The same authors
\cite{aiks89} give an $O(k^2n\log n)$ time algorithm to find the
subset of $S$ with the minimum perimeter enclosing axes-parallel
rectangle.

\paragraph{Minimum Perimeter Convex Hull.} The problem of finding a
subset of $S$ of size $k$ that has the least perimeter convex hull was
first considered over 20 years ago by Dobkin \etal\ \cite{ddg83} who
gave an $O(k^2n\log n + k^5 n)$ time algorithm.  This algorithm can be
improved to run in $O(k^2 n\log n + k^4 n)$ time using techniques of
Aggarwal \etal\ \cite{aiks89}.  

All the algorithms mentioned above are based on the fact that the $k$
points that define the solution are a subset of the $k'$ points that
define some cell in the order-$k'$ \voronoi\ diagram \cite{obsXX},
where $k'=\ceil{\pi (k-1)}$.  This allows the problem to be solved,
once the order-$k$ \voronoi\ diagram is computed, by considering
$O(k'n)=O(kn)$ subproblems each of size $k'=O(k)$.

\paragraph{Minimum-Area Convex Hull.}  The problem of finding a subset
of $S$ of size $k$ that has the minimum area convex hull was
considered by Eppstein \etal\ \cite{eorw92} and later by Eppstein
\cite{e93} who give $O(kn^{3})$ and $O((k^3+\log n) n^2)$ time
algorithms for this problem, respectively.  The second algorithm (by
Eppstein) uses the first algorithm along with the fact that the $k$
points that define the solution are among the $2k-4$ vertical nearest
neighbours of one of the $n\choose 2$ line segments determined by
pairs of points in $S$.  This allows the problem to be solved by
considering $O(n^2)$ subproblems each of size $O(k)$.

\comment{
Note that finding a subset $X\subseteq S$ of size $k$ whose convex hull
has minimum area generalizes the problem of determining if $S$
contains $k$ collinear points (in which case $S$ has a subset of size
$k$ whose convex hull has area 0).  For the case $k=3$, this problem is
one of the original \textsc{3-Sum}-hard problems \cite{go95} and is
conjectured to have an $\Omega(n^2)$ lower-bound in many models of
computation. However, for large values of $k$, the problem seems to
become easier, and Guibas \etal\ \cite{gor96} have an algorithm that
reports all lines containing at least $k$ points of $S$ in
$O((n^2/k)\log(n/k))$ time.  Notice that, for $k=\Omega(n)$, this
gives an $O(n)$ time algorithm, which offers hope that outlier removal
problems should have fast solutions for sufficiently small values of
$c$.
}

\paragraph{New Results.}

For fixed values of $k$, the results described above give $O(n\log n)$
or $O(n^2\log n)$ time algorithms for finding the $k$ point subset of
$S$ that minimize $f$.  However, when $k$ is close to $n$ the above
algorithms require $\Omega(n^3)$ time.  

In the current paper we consider specifically the case when $k=n-c$.
For Problem~1 we obtain an $O(n\log n + cn + c^7)$ time algorithm.
For problem~2 we obtain an $O(n + c^3)$ time algorithm.  For Problem~3
we obtain an $\Oruntime$ algorithm.  We show, by giving $\Omega(n\log
n)$ lower bounds for both Problems~1 and 3 that, for fixed values of
$c$, our algorithms are essentially optimal.



The remainder of the paper is organized as follows:
\secref{preliminaries} presents definitions, notation, and previous
results that are used in subsequent sections. \secref{algorithm}
describes the outlier removal algorithm. \secref{conclusions}
concludes and suggests directions for future research.


\section{Minimizing Diameter}

In this section we consider the problem of finding a subset
$S'\subseteq S$, $|S'|=c$ such that the diameter of $S\setminus S'$ is
minimum over all choices of $S'$.  We begin by showing that this
problem has an $\Omega(n\log n)$ lower bound even for the case $c=1$.

\subsection{The Lower Bound}

\begin{thm}
In the algebraic decision tree model of computation, the problem of
determining a single point $x\in S$ such that the diameter of
$S\setminus\{x\}$ is minimized has an $\Omega(n\log n)$ lower bound.
\end{thm}

\begin{proof}
Computing the diameter of a set $S$ of $n$ points in $\mathbb{R}^2$ has 
an $\Omega(n\log n)$ lower bound in the algebraic decision tree model.  
We simply
observe that the point $x$ that defines the optimal solution is one of
the two points that define the diameter of $S$. Thus, given $x$ we can
compute the diameter of $S$ in $O(n)$ time by computing the distance
from $x$ to every other point of $S$.  It must therefore take
$\Omega(n\log n)$ time to determine $x$. 
\end{proof}

\subsection{The Algorithm}

We first consider a more general problem in $\mathbb{R}^{n \times n}$ and then use the derived algorithm to find a set $\tilde{S}$ of $c^2$ points with the property that the $c$ points that can be removed to optimize the function $f$ form a subset of $\tilde{S}$.

Let $A$ denote a symmetric matrix of real numbers in $\mathbb{R}^{n \times n}$, let $R_i$ denote the $i$-th row of $A$, let $C_i$ denote the $i$-th column of $A$, and let $a_{i,j}$ denote the element in $R_i$ and in $C_j$. We consider the problem of selecting a set $T$ of $c$ indices, such that removing $R_t$ and $C_t$ for every $t \in T$ from $A$ yields a modified matrix $A'$ with the property that the maximum entry of $A'$ is minimized. The following algorithm selects a set $\tilde{T}$ of $(c+1)^2$ indices. We will later prove that $\tilde{T}$ is a superset of $T$. 

The algorithm $\textsc{DeepSet}(A,c)$ selects a set $\tilde{T}$ of $(c+1)^2$ indices. Marking an index $i$ means adding $i$ to $\tilde{T}$ and deleting an index $i$ means removing $R_i$ and $C_i$ from $A$. Algorithm $\textsc{DeepSet}(A,c)$ finds the maximum entry $a_{i,j}$ of $A$ and marks indices $i$ and $j$. Next, the $c+1$ largest entries in $R_i$ and $C_j$ are found and marked. Finally, $i$ and $j$ are deleted. The algorithm repeats these steps $c+1$ times. Algorithm $\textsc{DeepSet}(A,c)$ is given in pseudo code below.

\begin{minipage}{5.5in}
\noindent$\textsc{DeepSet}(A,c)$
\begin{algorithmic}[1]
\FOR{$g=1$ to $c+1$}
  \STATE{$a_{i,j}\gets$ maximum entry of $A$}
  \STATE{$\tilde{T}\gets \tilde{T} \cup \{i\}$}
  \STATE{$\tilde{T}\gets \tilde{T} \cup \{j\}$}
  \FOR{$h=1$ to $c+1$}
    \STATE{$a_{i,k}\gets$ $h$-th largest entry in $R_i$}
    \STATE{$\tilde{T}\gets \tilde{T} \cup \{k\}$}
    \STATE{$a_{k,j}\gets$ $h$-th largest entry in $C_j$}
    \STATE{$\tilde{T}\gets \tilde{T} \cup \{k\}$}
  \ENDFOR
  \STATE{$A\gets A \setminus R_i$}
  \STATE{$A\gets A \setminus C_i$}
  \STATE{$A\gets A \setminus R_j$}
  \STATE{$A\gets A \setminus C_j$}
\ENDFOR
\RETURN{$\tilde{T}$}
\end{algorithmic}
\end{minipage}

\begin{thm}
Algorithm $\textsc{DeepSet}$ returns a superset of some $T$.
\label{diameter_thm}
\end{thm}

\begin{proof}
We first impose an order on the elements of $T$, such that the maximum element of $A \setminus (R_{t_1} \cup R_{t_2} \cup \ldots \cup R_{t_{i-1}} \cup C_{t_1} \cup C_{t_2} \cup \ldots \cup C_{t_{i-1}})$ is in $R_{t_i}$ and symmetrically in $C_{t_i}$ of $A$. This ordering can always be achieved, since the optimal solution must remove the maximum element in each step. Let $T_i = \{t_1,t_2,\ldots,t_i\}$. Furthermore, let $\tilde{T}_i$ denote the set of indices contained in $\tilde{T}$ after the execution of the $i$-th outermost for-loop in the algorithm $\textsc{DeepSet}$.

We prove the theorem by induction on $i$. Let $a_{k,l}$ be the maximum element of $A$. The set $\tilde{T}_1 \supseteq T_1$, since $\{k, l\} \in \tilde{T}_1$ and since either $\{k\} \in T_1$ or $\{l\} \in T_1$ to ensure the removal of $a_{k,l}$.

For the inductive step, we show that $\tilde{T}_i \supseteq T_i$ if $\tilde{T}_{i-1} \supseteq T_{i-1}$.
Let $a_{k,l}$ be the maximum element of $A \setminus (R_{t_1} \cup R_{t_2} \cup \ldots \cup R_{t_{i-1}} \cup C_{t_1} \cup C_{t_2} \cup \ldots \cup C_{t_{i-1}})$. Three cases are possible. 
\begin{enumerate}
\item $k \not \in \tilde{T}_{i-1}$ and $l \not \in \tilde{T}_{i-1}$. Hence, $a_{k,l}$ is an element of $A \setminus \{R_j \cup C_j : \forall j \in \tilde{T}_{i-1}\}$. Since $\tilde{T}_{i-1} \supseteq T_{i-1}$, $a_{k,l}$ is the maximum element during the $i$-th loop of algorithm $\textsc{DeepSet}$. Hence, both $k$ and $l$ are marked and deleted in the $i$-th loop, i.e. $\{k, l\} \in \tilde{T}_i$. Since only either $k$ or $l$ are added to $T_{i-1}$ to form $T_i$, $\tilde{T}_i \supseteq T_i$. 
\item $k \in \tilde{T}_{i-1}$ and $l \in \tilde{T}_{i-1}$. Since only either $k$ or $l$ are added to $T_{i-1}$ to form $T_i$, $\tilde{T}_i \supseteq T_i$. 
\item Without loss of generality $k \in \tilde{T}_{i-1}$ and $l \not \in \tilde{T}_{i-1}$. Two cases are possible.
\begin{enumerate}
\item $R_k$ and $C_k$ got marked and deleted from $A$ during the execution of the algorithm $\textsc{DeepSet}$. Hence, the $c+1$ largest entries in $R_k$, or equivalently in $C_k$, were marked and added to $\tilde{T}$. Hence, $\tilde{T}_{i-1}$ contains every element in row $R_k$ that could ever become the maximum element of $A$ during the removal of $c$ rows and symmetric columns. Therefore, $l \in \tilde{T}_{i-1}$, which contradicts the initial assumption of case 3.
\item The index $k$ got only marked, but not deleted during the execution of the innermost for-loop of algorithm $\textsc{DeepSet}$ and neither $R_k$ nor $C_k$ got deleted from $A$. Therefore, $a_{k,l}$ is the maximum element of $A \setminus (R_j \cup C_j) \forall j \in \tilde{T}_{i-1}$. With the same argument used case 1 we can therefore conclude that $\tilde{T}_i \supseteq T_i$. 
\end{enumerate}
\end{enumerate}
\end{proof} 

We can use the algorithm $\textsc{DeepSet}$ to find a superset of the $c$ outliers we wish to remove to minimize the diameter of the point set. For each of the $n$ elements of the point set $S$, we symmetrically create a column and a row in an $n\times n$ matrix $A$. Each matrix entry describes the distance between the two points associated with the column and row of the entry. Note that $A$ is a symmetric matrix of positive real numbers with zero values along the diagonal. Therefore, we can run algorithm $\textsc{DeepSet}$ on $A$ to obtain a superset of the indices of points that need to be removed to minimize the diameter of $S$.

\begin{thm}
In $O(n\log n + cn + c^7 \log c)$ time, we can find a set $S' \subset S$ of cardinality $c$, such that the diameter of $S\setminus S'$ is minimum.
\end{thm}

\begin{proof}
First, we transform the point set $S$ into a matrix $A$ as outlined above. To execute algorithm $\textsc{DeepSet}$, we find the diameter of the point set in time $O(n\log n)$. Note that the diameter of $S$ corresponds to the maximum entry of $A$. To find the diameter, we first compute the convex hull of $S$ using the dynamic convex hull algorithm \cite{bj02}. This algorithm allows the computation of the convex hull of $S$ in $O(n \log n)$ time and updates to the convex hull are supported in $O(\log n)$ amortized time. Once the convex hull of $S$ is known, the rotating calipers algorithm proposed by Shamos \cite{s78} allows to find the diameter of $S$ in $O(n)$ time. Denote the two points forming the diameter of $S$ by $p$ and $q$. We mark $p$ and $q$. Next, we mark the $c+1$ furthest points from $p$ (respectively $q$) in $S$. Let $r$ denote the $c+1$st furthest point from $p$ (respectively $q$). In $O(n)$ time, we find $r$ and all of the points in $S$ with larger distance to $p$ (respectively $q$) than $r$. Note that this corresponds to lines $\textsc{5}$ to $\textsc{9}$ in the algorithm $\textsc{DeepSet}$. Finally, $p$ and $q$ are deleted from $S$ and the convex hull is updated in $O\log n)$ amortized time \cite{bj02}.

We repeat finding the diameter of the point set, marking $O(c)$ points, deleting the points forming the diameter from $S$, and updating the convex hull of $S$ for $c+1$ steps to execute algorithm $\textsc{DeepSet}$. Computing and maintaining the convex hull of $S$ throughout the algorithm takes $O(n\log n +c\log n) = O(n\log n)$ time, finding the $c+1$ diameters of the updated point set $S$ takes $O(cn)$ time, and updating the point set $\tilde{T}$ takes $O(c n)$ time. Hence, the total time requirement of algorithm $\textsc{DeepSet}$ is $O(n\log n + cn)$.

Once algorithm $\textsc{DeepSet}$ was executed, we know a superset of the outlier set of size $O(c^2)$, see Theorem \ref{diameter_thm}. It remains to find the $c$ outliers in the set $\tilde{T}$ of $O(c^2)$ outliers. To solve this problem, we use the existing algorithm by Aggarwal \etal\ \cite{aiks89} that finds a subset of size $k$ of a set of $n$ points that has minimum diameter. The algorithm by Aggarwal \etal\ takes $O(k^{2.5}n \log k + n\log n)$ time. We wish to find a point set of size $(c+1)^2-c = O(c^2)$ that has minimum diameter. Hence, $n=k=O(c^2)$. Therefore, the algorithm by Aggarwal \etal\ can be used to find the $c$ outliers in $\tilde{T}$ in time $O(c^7 \log c + c^2 \log c)$.

This yields the total time $O(n\log n + cn + c^7 \log c)$ to find the set $S'$.
\end{proof}

\section{Minimizing the Enclosing Rectangle}
\seclabel{minimizing-rectangle}
In this section we propose a fairly simple algorithm for the following
problem:  given a set $S$ of $n$-points in the plane, find an
axes-parallel rectangle $R$ of minimum perimeter that has exactly
$c$-points of $S$ in its exterior, where $1\le c \le n$.  Our
algorithm first computes a set of $O(c)$ candidate points and then
uses the algorithm of \cite{aiks89} to compute the desired rectangle.
The main steps of our algorithm are as follows:

\begin{minipage}{5.5in}
\noindent$\textsc{FindOptimalRectangle}(S)$
\begin{algorithmic}[1]
\STATE{Find a subset $K\subseteq S$ consisting of 
$c$ leftmost, $c$ rightmost, $c$ topmost and $c$ bottommost points in
$S$.}
\STATE{Computing the smallest axes-parallel bounding box $B$ for points in $S\setminus K$, 
and then delete all these points.}
\STATE{Insert $c$ points at the bottom-left corner of $B$.  Also
insert $c$-points at the top-right corner of $B$.  Let the set of
newly inserted points be $I$.}
\STATE{Compute the minimum perimeter axes-parallel rectangle $R$ that 
encloses exactly $c+|K|$ points out of $2c+|K|$ points in the set $K\cup I$
using the algorithm in
\cite{aiks89}.}
\end{algorithmic}
\end{minipage}

\begin{obs}\label{bounding-box-obs}
 The bounding box $B$ is in the interior of the rectangle $R$ reported
 by $\textsc{FindOptimalRectangle}$.
\end{obs}
\begin{proof}
Proof by contradiction. 
Assume that the box $B$ is not completely in
the interior of $R$. Then at least one of the points in the set $I$ is in the
exterior of $R$. Let $p$ be one such point. Imagine the coordinate
system with its origin at $p$.
Notice that  $R$ does not overlap with at least one of the following four
halfspaces: (1) $y\ge 0$ (2) $x\ge 0$ (3) $y\le 0$  (4) $x\le 0$.  
Each of these half spaces contains more than c points (including p).
Hence there are more than $c$ points in the exterior of $R$, a contradiction.
\end{proof}

\begin{thm}
The minimum perimeter axes-parallel rectangle of a set of $n$ points
in the plane that leaves $c$ points in its exterior can be computed in
$O(n+c^3\log c)$ time.
\end{thm}
\begin{proof}
Correctness follows from the above observation. As for the complexity
analysis, Steps 1--3 take $O(n)$ time. Since $|K|\le 4c$, Step 4
requires $O(c^3\log c)$ time \cite{aiks89}. Hence the overall
time complexity of our algorithm is $O(n+c^3\log c)$.
\end{proof}

\noindent Remark: 
Observation \ref{bounding-box-obs} holds if we change the problem to
computing minimum area rectangle instead of minimum perimeter
rectangle.  Moreover, the {\sf Procedure Rectangle} in \cite{aiks89},
also works for area, as, we make observation that, it computes all possible
``anchored'' rectangles containing fixed number of points in its
interior.

The complexity of the perimeter problem can be further improved to
$O(n+c^3)$ time using the results of Datta, Lenhof, Schwarz, and Smid,
``Static and dynamic algorithms for k-point clustering problems'',
Journal of Algorithms, 19:474--503, 1995.

Prof. Michiel  might shed light on whether it works for area or not? 

 


\section{Minimizing the Convex Hull}


\subsection{The Lower Bound}


\begin{thm}
In the algebraic decision tree model of computation, the problem of
determining a single point $x\in S$ such that the area or perimeter of
$\ch(S\setminus\{x\})$ is minimized has an $\Omega(n\log n)$ lower
bound.
\end{thm}

\begin{proof}
The proof is by a reduction from the problem \textsc{Set-Equality}, of
determining whether two sets $A$ and $B$ of real numbers are equal,
which has an $\Omega(n\log n)$ lower bound in the algebraic decision
tree model.
The \textsc{Set-Equality} problem can be mapped to an outlier removal
problem on the point multiset $S=S_A \uplus S_B$ where $S_A=\{(x,x^2):
x\in A\}$, $S_B=\{(x,x^2):x\in B\}$ and $\uplus$ denotes multiset
union. The sets $A$ and $B$ are equal if and only if for every $p\in
S$, $\ch(S)=\ch(S\setminus\{p\})$.
\end{proof}

\subsection{The Algorithm}
\seclabel{algorithm}

\subsubsection{Preliminaries} 
\seclabel{preliminaries}

The \emph{convex layers} $S_0,\ldots,S_k$ of $S$ are defined as
follows: $S_0$ is the subset of $S$ on the boundary of $\ch(S)$.
$S_i$, for $i\ge 1$ is the subset of $S$ on the boundary of
$\ch(S\setminus\bigcup_{j=0}^{i-1} S_j)$.  The convex layers of $S$
can be computed in $O(n\log n)$ time \cite{c85,hs92} or, more simply,
the first $c$ convex layers can be computed in $O(cn\log n)$ time by
repeated applications of any $O(n\log n)$ time convex hull algorithm.
For the remainder of this paper we will use the notation $p_{i,j}$ to
denote the $(j\bmod |S_i|)$th point of $S_i$, and use the convention
that $p_{i,0},\ldots,p_{i,|S_i|-1}$ occur in counterclockwise order on
the boundary of $\ch(S_i)$.

Once the convex layers $S_0,\ldots,S_c$ have been computed, we can
find, in $O(c^2 n)$ time, for each point $p_{i,j}$ on layer $i$ and
for each layer $i'> i$ and $i'\le c$ the two points $p_{i',k}$ and
$p_{i',\ell}$ such that the line through $p_{i,j}$ and $p_{i',k}$
(respectively $p_{i,j}$ and $p_{i',\ell}$) is tangent to $S_{i'}$.
This is accomplished by a simple walk around $S_i$, updating tangents
$p_{i',k}$ and $p_{i',\ell}$ as we proceed.

Consider a point $p_{0,j}\in S_0$ and refer to \figref{point-removal}.
If we remove $p_{0,j}$ from $S$ then a (possibly empty) sequence
$p_{1,k},\ldots,p_{1,\ell}$ of $S_1$ appears on the boundary of
$\ch(S\setminus\{p_{0,j}\})$.  When this happens we say that
$p_{1,k},\ldots,p_{1,\ell}$ is \emph{exposed}.  This exposed sequence
can be obtained from the preprocessing described above by using two
tangents $p_{1,k}$ and $p_{1,\ell}$ joining $p_{0,j-1}$ and
$p_{0,j+1}$ to $S_1$.  Finding the two tangent points takes $O(1)$
time and traversing the sequence takes $O(t_j)$ time, where
$t_j=\ell-k+1$.

\begin{figure}
\begin{center}\includegraphics{point-removal}\end{center}
\caption{Removing a point $p_{0,j}$ from $S_0$ exposes a chain
$p_{1,\ell},\ldots,p_{1,k}$ of $S_1$.}
\figlabel{point-removal}
\end{figure}

Once we have removed a point $p_{0,j}$ from $S_0$, if we know the area
(or perimeter) of $\ch(S)$ we can compute the area (or perimeter) of
$\ch(S\setminus\{p_{0,j}\})$ in $O(t_j)$ time.  We do this by
computing the area of the triangle $\triangle
p_{0,j-1}p_{0,j}p_{0,j+1}$ and subtracting from it the area of
$\ch(\{p_{0,j-1},p_{0,j+1}\}\cup\{p_{1,k},\ldots,p_{1,\ell}\})$.  This
gives us the difference in area (perimeter) between $\ch(S)$ and
$\ch(S\setminus\{p_{0,j}\})$.

In this section we present our algorithm for solving the
perimeter-based and area-based outlier removal problems. Our solution
to both problems is to enumerate all the combinatorial types of
solutions of size $c$.  For each such solution type, we then use a
combination of divide-and-conquer and dynamic programming to find the
optimal solution of that particular solution type.  Before we present
the general algorithm, it will be helpful to discuss the special cases
$c=1$ and $c=2$ to illustrate the principles involved.

\subsubsection{Removing 1 Outlier}

The case $c=1$ asks us to remove 1 point of $S$ so that the convex
hull of the resulting set is minimum.  This can be solved as follows:
We first compute the two convex layers $S_0$ and $S_1$ in $O(n\log n)$
time and preprocess them for the tangent queries described in the
previous section.  We then determine, for each point $p_{0,j}\in S_0$
the difference in area between $\ch(S)$ and
$\ch(S\setminus\{p_{0,j}\})$ using the method described in the
previous section.  This process takes $O(1+t_j)$ time, where $t_j$ is
the number of vertices of $S_1$ exposed by the removal of $p_{0,j}$.
We output the point $p_{0,j}$ that gives the largest difference in
area.

To analyze the overall running time of this algorithm we observe that
any particular point $p_{1,k}\in S_1$ appears in at most two triangles
$\triangle p_{0,j-1},p_{0,j},p_{0,j+1}$ and
$\triangle p_{0,j},p_{0,j+1},p_{0,j+2}$.  Stated another way,
\[
     \sum_{j=0}^{|S_0|-1} t_j \le 2|S_1|\le 2n \enspace .
\]
Thus, the overall running time of this algorithm is
\[
     T(n) = O(n\log n)+\sum_{j=0}^{|S_0|-1} O(1+t_j) = O(n\log n) \enspace ,
\]
as claimed.

\subsubsection{Removing 2 Outliers}

Next we consider the case $c=2$.  In this case, the optimal solution
$S'$ has one of three following forms:

\begin{enumerate}

\item $S'$ contains two consecutive points $p_{0,j}$ and $p_{0,j+1}$
of $S_0$.

\item $S'$ contains two non-consecutive points $p_{0,j_1}$ and
$p_{0,j_2}$ of $S_0$ (with $j_2\not\in\{j_1+1,j_1-1\}$).

\item $S'$ contains one point $p_{0,j}$ of $S_0$ and one point
$p_{1,j'}$ of $S_1$.

\end{enumerate}

The solutions of Type~1 can be found in much the same way as the
algorithm for the case $c=1$.  For each $j\in\{0,\ldots,|S_0|-1\}$ we
compute the difference in area between $\ch(S)$ and
$\ch(S\setminus\{p_{0,j},p_{0,j+1}\})$.  The analysis remains exactly
the same as before except that, now, each point of $S_1$ can appear in
at most $3$ area computatons, instead of only 2.  Thus, all solutions
of Type~1 can be evaluated in $O(n\log n)$ time.

The solutions of Type~3 can also be found in a similar manner.  For
each point $p_{0,j}\in S_0$ we remove $p_{0,j}$ to expose a sequence
$p_{1,k},\ldots,p_{1,\ell}$ of $S_1$ and compute the area of
$\ch(S\setminus\{p_{0,j}\})$.  We then remove each of
$p_{1,k},\ldots,p_{1,\ell}$ in turn (exposing a chain of points from
$S_2$) and compute the area of the resulting convex hull.  To analyze
the cost of all these, we observe that each point $p_{1,j}\in S_1$
appears in at most 2 subproblems because there are at most 2 points in
$S_0$ whose removal causes $p_{1,j}$ to appear on the convex hull.
Similarly, for each point $p_{2,j}\in S_2$ there are at most 2 points
of $S_1$ whose removal causes $p_{2,j}$ to appear on the convex hull.
Thus, each point in $S_1$ appears in at most 2 subproblems and each
point in $S_2$ appears in at most $4$ area computations.  The overall
running time of this algorithm is therefore bounded by
\[
    O\left(n\log n + |S_0| + 2|S_1| + 4|S_2|\right) = O(n\log n) \enspace ,
\]
as required.

Finally, we consider solutions of Type~2.  To find these we compute,
for each $p_{0,j}\in S_0$ the difference $x_j$ between the area of
$\ch(S\setminus\{p_{0,j}\})$ and $\ch(S)$ using the technique
described for the case $c=1$.  In this way, we reduce the problem to
that of finding two indices $0\le j_1,j_2< |S_0|$ with $j_2\ge j_1+2$
such that $x_{j_1}+x_{j_2}$ is maximum.  We do this by computing the
following quantity
\[
     D_j = \max\{x_{j_1}+x_{j_2} :
       \mbox{$0\le j_1,j_2\le j$ and $j_2 \ge j_1+2$}\} \enspace ,
\]
that can be computed in $O(|S_0|)$ time using the recurrence
\[
    D_j = \max\{D_{j-1}, x_{j} + \max\{x_{0},\ldots,x_{j-2}\}\}
                \enspace .
\]

Since the best solution of each of the three types can be found in
$O(n\log n)$ time we can find the overall best solution in $O(n\log
n)$ time by keeping the best of the three.

\subsubsection{Removing $\mathbf{c}$ Outliers}

The solution for the case $c=2$ illustrates all of the ideas used in 
our algorithm.  We begin by enumerating the combinatorial types of
solutions and then compute the best solution of each type.  The
algorithm for computing the best solution of each type is a
divide-and-conquer algorithm whose merge step is accomplished by
solving a dynamic programming problem (as in the Type~2 solutions
described above).

For ease of exposition (to avoid treating $S_0$ as a special case), we
describe an algorithm to find the optimal solution with the
restriction that it does not include both $p_{0,-1}$ and $p_{0,0}$.
To find the true optimal solution we can run this algorithm at most
$c$ times, shifting the numerical labelling of the points on $S_0$ by
one each time.

\subsubsection{The Types of Solutions}

We represent the type of a solution as a rooted ordered binary tree in
which each node is labeled with a positive integer and the sum of all
node labels is $c$.  We call such trees \emph{solution trees}.  The
following lemma tells us that, for small values of $c$, there are not
too many solution trees:
 
\begin{lem}\lemlabel{catalan}
The number of solution trees is at most $O(C(2c))$, where
$C(r)={2r\choose r}/(r+1)$ is the $r$th Catalan number.
\end{lem}

\begin{proof} Given a solution tree $T$, we convert it to an
unlabelled rooted binary tree as follows: First, for each node $N$ of
$T$ whose label is $\ell$, we color $N$ black, leave $N$'s left child
unchanged and replace $N$'s right child with a (right) path of
$\ell-1$ \emph{white} nodes, the last node of which has $N$'s original
right child as its right child.  Note that this gives us a binary
tree with exactly $c$ nodes in which no white node has a left child.
Next, for each black node we add a leaf, if necessary, to guarantee
that each black node has a left child.  This gives us an unlabelled
rooted ordered binary tree $T'$ with at most $2c$ nodes.

Observe that, given only $T'$, we can recover $T$ and its labels since
we can recognize white nodes by the fact that they have no left child.
Thus, the number of solution trees is at most equal to the number of
unlabelled rooted ordered binary trees with at most $2c$ nodes.  The
number of such trees is 
\[
  \sum_{i=1}^{2c} C(i) = O(C(2c))
\]
\cite{knuth-graham-patashnik},
as required.
\end{proof}

Solution trees are interpreted as follows (refer to
\figref{solution-tree} for an example): Any solution removes some
elements of $S_0$ and the elements removed come in $d$ groups
$G_0^1,\ldots,G_0^d$ of consecutive elements with each group separated
by at least one element of $S_0$.  The sizes of these groups are given
by the labels of the nodes on the rightmost path in $T$, in the order
in which they occur.  That is, the $j$th node, $N_0^j$ on the
rightmost path of $T$ has the label $|G_0^j|$. 

\begin{figure}
\begin{center}
\begin{tabular}{ccc}
\includegraphics[scale=.9]{soltree-a} & 
\includegraphics[scale=.9]{soltree-b} &
\includegraphics{soltree-c} \\
(a) & (b) & (c)
\end{tabular}
\end{center}
\caption{Examples of (a)~a point set $S$, (b)~a solution
$S\setminus\{S'\}$, and (c)~the solution tree for $S'$.}
\figlabel{solution-tree}
\end{figure}

For some group $G_0^j$, let $p_{1,k}, \ldots, p_{1,\ell}$ denote the
points of $S_1$ that appear on the boundary of $\ch(S\setminus
G_0^j)$.  Any solution removes some subset $p_{1,k},\ldots,
p_{1,\ell}$ of elements from $S_1$.  Again, this subset can be
partitioned into groups of consecutive elements with any two groups
separated by at least one element of $S_1$.  In the solution tree $T$,
the sizes of these groups are given, in the order in which they occur,
by the labels of the rightmost path in the subtree of $T$ rooted at
the left child of $N_0^j$.

This process is repeated recursively: Let
$S_{<i}=\bigcup_{j=0}^{i-1}S_i$ and let $S_{<i}'=S_{<i}\cap S'$.  For
each consecutive group $G_i^j$ of nodes that are removed from $S_i$,
let $p_{i+1,k}, \ldots, p_{i+1,\ell}$ denote the vertices on $S_{i+1}$
that appear on the boundary of $CH(S \setminus (S_{<i}'\cup G_i^j))$.
In the solution tree $T$, the rightmost path of the left subtree of
the node representing $G_i^j$ contains nodes representing the sizes of
consecutive groups of nodes that are removed from the chain
$p_{i+1,k}, \ldots, p_{i+1,l}$ of $S_{i+1}$.  In this way, any
solution $S'$ to the outlier removal problem that does not remove both
$p_{0,0}$ and $p_{0,-1}$ maps to a unique solution tree.

\comment{Note that the mapping between different types of solutions
and labeled binary search trees is not bijective, because for one type
of solutions, there are many labeled binary search trees that
represent that solution. The reason is that the ordering along the
rightmost path of the tree (and recursively, the orderings along the
rightmost paths of all subtrees) is not uniquely defined.  }


\subsubsection{Computing the Solution of a Specific Type}

In this section we describe an algorithm that takes as input a
solution tree $T$ and outputs the value of the optimal solution $S'$
whose solution tree is $T$.

The algorithm we describe is recursive and operates on a subchain
$p_{i,j},\ldots,p_{i,k}$ of $S_i$ along with a solution (sub)tree $T$.  The
algorithm requires that some subset of $\bigcup_{j=0}^{i-1}S_i$ has
already been removed from $S$ so that $p_{i,j},\ldots,p_{i,k}$ are on
the boundary of the convex hull of the current point set.  The
algorithm finds an optimal solution of type $T$ such that the only
points removed from the convex hull of the current point set are in
$p_{i,j},\ldots,p_{i,k}$.

Let $d$ denote the number of nodes on the rightmost path of $T$.  The
algorithm accomplishes its task by recursively solving $O(d(k-j+1))$
subproblems on the left children of these $d$ nodes and then combining
these solutions using dynamic programming.  The following pseudocode
gives a detailed description of the algorithm's operation with the
exception of the dynamic programming component, whose description and
analysis is discussed in the next subsection.  Note that the algorithm
below only computes the maximum amount of area (perimeter) that can be
removed from $\ch(S)$ by a solution $S'$ whose solution tree is $T$.  To
obtain the points in $S'$ the algorithm can be augmented using
the standard trick of remembering, whenever the algorithm takes the
maximum of two values, which of the two values produced the maximum.
The details of this are standard and ommitted here.

\begin{minipage}{5.5in}
\noindent$\textsc{FindOptimalOfType}(T,i,j,k)$
\begin{algorithmic}[1]
\IF{$T$ is empty}
  \RETURN{0}
\ENDIF
\STATE{$d\gets$ the number of nodes on the rightmost path of $T$}
\FOR{$g=1$ to $d$}
  \STATE{$N_g\gets g$th node on the rightmost path of $T$}
  \STATE{$c_g=\lbl(N_g)$}
  \FOR{$\ell=j$ to $k-c_g+1$}
    \STATE{delete $S_{i,\ell},\ldots,S_{i,\ell+c_g-1}$ from $S_{i}$
           exposing $S_{i+1,j'},\ldots,S_{i+1,k'}$ on $S_{i+1}$}
    \STATE{$s\gets$ reduction in area (perimeter) obtained by the deletion of
           $S_{i,\ell},\ldots,S_{i,\ell+c_g-1}$} 
    \STATE{$X_{g,\ell-j+1}\gets
            s+\textsc{FindOptimalOfType}(\lft(N_g),i+1,j',k')$}
    \STATE{reinsert $S_{i,\ell},\ldots,S_{i,\ell+c_d-1}$ into $S_{i}$}
  \ENDFOR
\ENDFOR
\RETURN{$\textsc{CombineSolutions}(X,d,k-j+1,c_1,\ldots,c_d)$}
\end{algorithmic}
\end{minipage}

The call to $\textsc{CombineSolutions}$ in the last line of the
algorithm is a dynamic programming subroutine described in the next
section that runs in $O(d(k-g))$ time.  The \textsc{CombineSolutions}
subroutine computes the optimal locations of the groups of points
represented by $N_1,\ldots,N_d$ in $T$.  At the topmost level, the
algorithm is called as $\textsc{FindOptimalOfType}(T,0,0,|S_0|-1)$.

To analyze the cost of \textsc{FindOptimalOfType} it suffices to
determine, for each point $p_{i,j}$, the maximum number of times
$p_{i,j}$ is deleted (in line 8) by the algorithm.  All other work
done by the algorithm can be bounded in terms of this quantity.
points $p_{0,j}\in S_0$, each point is deleted exactly $g_0$, times,
where $g_0$ is the sum of labels of nodes on the rightmost path of
$T$. 

More generally, let $g_i$ denote the sum of labels of all nodes $N$ of
$T$ for which the path from the root of $T$ to $N$ make exactly $i$
left turns. (These nodes correspond to groups that are deleted from
$S_i$).  Consider some point $p_{i,j}\in S_i$, for $i\ge 1$.  By
Carath\'eodory's Theorem \cite{eckhoff93}, each such point is contained
in some triangle $\Delta_{i,j}=\triangle
p_{i-1,\ell_1},p_{i-1,\ell_2},p_{i-1,\ell_3}$. If $p_{i,j}$ is deleted
by \textsc{FindOptimalOfType} then it is on the boundary of the convex
hull of the current point set.  However, this implies that at least
one of the three vertices of $\Delta_{i,j}$ must be deleted from the
current point set.  Thus, if we define $m_i$ as the maximum number of
times a point of $S_i$ is deleted by \textsc{FindOptimalOfType} then
we have the relationships:
\[ 
    m_i \le \left\{\begin{array}{ll}
            g_0 & \mbox{if $i=0$} \\
            3 m_{i-1} g_i & \mbox{if $1\le i< c$} \\
            0 & \mbox{otherwise}      
        \end{array}\right.
\] 
Using the fact that $g_i \le c$, we obtain the (extremely loose) upper
bound $m_i \le (3c)^{i+1}$.  
This implies that the points of $S_c$
(which are never deleted) appear in at most $3m_{c-1}$ subproblems.
Putting all this together we obtain:

\begin{lem}\lemlabel{recursion}
The algorithm \textsc{FindOptimalOfType} finds the optimal solution
whose solution tree is $T$ in $O((3c)^c n)$ time.
\end{lem}

\subsubsection{Combining the Solutions}

One aspect of the algorithm that we have not yet described is how the
subroutine \textsc{CombineSolutions} works.  This subroutine is given
positive integers $c_1,\ldots,c_d$ and a $d\times m$ positive
real-valued matrix $X$ and must find 
indices $1\le i_1,\ldots,i_d \le m-c_d$ such that
\[
     i_{j+1} \ge i_j + c_j + 1
\]
for all $1\le j < d$ and such that the sum
\[
      h(i_1,\ldots,i_d)=\sum_{j=1}^d X_{j,i_j}
\]
is maximum.  In the terminology of the previous section, the value $d$
is the number of nodes in the rightmost path of $T$, $m=k-j+1$, and
the indices
$i_1,\ldots,i_d$ correspond to the indices of the
first element of each group on the chain $p_{i,j},\ldots,p_{i,k}$
considered by the algorithm.
We solve this problem by filling out the $d\times m$ dynamic
programming table:
\[
     D_{j,\ell} = \max\{h(i_1,\ldots,i_j):
      \mbox{$1\le i_1,\ldots,i_j\le \ell$, and $i_{j'+1} \ge i_{j'}+c_{j'}+1$
             for all $1\le j'< j$}  \} 
\]
for $j=1,\ldots,d$ and $\ell=1,\ldots,m-c_j+1$.  We can do this in
$O(cn)$ time because the table entries satisfy the recurrence
\[
     D_{j,\ell} = \max\{D_{j,\ell-1},D_{j-1,\ell-c_{j-1}-1}+X_{j,\ell} \}
\]
where we use the convention that $D_{j,\ell} = 0$ if $j=0$ and
$D_{j,\ell}=-\infty$ if $\ell<0$.  This gives the last lemma required
by the algorithm:

\begin{lem}\lemlabel{combine}
The function \textsc{CombineSolutions} can be implemented in
$O(dm)$ time.
\end{lem}

\section{Conclusions}
\seclabel{conclusions}

Together with the $O(n\log n+c^2n)$ time preprocessing described in
\secref{preliminaries}, \lemref{catalan}, \lemref{recursion} and
\lemref{combine} give an algorithm for the outlier removal problem
whose running time is
\[
 T(n,c) =   O(n\log n + c^2 n) + c \times C(2c) \times O((3c)^cn) 
      = \Oruntime \enspace .
\]
Stretching the use of asymptotic notation, this completes the proof of:
\begin{thm}
For any constant $c$, there exists an algorithm for the
(perimeter-based or area-based) outlier removal problem that runs in
$O(n\log n)$.
\end{thm}

We have made no attempt to optimize the dependence of our running time
with respect to the value of $c$ and, indeed, the running time of our
algorithm is superpolynomial in $c$. Does there exist an algorithm
that is polynomial in $c$ but that still runs in $O(n\log n)$ time for
any fixed value of $c$?

\bibliographystyle{plain}
\bibliography{outliers}

\end{document}
