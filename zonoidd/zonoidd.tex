\documentclass[lotsofwhite]{patmorin}
\usepackage{amsthm}

\newcommand{\CH}{\mathit{CH}}
\newcommand{\depth}{\mathrm{depth}}
\newcommand{\argmax}{\mathrm{argmax}}
\newcommand{\drop}{\!\!\downarrow\!\!}
\newcommand{\dual}{\varphi}

\input{pat}

%\title{An Optimal Algorithm for $d$-Variate Zonoid Depth}
\title{\MakeUppercase{An Optimal Algorithm
	for} $d$\MakeUppercase{-Variate Zonoid Depth}}
\author{Pat Morin}
\date{}

\begin{document}
\maketitle
\begin{abstract}
Algorithms for Zonoid depth in $d$ dimensions are considered.
\end{abstract}

\section{Introduction}

Let $S$ be a set of $n$ points in $\R^d$.
For a real number $k\ge 1$, the \emph{$k$-zonoid} of $S$ is defined as 
\[
      Z_k(S) = \left\{\sum_{p\in S}p\lambda_p 
	: \mbox{$0\le \lambda_p \le 1/k$ for all $p\in S$  
	   and $\sum_{p\in S}\lambda_p = 1$}  \right\} \enspace .
\] 
Notice that, for $k=1$ the $1$-zonoid of $S$ is the convex hull of
$S$,  i.e., $Z_1(S)=\CH(S)$.
As $k$ increases, $Z_k(S)$ becomes smaller and smaller until
the limiting case $k=n$, for which $Z_n(S)$ consists of a single point,
the mean of $S$.  The \emph{zonoid depth} of a point
$p\in\CH(S)$ with respect to $S$ is defined as
\[
     \depth(p,S) = \sup\{k : p\in Z_k(S) \} \enspace ,
\]
and, for $p\in\CH(S)$, is a real number in the interval $[1,n]$.

Gopala and Morin \cite{gm06} consider algorithms for bivariate ($d=2$)
zonoid depth and give an $O(n)$ expected time algorithm for computing,
$\depth(p,S)$ when $p$ and $S$ are in $\R^2$.  The current
paper extends their results by giving an $O(n)$ time algorithm to compute
$\depth(p,S)$ when $p$ and $S$ are in $\R^d$ for any constant
dimension $d$.  

\section{Chan's Generalized Optimization Technique}

Chan \cite{c2004} used the following theorem to provide an $O(n\log
n)$ time algorithm for maximum Tukey depth.  In the following, and
throughout the remainder of the paper, we use the shorthand $\cap S$
to denote $\bigcap_{s\in S}s$.

\begin{thm}[Chan 2004]\thmlabel{chan}
Let $\mathcal{H}$ denote the set of all halfspaces in $\R^d$,
let $\mathcal{P}$ denote the set of all possible inputs to some problem, 
let $f:\mathcal{P}\mapsto 2^{\mathcal{H}}$ be any function mapping 
problem inputs to sets of halfspaces in $\R^d$,
and let $w:\R^d\mapsto \R$ be
any linear objective function.  Suppose that $f$ and $w$ satisfy:
\begin{enumerate}
\setcounter{enumi}{-1}
\item Given inputs $P_1,\ldots,P_d\in\mathcal{P}$ each of constant
size, a point $p\in\cap (f(P_1)\cup\cdots\cup f(P_d))$ maximizing
$w(p)$ can be found in constant time.

\item Given a point $p\in\R^d$ and an input $P\in\mathcal{P}$
of size $n$, there exists a $D(n)$ time algorithm to determine whether
$p\in\cap f(P)$.

\item There exists constants $\alpha < 1$ and $r$ such that, for any
input $P\in\mathcal{P}$ of size $n$, it is possible to compute, in
$D(n)$ time, inputs $P_1,\ldots,P_r$, each of size at most
$\ceil{\alpha n}$, and such that $\cap f(P) =
\cap(f(P_1)\cup\cdots\cup f(P_r))$.

\end{enumerate}
Then there exists an $O(D(n))$ expected time randomized algorithm to
compute, for any input $P\in\mathcal{P}$ of size $n$ a point
$p\in\cap f(P)$ that maximizes $w(p)$.
\end{thm}

It is worth noting that the codomain of the function $f$ may contain
infinite sets.  That is, it is acceptable (and common) to have inputs
$P\in\mathcal{P}$ that generate an infinite number of constraints,
i.e., $|f(P)|=\infty$.


\section{Dual Zonoids}

The $k$-zonoid $Z_k(S)$ is a convex polytope.  The extreme-most vertex
of $Z_k(S)$ in direction $w$ can be obtained as follows
\cite{gmXX,beXX}:  Let $w$ be a non-zero vector and denote 
by $S_1^w,\ldots,S_n^w$ the points of $S$
ordered by their projection onto a line in direction $w$.  That is,
$S_i\cdot w \ge S_{i+1}\cdot w$ for all $1\le i\le n-1$.  Then the
extreme-most vertex of $Z_k(S)$ in direction $w$ is given by 
\[  
\argmax\{p\cdot w: p\in Z_k(S)\} =
        \left(\sum_{i=1}^{\floor{k}} S_i^w\times\frac{1}{k}\right) +
          S_{\ceil{k}}^w\times(k-\floor{k})
\]
\cite{beXX,gmXX}.
Consider the point-hyperplane duality function
$\dual$ given by 
\[
    \dual(x)=\{y\in\R^d : y_d = x_1y_1 +\cdots +x_{d-1}y_{d-1} - x_d \}
%   \dual(a_1,\ldots,a_d) = 
%      \{(b_1,\ldots,b_d) : a_db_d = a_1b_1+\cdots a_{d-1}b_{d-1}  \}
\] 
when $x$ is a point in $\R^d$ and
\[
     \dual(X) = \{\dual(x) : x\in X\}
\]
when $S$ is a subset of $\R^d$.  For a point $x$
and a hyperplane $h$, let $x\drop h$ denote the $d$th coordinate of
the vertical projection of $x$ onto $h$.  For a set $H$ of
hyperplanes, let $H_i^x$ be the $i$th hyperplane in $H$ encountered by
a downward vertical ray originating at $(x_1,\ldots,x_{d-1},\infty)$.
For ease of notation we use the shorthand $H_{-i}^x=H_{|H|-i+1}^x$.

Let $H=\dual(S)$.  Then,
under this duality, the \emph{dual $k$-zonoid} $\dual(Z_k(S))$ is the set 
of all hyperplanes in $\R^d$
that do not intersect either of two convex sets $R_A(S)$ and $R_B(S)$.
That is,
\[
     \dual(Z_k(S)) = \{ h\in\mathbb{H^d} : h\cap(R_A(S)\cup R_B(S)) = \emptyset \} \enspace ,
\]
where
\begin{equation}
   R_A(S) = \left\{x\in\R^d: x_d \ge 
\left(\frac{1}{k}\sum_{i=1}^{\floor{k}} x\drop H_i^x\right) +
          (x\drop H_{\ceil{k}}^x)(k-\floor{k}) \right\}  \eqlabel{ra}
\end{equation} 
and
\begin{equation}
   R_B(S) = \left\{x\in\R^d: x_d \le 
\left(\frac{1}{k}\sum_{i=1}^{\floor{k}} x\drop H_{-i}^x\right) +
          (x\drop H_{-\ceil{k}}^x)(k-\floor{k}) \right\} \enspace .
\end{equation}
The two sets $R_A(S)$ and $R_B(S)$ are convex, unbounded from above,
respectively, below, and piecewise linear.  Indeed, the linear pieces
of $R_A(S)$ (respectively $R_B(S)$) are in one to one correspondence
with the linear pieces of the $\ceil{k}$-level (respectively
the $(n-\floor{k}+1)$-level) of the hyperplanes in $H$.


\section{The Decision Algorithm}

Next we consider the following decision problem:  Given a point set
$S$ and an integer $k$, is the origin contained in $Z_k(S)$?  By
translation, a solution to this problem allows us to test if an
arbitrary point $p\in\R^d$ is contained in $Z_k(S)$. One
approach to solving this problem is to compute the intersection of
$Z_k(S)$ with a vertical line through the origin (the $d$th coordinate
axis) and then check if this intersection contains the origin. 

Under duality, the above strategy is equivalent to finding the lowest
point on $R_A(S)$ and the highest point on $R_B(S)$ and checking that each
of these points is above, respectively, below, the hyperplane
$\{x\in\R^d:x_d=0\}$.  In the remainder, we focus on determining the
lowest point in $R_A(S)$.  Finding the highest point in $R_B(S)$ is done in
a symmetric manner.  However, before we can proceed, we need to define
a slightly more general problem on weighted zonoids as well as the
corresponding notion of dual weighted zonoids.

Let $S$ be a set of $n$ points in $\R^d$ and let
$v:S\mapsto\mathbb{N}$ be a function assigning positive integer
weights to the elements of $S$.   We denote by $S^v$, the multiset in
which each element $p\in S$ occurs $v(p)$ times.  The
\emph{$v$-weighted zonoid} $Z_k(S,v)$ is simply the $k$-zonoid of the
multiset $S^v$, i.e., $Z_k(S,v)=Z_k(S^v)$.  As with standard zonoids,
the weighted zonoid $Z_k(S,v)$ dualizes to the set of all lines that
do not intersect either of two convex regions $R_A(S,v)$ and
$R_B(S,v)$, where $R_A(S,v)=R_A(S^v)$ and $R_B(S,v)=R_B(S^v)$.


This definition of weighted zonoids
allows us to naturally define subproblems.
For a subset $C\subseteq S$, define the \emph{total weight}
\[
       v(C)=\sum_{p\in C}v(p)
\]
and the \emph{weighted mean}
\[ 
       \mu(C)=\sum_{p\in C} p(v(p)/v(C)) \enspace .
\]
The \emph{contraction} of
$(S,v)$ by $C$ is obtained by replacing the points of $C$ by their
weighted average, $\mu(C)$.  More precisely, the contraction of
$(S,v)$ by $C$ is the pair $(T,w)$ where 
\[ T = (S\setminus C) \cup \{ \mu(C) \} \] 
and 
\[ w(p) = \left\{\begin{array}{ll} 
        v(p) & \mbox{if $p\in S\setminus C$} \\ 
        v(C) & \mbox{if $p=\mu(C)$} \end{array}\right.
\]

The following lemma shows that contraction results in strictly smaller
zonoids:

\begin{lem}\lemlabel{contraction}
If $(T,w)$ is a contraction of $(S,v)$ by $C$ then $Z_k(S',v')
\subseteq Z_k(S,v)$.
\end{lem}

\begin{proof}
Let $x$ be any point in $Z_k(T,w)$.  Then, by the definition of
zonoids:
\begin{eqnarray*}
    x &=& \sum_{p\in T^w} p\lambda_p \\
      &=& \sum_{p\in (T\setminus \{\mu(C)\})^w} p\lambda_p\
          + \left(\sum_{p\in \{\mu(C)\}^w}p\right)\lambda_{\mu(C)} \\
      &=& \sum_{p\in (S\setminus C)^v} p\lambda_p
          + \left(\sum_{p\in C^v} p\right)
             \lambda_{\mu(C)}\\
      &=& \sum_{p\in (S\setminus C)^v} p\lambda_p
          + \sum_{p\in C^v} p
             \lambda_{\mu(C)}\\
      &\in& Z_k(S,v)
\end{eqnarray*}
as required.
\end{proof}



We now have all the tools required to apply \thmref{chan} to solve our
decision problem.

\begin{thm}\thmlabel{decision}
Given a set $S$ of $n$ points in $\R^d$ and a 
function $v:S\mapsto\mathbb{Z}^+$ that is computable in constant
time, the point $x\in R_A(S,v)$ such
that $x_d$ is minimum can be found in $O(n)$ expected
time.
\end{thm}

\begin{proof}
Let $f$ be a function that maps the pair $(S,v)$ onto a set of
halfspaces whose intersection is $R_A(S,v)$.  We need to show that the
function $f$ satisfies the Conditions~0--2 of \thmref{chan}.

To satisfy Condition 0 we can enumerate all the linear constraints
generated by each of the $d$ subproblems and use any linear
programming algorithm to find a point $x$ that satisfies all
constraints and such that $x_d$ is minimum.  There are only $d$
subproblems, each of constant size, so this step takes constant time,
as required.

To satisfy Condition 1, we observe that, testing if $x\in R_A(S,v)$
simply involves checking if $x$ satisfies \eqref{ra}.  Let
$H=\dual(S)$.  This check can be accomplished by using a $D(n)=O(n)$
time weighted selection algorithm \cite{X} to compute the smallest
index $t$ and the hyperplanes $H_{1}^x,\ldots,H_{t}^x$ such that
$\sum_{i=1}^tv(\dual(H_{i}^x)) \ge k$.  Once this is done we need only
check \eqref{ra} which, in the weighted setting, becomes 
\[
     x \ge \left(\sum_{i=1}^{t-1} (x\drop
H_i^x)\times\frac{1}{k}\times v(\dual(H_i^x))\right) 
   + (x\drop H_t^x) \times \left(k-\sum_{i=1}^{t-1} v(\dual(H_{i}^x)) \right)
\enspace .
\]\notice{Deal with overly large values of $k$ here} 

To satisfy Condition~2 we make use of \emph{cuttings} \cite{X}.  In
particular, we use the fact that, in $O(n)$ time, it is possible to
partition $\R^d$ into $O(1)$ simplices
$\Delta_1,\ldots,\Delta_r$ such that the interior of each simplex is
intersected by at most $n/2$ of the hyperplanes in $\dual(S)$.  For
each simplex $\Delta_i$ we create a subproblem $(S_i,v_i)$ as follows:
Let $C_i\subseteq S$ contain every point $p\in S$ such that $\dual(p)$
is above the interior of $\Delta_i$.  We first construct the pair
$(T_i,v_i)$ by contracting $(S,v)$ by $C_i$.  Next, we obtain $S_i$ by
removing from $T_i$ every point $p$ such that $\dual(p)$ is below the
interior of $\Delta_i$.  The subproblems $(S_i,v_i)$ for $1\le i\le r$
that we obtain in this manner are each of size at most $n/2+2$.

It follows from \lemref{contraction} and the definition of $Z_k(S,v)$
that $Z_k(S_i,{v_i})\subseteq Z_k(S,v)$.  In the dual, this means that
$R_A(S_i,{v_i})\supseteq R_A(S,v)$.  To satisfy Condition~2 we must
show that $\bigcap_{i=1}^r R_A(S_i^{v_i}) = R_A(S^v)$.  To see this,
consider any point $x$ on the boundary of $R_A(S,v)$.  It is
sufficient to show that $x$ is also on the boundary of at least one
region $R_A(S_i,{v_i})$ for $1\le i\le r$.  The point $x$ is defined
by $\ceil{k}$ hyperplanes $h_1,\ldots,h_{\ceil{k}}\in\dual(S)$ that pass
above the point $x\drop h_{\ceil{k}}$.  Note that there is some
simplex $\Delta_i$ that contains
$x\drop h_{\ceil{k}}$.  This the index $i$ that such that
$R_A(S_i,v_i)$ has $x$ on its boundary.

This completes the proof.
\end{proof}


\section{The Optimization Algorithm}

\end{document}

