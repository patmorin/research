\documentclass [letterpaper] {patmorin}
%fleqn: left alignment of the equations
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
%\usepackage [noend] {algorithmic}
%\usepackage{setspace}
%\usepackage [letterpaper] {geometry}
%\usepackage{indentfirst}
\usepackage[pdftex]{color, graphicx}
%\usepackage{subfigure}
%\usepackage{supertabular}
%\usepackage{multirow}
%\usepackage[normalem]{ulem}
\usepackage[mathlines]{lineno}
\linenumbers

%\newcommand{\note}[1]{$\spadesuit$\marginpar{$\spadesuit$ #1}}

\newtheorem{theorem}{Theorem}%[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{lemma}{Lemma}%[section]
\newtheorem{notation}{Notation}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{claim}{Claim}
\newtheorem{corollary}{Corollary}


\newcommand{\EXP}{\mathrm{E}}
\newcommand{\PROB}{\Pr}
\newcommand{\R}{\mathbb{R}}
\newcommand{\etal}{\emph{et al}}

\title{\MakeUppercase{Oblivious Routing in Convex Subdivisions: \newline 
       Random Walks are Optimal}}
\author{Dan Chen, Luc Devroye, Vida Dujmovi\'c, and Pat Morin}

\begin{document}
\maketitle

\section{Introduction}
\label{sec:intro}

In recent years, motivated primarily by the proliferation of wireless networks and GPS devices, much research has been done on routing algorithms for geometric networks \cite{gior03}.  In this research a network is modelled as a geometric graph $G=(V,E)$ whose vertex set $V$ is a set of points in $\R^2$. We say that a routing algorithm $\mathcal{A}$ \emph{works} for $G$ if, for any pair of vertices $s,t\in V$, the algorithm always find a path from $s$ to $t$ in a finite number of steps.

The research on geometric routing algorithms largely focuses on utilizing geometric properties of a class of geometric graphs to reduce the complexity of, and information required by, routing algorithms.  For example, when $G$ is the unit disk graph of the points in $V$, then an algorithm, called \textsc{Face-1}, of Bose \etal\ \cite{bose01} works and requires no preprocessing of $G$ or additional state information at the vertices of $G$ and requires only a constant size header associated with each packet.

A particularly interesting and restricted class of routing algorithms are so-called oblivious routing algorithms.  An \emph{oblivious} routing algorithm is one in which the decision about the next edge on the route to $t$ for a packet currently located at node $v$ is made based only on $v$, $t$, and the neighbourhood, $N(v)$, of $v$.\footnote{More precisely, a deterministic oblivious routing algorithm is a function $f:\R^2\times\R^2\times(\R^2)^+\rightarrow \R^2$ that satisfies $f(v,t,N) \in N$ and $f(t,t,N) = t$ for all inputs.}  In particular, an oblivious algorithm does not make use of information obtained in previous routing steps and can not use any global information about $G$.

Bose and Morin \cite{bose04} showed that if $G$ is Delaunay triangulation or a regular triangulation then deterministic oblivious routing algorithms named \textsc{Greedy} and \textsc{Compass}, respectively, guarantee delivery of a packet between any source-destination pair.  Bose \etal\ \cite{bose02} later proved a stronger result showing that a deterministic oblivious routing algorithm named \textsc{Greedy-Compass} works for any triangulation $G$.

Oblivious routing algorithms are so simple, elegant, and practical that researchers have spent considerable effort designing geometric embeddings of graphs so that oblivious routing algorithms can be applied to the resulting embeddings.  A famous example in this vein is due to Leighton and Moitra \cite{lm08} who proved that every 3-connected planar graph $\tilde G$ admits an embedding $G$ in $\R^2$ such that \textsc{Greedy} works on $G$.  The combination of the embedding and routing algorithm represents a form of \emph{compact routing} \cite{l94}.

Bose \etal\ also showed that deterministic oblivious routing algorithm are, however, inherently limited. There exists 17 convex subdivisions $G_1,\ldots,G_{17}$ each with 17 vertices such that any deterministic oblivious routing algorithm does not work for at least one of these subdivisions.  Thus, convex subdivisions form a class of geometric graphs that are too rich for deterministic oblivious routing algorithms \cite{bose02}.

The authors \cite{bose02,bose04} did, however, observe that, if randomization is allowed, then an oblivious algorithm, named \textsc{RandomCompass}, that uses one random bit per step works for any convex subdivision. They did not analyze the efficiency of \textsc{Random-Compass} except to note that, for some convex subdivisions $G$, and some pairs $s,t\in V$, the expected number of steps taken by \textsc{Random-Compass} when routing from $s$ to $t$ is $\Omega(|V|^2)$.

Observe that, by the theory of random walks \cite{X}, the expected time required for a random walk on $G$ to travel from a particular to vertex $s$ to a particular vertex $t$ is $O(n^2)$.  Therefore, a random walk is as efficient, in the worst case, as \textsc{Random-Compass} algorithm. Nevertheless, one might expect that \textsc{Random-Compass} is more likely to find short routes, since it uses geometry to find a route that is specifically directed towards the target vertex $t$.  Thus, we might intuit that \textsc{Random-Compass} is a heuristic that is usually better than a random walk and never much worse.

In the current paper, we show that this intuition about \textsc{Random-Compass} could not be further from the truth.  Indeed, for any $n>0$, there exists a convex subdivision (in fact, a triangulation) $G$ with $n$ vertices and having two vertices $s$ and $t$ such that the expected number of steps taken by \textsc{Random-Compass} when routing from $s$ to $t$ is $2^{\Omega(n)}$.

Next we study whether \emph{any} randomized oblivious routing algorithm for convex subdivisions can outperform a random walk.  We show that, for any randomized oblivious routing algorithm $\mathcal{A}$ and any $n$, there exists a convex subdivision $G$ of size $n$ and a pair of vertex $s,t\in V(G)$ such that the expected number of steps taken by $\mathcal{A}$ when routing from $s$ to $t$ is $\Omega(n^2)$.  Therefore, at least in the worst-case, no algorithm significantly outperforms a random walk.

\section{A Bad Example for Random-Compass}

Figure~\ref{fig:bad-unbiased} shows an example of a triangulation that is
bad for the \textsc{Random-Compass} algorithm.  It's vertex set has size
$n=4k+1$ that are organized as a central vertex $t$ and four paths leading
from the outer face to $t$.  The space between these paths is triangulated
so that, at any point, \textsc{Random-Compass} chooses between an edge
that leads one step closer to $t$ or that returns to the outer face.

\begin{figure}
  \begin{center}
    \includegraphics{pics/bad-unbiased}
  \end{center}
  \caption{A graph in which \textsc{Random-Compass} has expected running time 
           $\Omega(2^{n/4})$.}
  \label{fig:bad-unbiased}
\end{figure}

If denote by $T_i$ the expected number of steps required by \textsc{Random-Compass} to reach $t$ given that it is currently $i$ steps from $t$, we see that 
\[ 
   T_1=1 \enspace ,
\]
and 
\[
  T_i = 1 + (1/2)T_{i-1} + (1/2)T_k
\]
for $i \in \{2,\ldots, k\}$.  So 
\begin{eqnarray*}
  T_k & = & 1 + (1/2)T_k + (1/2)T_{k-1} \\
      & = & 1 + (1/2)T_k + 1/2 + (1/4)T_{k} + (1/4)T_{k-2} \\
      & = & 1 + (1/2)T_k + 1/2 + (1/4)T_{k} + (1/4)
              + \cdots  + (1/2^{k-1}) + (1/2^{k})T_{k} + (1/2^{k})T_1 \\
      & = & 2-1/2^{k} + (1-1/2^k)T_k \enspace .
\end{eqnarray*}
and rewriting this gives $T_k = 2^k(2-1/2^{k}) = \Omega(2^{n/4})$.  This proves:

\begin{theorem}
For any $n>1$, there exists a triangulation $G$ having two vertices $s$ and $t$ such that the expected number of steps taken by $\textsc{Random-Compass}$ when routing from $s$ to $t$ is $2^{\Omega(n)}$.
\end{theorem}

Note that the base in the exponent can be improved by using a construction
with 3 paths instead of 4.  In this case, the lower bound becomes
$\Omega(2^{n/3})$.

\section{A Lower Bound for Any Algorithm}

In this section, we develop an $\Omega(n^2)$ lower bound for any randomized oblivious routing algorithm $\mathcal{A}$.  The outline of the lower bound is as follows:  We start with a lemma about Markov chains whose transition graphs are paths. We show that, when starting at the midpoint of the path, there is at most one endpoint of the path that can be reached in subquadratic expected time.  This lemma is relevant since, if $\mathcal{A}$ finds itself in the interior of a path of degree 2 vertices in $G$, it will behave a like such a Markov chain until it reaches one of the endpoints of the path.

Next, we observe how $\mathcal{A}$ behaves on certain paths of degree 2 vertices and show that, because $\mathcal{A}$ can only reach one endpoint of any path in subquadratic time, that we can always find a constant-sized subset of these paths that can be pieced together to obtain a convex subdivision in which $\mathcal{A}$ takes at least quadratic expected time to route from some vertex $s$ to some vertex $t$.

\section{Markov Chains}
\label{sec:markov}

Consider a Markov chain on $\{ 1, \ldots, n \}$, $n > 1$, where transitions only
take place between neighbors. If $p_{i,j}$ is the probability of a transition
from $i$ to $j$, then we have 
\[
p_{1,2} = p_{n,n-1} = 1,
\]
\[
p_{i,i+1} = 1-p_{i,i-1} = \pi_i, 2 \le i \le n-1,
\]
where $\pi_2, \ldots, \pi_{n-1}$ are fixed probabilities.
The vector of these probabilities is denoted by $\pi$.
We will set $\pi_1 = 1$, $\pi_n = 0$, to be consistent, as the
extreme states are reflecting.  When $\pi_i = 1/2$ for $2 \le i \le n-1$,
we obtain a standard random walk on a finite interval with reflecting barriers.

We denote the Markov chain by $X_0, X_1, \ldots, X_t , \ldots$,
and denote the hitting times by $T_{i,j}$:
\[
T_{i,j} = \min \{ t > 0: X_t = j | X_0 = i \}.
\]
For a standard random walk, it is known that
\[
\EXP \{ T_{i,j} \} = (j-i)^2, j \not= i, 1 \le j,i \le n.
\]
The standard random walk is in fact the best possible chain in the following sense:

\begin{lemma}\label{lemma:backandforth}
For any vector of probabilities $\pi$, and any $n > 1$,
\[
\EXP \{ T_{1,n} + T_{n,1} \} \ge 2 (n-1)^2.
\]
\end{lemma}

\begin{proof}
The lemma is obviously true if any $\pi_i$, $2 \le i \le n-1$, is either
zero or one as that would imply that at least one of the hitting times is
infinite. Thus, we assume that all probabilities are strictly in $(0,1)$.
It is also trivial if $n=2$, so assume $n > 2$.
Define
\[
P_i = {1 \over \pi_i } - 1, Q_i = {1 \over 1-\pi_i} - 1,
\]
and note that $P_i Q_i = 1$.
If needed, we formally set $P_1 = Q_n = 0$.
%  For later reference, we need the inequality
%  $$
%  \left( {1 \over n-2} \sum_{i=2}^{n-1} P_i \right) \times
%  \left( {1 \over n-2} \sum_{i=2}^{n-1} Q_i \right)  \ge 1.
%  $$
%  This follows after noting $Q_i = 1/P_i$, so that the left-hand factor 
%  can be written as $\EXP \{ Y \}$ and the right-hand factor as $\EXP \{ 1/Y \}$,
%  where $\PROB \{ Y=P_i \} = 1/(n-2)$, $2 \le i \le n-1$.
%  But $Y$ and $1/Y$ are negatively associated random variables, and thus
%  $$
%  \EXP \{ Y \} \EXP \{ 1/Y \} \ge \EXP \{ Y \cdot (1/Y \} = 1,
%  $$
%  which proves the inequality above.
%  

We need an explicit formula for $\EXP \{ T_{1,1} \}$.
Let us introduce the chains on $\{ i, \ldots , n \}$ with
reflecting barriers at $i$ and $n$, but with the same $\pi_j$ values
associated with non-terminal states. 
Let $T^+_{i,j}$ with $j \ge i$, denote the hitting time from $i$ to $j$ in the chain $\{1,\ldots,n\}$ defined this way.
Clearly,
\[
T^+_{n-1, n-1} = 2.
\]
Next,
\[
T^+_{n-2, n-2 } = 2 + \sum_{j \le Z} W_j,
\]
where $W_j$ are independent lengths excursions from $n-1$ to  $n-1$
on the chain $\{ n-1, n \}$, and $Z$ (possibly zero) is the number of such excursions.
Obviously, $Z$ is geometrically distributed, and $\EXP \{ Z \} = Q_{n-1}$.
Because $\EXP \{ W_1 \} = \EXP \{ T^+_{n-1, n-1} \} = 2$,
and because $Z$ is a stopping time, 
we have, by Wald's identity,
\[
\EXP \{ T^+_{n-2, n-2} \} = 2 + 2 Q_{n-1}.
\]
This argument is easily extended by induction, and we obtain for $1 \le i < n-1$,
\[
\EXP \{ T^+_{i, i} \}  = 2 + Q_{i+1} \EXP \{ T^+_{i+1, i+1} \}
  = 2 \left( 1 + Q_{i+1} + Q_{i+1} Q_{i+2} + \cdots + Q_{i+1} \cdots Q_{n-1} \right).
\]
By flipping sides, and denoting by $T^-$ the hitting times for
the Markov chains on $\{ 1, \ldots i \}$
with reflecting bariers at $1$ and $i$, we obtain in a similar fashion,
for $2 < i \le n$,
\[
\EXP \{ T^-_{i, i} \}  = 2 + P_{i-1} \EXP \{ T^-_{i-1, i-1} \}
  = 2 \left( 1 + P_{i-1} + P_{i-1} P_{i-2} + \cdots + P_{i-1} \cdots P_{2} \right).
\]
Furthermore, $\EXP \{ T^-_{2, 2} \}  =2$.

With these calculations out of the way,  we note that
\[
\EXP \{ T_{i,i+1} \} = 1 + P_i \times \EXP \{ T^-_{i, i} \},
\EXP \{ T_{i,i-1} \} = 1 + Q_i \times \EXP \{ T^+_{i, i} \}.
\]
Clearly,
\[
\begin{aligned}
\EXP &\{  T_{1,n} + T_{n,1} \} \\
&= \sum_{i=1}^{n-1} \EXP \{ T_{i,i+1} \} + \sum_{i=2}^n \EXP \{ T_{i,i-1} \} \\
&= 2(n-1) + 2\sum_{i=2}^{n-1} \left( P_i + P_i P_{i-1} + \cdots + P_i \cdots P_{2} \right) + 2\sum_{i=2}^n \left( Q_i + Q_i Q_{i+1} + \cdots + Q_i \cdots Q_{n-1} \right) \\
&= 2(n-1) + 2\sum_{i=2}^{n-1} \sum_{j=2}^i \prod_{k=j}^i P_k + 2\sum_{i=2}^n \sum_{j=i}^{n-1} \prod_{k=i}^j Q_k  \\
&= 2(n-1) + 2\sum_{i=2}^{n-1} \sum_{j=2}^i \prod_{k=j}^i P_k + 2\sum_{j=2}^n \sum_{i=j}^{n-1} \prod_{k=j}^i Q_k  \\
&= 2(n-1) + 2\sum_{i=2}^{n-1} \sum_{j=2}^i \prod_{k=j}^i P_k + 2\sum_{i=2}^{n-1} \sum_{j=2}^i \prod_{k=j}^i Q_k  \\
&= 2(n-1) + 2\sum_{i=2}^{n-1} \sum_{j=2}^i \left( \prod_{k=j}^i P_k + \prod_{k=j}^i Q_k \right)  \\
&\ge 2(n-1) + 4\sum_{i=2}^{n-1} \sum_{j=2}^i \sqrt{ \prod_{k=j}^i P_k \times \prod_{k=j}^i Q_k } \\
&\qquad \hbox{\rm (by the arithmetic-geometric mean ineqality)} \\
&= 2(n-1) + 4\sum_{i=2}^{n-1} \sum_{j=2}^i  1 \\
&\qquad \hbox{\rm (by part (i), as $P_iQ_i = 1$ for all $i$ in our range)} \\
&= 2(n-1) + 4\sum_{i=1}^{n-1} (i-1) \\
&= 2(n-1) + 2 n (n-1) - 4 (n-1) \\
&= 2(n-1)^2,\\
\end{aligned}
\]
which concludes the proof.
\end{proof}

Next we present a simple corollary of \ref{lemma:backandforth} that is used in our lower bound.
Consider a random walk with reflecting barriers on $\{ -n, \ldots, n \}$, $n > 0$.
We intend to show
\[
\max \left( \EXP \{ T_{0,n} \} , \EXP \{ T_{0,-n} \} \right)
 \ge  {2 \over 3} \, n^2.
\]
We prove this by contradiction. Set $c = 2/3$. Assume that
\[
\max \left( \EXP \{ T_{0,n} \} , \EXP \{ T_{0,-n} \} \right) <  cn^2.
\]
By Theorem 1,
\[
 \EXP \{ T_{0,n} \}  +  \EXP \{ T_{n,0} \}  \ge 2n^2,
\]
and
\[
 \EXP \{ T_{0,-n} \}  +  \EXP \{ T_{-n,0} \}  \ge 2n^2.
\]
Observe for this that $0$ is not a reflecting barrier, but this makes 
$ \EXP \{ T_{0,n} \}$ only larger, so Theorem 1 does indeed apply.
By our assumption, we thus have
\[
\min \left( \EXP \{ T_{n,0} \} ,  \EXP \{ T_{-n,0} \} \right) >  (2-c) n^2.
\]
Let $T$ be the cover time, i.e., the time to visit all states starting from state $0$. It is easy to see that
\[
T_{0,n} + T_{0,-n} > T = \max \left( T_{0,n} , T_{0,-n} \right)
  =  T_{0,S} + T_{S,-S},
\]
where $S \in \{ n, -n \}$ is the first of the two end states
reached by the Markov chain. If we condition on the history up to $T_{0,S}$,
we see that
\[
\EXP \{ T_{S,-S} \} \ge \min \left( \EXP \{ T_{n,0} \} ,  \EXP \{ T_{-n,0} \} \right) >  (2-c) n^2.
\]
Thus,
\[
\max \left( \EXP \{ T_{0,n} \} , \EXP \{ T_{0,-n} \} \right)
 \ge {1 \over 2} \, \left( \EXP \{ T_{0,n} \} + \EXP \{ T_{0,-n} \} \right)
 \ge {1 \over 2} \, \EXP \left\{ \max \left( T_{0,n} , T_{0,-n} \right) \right\} 
= {1 \over 2} \, \EXP \{ T \}
>  (1- c/2 ) \,  n^2 ,
\]
which contradicts our assumption.


We note that Moon's identity implies that $\EXP \{ T_{0,n} \} = \EXP \{ T_{0,-n} \} = 3n^2$
for the standard random walk, which is conjectured to be best possible.
	The lower bound thus seems to be off by a factor $9/2$.




\section{The Bound}
\label{sec:bound}

Let $A$ be a chain of $k-1$ edges in a line such that $a_{k}$ is closer to $t$ and $a_{1}a_{k}t$ is a left turn with $\angle a_{1}a_{k}t$ greater than $150$ degrees. Let $B$ be a chain of $k-1$ edges in a line such that $b_{k}$ is closer to $t$ and $b_{1}b_{k}t$ is a right turn with $\angle b_{1}b_{k}t$ greater than $150$ degrees. Let $C_{A}$ be auxiliary circle of $A$. Each point on $C_{A}$ represents a direction of $A$ (as shown in Figure~\ref{fig:acircle}). If it takes $\Omega (k^{2})$ time to reach $a_{k}$ from $a_{1}$ in any direction we color the corresponding point on $C_{A}$ black, otherwise, we color the corresponding point blue.
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.6\textwidth]{pics/achaincircle.pdf}
  \caption{Chain $A$ and its auxiliary circle}
  \label{fig:acircle}
\end{figure}
Let $C_{B}$ be the auxiliary circle for $B$ (as shown in Figure~\ref{fig:bcircle}), and if it takes $\Omega (k^{2})$ time to reach $b_{k}$ from $b_{1}$ in any direction we color the corresponding point on $C_{B}$ black, otherwise, we color the corresponding point blue.
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.6\textwidth]{pics/bchaincircle.pdf}
  \caption{Chain $B$ and its auxiliary circle}
  \label{fig:bcircle}
\end{figure}
Let $C_{o}$ be the overlap of the $C_{A}$ and $C_{B}$ and the black points on any circle will override blue ones when overlapping.

\begin{lemma}
  \label{lem:1blue}
  If there is a blue point on $C_{o}$, there exists a convex subdivision on which any oblivious routing algorithm will take $\Omega (n^{2})$ time.
\end{lemma}

\begin{proof}
  The blue point on $C_{o}$ corresponds two blue points at the same place on $C_{A}$ and $C_{B}$. Let $k = \frac{n}{2}$. We can have an arrangement of two chains $A$ and $B$ according to the two blue points by connecting $a_{\frac{n}{2}}t$, $b_{\frac{n}{2}}t$, and $a_{1}b_{1}$, like the one shown in Figure~\ref{fig:1blue}.
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.35\textwidth]{pics/1blue.pdf}
  \caption{Two chains corresponding to the blue point }
  \label{fig:1blue}
\end{figure}
We know that it takes $\Omega (n^{2})$ time to reach $a_{\frac{n}{2}}$ from $a_{1}$. If we let $a_{1}$ be $s$, the algorithm will need $\Omega (n^{2})$ time to reach $t$.
\end{proof}

\begin{theorem}
  \label{thm:quadratic}
  Any oblivious routing algorithm requires $\Omega (n^{2})$ time on convex subdivisions.
\end{theorem}

\begin{proof}
  If there is a blue point on $C_{o}$, the algorithm requires $\Omega (n^{2})$ time according to Lemma~~\ref{lem:1blue}. If there is no blue point on $C_{o}$, the whole $C_{o}$ has to be black, then there will be three black points on $C_{o}$ which have equal distance to each other.

  Let $X$, $Y$, and $Z$ be three chains of edges corresponding to the three black points, then the angle between any two of them must equal to $120^{\circ}$. There are two possibilities ($A$ or $B$) for each of the three chains as shown in 
Figure~\ref{fig:3black}.
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.35\textwidth]{pics/3black.pdf}
  \caption{Three chains corresponding to the three black points}
  \label{fig:3black}
\end{figure}
Let $k = \frac{n}{3}$. We now show that $t$ is always contained in $\triangle x_{\frac{n}{3}}y_{\frac{n}{3}}z_{\frac{n}{3}}$ no matter if $A$ or $B$ is used for any of the three chains. 

Since the angle between $Y$ and $Z$ is $120^{\circ}$, $\angle y^{a}_{\frac{n}{3}}tz^{a}_{\frac{n}{3}} = \angle y^{b}_{\frac{n}{3}}tz^{b}_{\frac{n}{3}} = 120^{\circ}$. Hence, $y^{a}_{\frac{n}{3}}tz^{a}_{\frac{n}{3}}$ and $y^{b}_{\frac{n}{3}}tz^{b}_{\frac{n}{3}}$ are all right turns. According to the definition of $A$ and $B$, $0 < \angle y^{a}_{\frac{n}{3}}ty^{b}_{\frac{n}{3}} = \angle z^{a}_{\frac{n}{3}}tz^{b}_{\frac{n}{3}} < 60^{\circ}$, then $120^{\circ} < \angle y^{b}_{\frac{n}{3}}tz^{a}_{\frac{n}{3}} < 180^{\circ}$ and $60^{\circ} < \angle y^{a}_{\frac{n}{3}}tz^{b}_{\frac{n}{3}} < 120^{\circ}$. In other words, $y_{\frac{n}{3}}tz_{\frac{n}{3}}$ is always a right turn.

With the same argument, $x_{\frac{n}{3}}ty_{\frac{n}{3}}$ and $z_{\frac{n}{3}}tx_{\frac{n}{3}}$ are also right turns. Therefore $t$ is inside $\triangle x_{\frac{n}{3}}y_{\frac{n}{3}}z_{\frac{n}{3}}$. By adding edges $x_{1}y_{1}$, $y_{1}z_{1}$, $x_{1}z_{1}$, $x_{\frac{n}{3}}y_{\frac{n}{3}}$, $y_{\frac{n}{3}}z_{\frac{n}{3}}$, $x_{\frac{n}{3}}z_{\frac{n}{3}}$, $x_{\frac{n}{3}}t$, $y_{\frac{n}{3}}t$, and $x_{\frac{n}{3}}t$, we have convex subdivision. Since the three points on $C_{o}$ are black, it takes  $\Omega (n^{2})$ time to reach $x_{\frac{n}{3}}$ from $x_{1}$. If we let $x_{1}$ be $s$, any oblivious algorithm needs $\Omega (n^{2})$ time to reach $t$.



\end{proof}





\bibliographystyle{plain}
\bibliography{convobl}
\end{document}
