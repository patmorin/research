\documentclass[lotsofwhite]{patmorin}
\usepackage{amsthm}
\usepackage[noend]{algorithmic}

\input{pat}

\title{\MakeUppercase{Removing Outliers to Minimize Area and Perimeter}}
\author{Rossen Atanassov \and
    Pat Morin \and
    Stefanie Wuhrer}
\date{}

\newcommand{\ch}{\mathrm{CH}}

\newcommand{\ntypes}{C_c}
\newcommand{\timepertype}{c^2 n\log n}
\newcommand{\runtime}{\ntypes \timepertype}

\begin{document}

\maketitle

\begin{abstract}
We consider the problem of removing $c$ points from a set $S$ of $n$
points so that the resulting point set has the smallest possible
convex hull.  Our main result is an $O(\runtime)$ time algorithm
that solves this problem when ``smallest'' is taken to mean least area
or least perimeter. Here $C_r = {2r\choose r}/(r+1)$ is
the $r$th \emph{Catalan number}.
\end{abstract}

\section{Introduction}

Motivated by the problem of removing outliers in a data set, this
paper considers the following problem: Let $S$ be a set of $n$ points
in $\mathbb{R}^2$ with convex hull denoted by $\ch(S)$.  We consider
the problem of selecting a subset $S'\subset S$, $|S'|=c$ such that
the area, or perimeter, of $\ch(S\setminus S')$ is minimum.  We call
these problems the \emph{area-based}, respectively,
\emph{perimeter-based}, \emph{outlier removal problems}.  We are
particularly interested in the case when $c$ (the number of outliers)
is small.

\paragraph{Previous Work.} 

The outlier removal problems stated above and similar problems are
fairly well-studied problems in computational geometry.  However, most
work thus far has focused on the case when $c$ is large. More
specifically, most research has been on the problem of finding a $k$
point subset (a $k$-cluster) $X\subseteq S$, $|X|=k$, such that
$\ch(X)$ has minimum area or perimeter. These are the same problems
studied in this paper except that $k=n-c$ and most existing research
has focused on designing efficient algorithms for small values of $k$.

The problem of finding a subset of $S$ of size $k$ that has the least
perimeter convex hull was first considered over 20 years ago by Dobkin
\etal\ \cite{ddg83} who gave an $O(k^2n\log n + k^5 n)$ time
algorithm.  This algorithm can be improved to run in $O(k^2 n\log n +
k^4 n)$ time using techniques of Aggarwal \etal\ \cite{aiks89}.  Both
algorithms are based on the fact that the $k$ points that define the
solution are a subset of the $k'$ points that define some cell in the
order $k'$ \voronoi\ diagram, where $k'=\ceil{\pi (k-1)}$.  This
allows the problem to be solved by considering $O(k'n)$ subproblems
each of size $k'$.

The problem of finding a subset of $S$ of size $k$ that has the
minimum area convex hull was considered by Eppstein \etal\
\cite{eorw92} and later by Eppstein \cite{e93} who give $O(kn^{3})$
and $O((k^3+\log n) n^2)$ time algorithms for this problem,
respectively.  The second algorithm (by Eppstein) uses the first
algorithm along with the fact that the $k$ points that define the
solution are ``close to'' one of the $n\choose 2$ line segments
defined by pairs of points in $S$.  This allows the problem to be
solved by considering $O(n^2)$ subproblems each of size $O(k)$.

Note that finding a subset $X\subset S$ of size $k$ whose convex hull has
minimum area generalizes the problem of determining if $S$ contains $k$
collinear points.  For the case $k=3$, this problem is one of the original
\textsc{3-Sum}-hard problems \cite{X} and is conjectured to have an
$\Omega(n^2)$ lower-bound in most models of computation.

\paragraph{New Results.}

For fixed values of $k$, the results above give $O(n\log n)$ and
$O(n^2)$ time algorithms for finding the $k$ point subset of $S$ with
minimum perimeter, respectively, area, convex hull.  However, when $k$
is close to $n$ the above algorithms require $\Omega(n^3)$ time.  In
this paper we consider the case when $k=n-c$ and show that
perimeter-based and area-based outlier removal problems can be solved
in $O(\runtime)$ time.  Here, $C_r={2r \choose r}/(r+1)$ is the famous
$r$th Catalan number.  Thus, for any fixed $c$, both problems can be
solved in $O(n\log n)$ time.

The remainder of the paper is organized as follows: \ldots

\section{Preliminaries}

The \emph{convex layers} $S_0,\ldots,S_k$ of $S$ are defined as
follows: $S_0$ is the subset of $S$ on the boundary of $\ch(S)$.
$S_i$, for $i\ge 1$ is the subset of $S$ on the boundary of
$\ch(S\setminus\bigcup_{j=0}^{i-1} S_j)$.  The convex layers of $S$
can be computed in $O(n\log n)$ time in several different ways
\cite{X,Y,Z} or, more simply, the first $c$ convex layers can be
computed in $O(cn\log n)$ time by repeated applications of any
$O(n\log n)$ time convex hull algorithm.  For the remainder of this
paper we will use the notation $p_{i,j}$ to denote the $(j\bmod
|S_i|)$th point of $S_i$.

Consider a point $p_{0,j}\in S_0$.  If we remove $p_{0,j}$ from $S$
then the boundary of $\ch(S\setminus\{p_{0,j}\})$ can be obtained
either by computing two tangents joining $p_{0,j-1}$ and $p_{0,j+1}$
to $S_1$ (when the triangle $\triangle p_{0,j-1}p_{0,j}p_{0,j+1}$ has
points of $S$ in its interior) or by joining $p_{0,j-1}$ and
$p_{0,j+1}$ (when the triangle $\triangle p_{0,j-1}p_{0,j}p_{0,j+1}$
is empty of points from $S$.  If $S_1$ is stored in an array then
computing the necessary tangents and deciding which of the two cases
applies can be done in $O(\log n)$ time \cite{X}.  Once we have done
this, we can update the area (or perimeter) of
$\ch(S\setminus\{p_{0,j}\})$ in $O(t_j)$ time, where $t_j$ is the
number of points of $S_1$ on the boundary of
$\ch(S\setminus\{p_{0,j}\})$. 

\section{The Algorithm}

In this section we present our algorithms for solving the
perimeter-based and area-based outlier removal problems. Our solution
to both problems is to enumerate all the combinatorial types of
solutions of size $c$.  For each such solution type, we then use a
combination of divide-and-conquer and dynamic programming to find the
optimal solution of that particular solution type.  Before we present
the general algorithm, it will be helpful to discuss the special cases
$c=1$ and $c=2$ to illustrate the principles involved.

\subsection{Removing 1 Outlier}

The case $c=1$ asks us to remove 1 point of $S$ so that the convex
hull of the resulting set is minimum.  This can be solved as follows:
We compute the two convex layers $S_0$ and $S_1$ in $O(n\log n)$ time.
We then determine, for each point $p_{0,j}\in S_0$ the difference in
area between $\ch(S)$ and $\ch(S\setminus\{p_{0,j}\})$.  To do this we
compute the new vertices $p_{1,k},\ldots,p_{1,\ell}$ of $S_1$ that
appear on the boundary of $\ch(S\setminus\{p_{0,j}\})$ when we delete
$p_{0,j}$.  We then compute the area of
$\ch(\{p_{0,j-1},p_{0,j+1}\}\cup\{p_{1,k},\ldots,p_{1,\ell}\})$ and
subtract this value from the area of the triangle
$p_{0,j-1}p_{0,j}p_{0,j+1}$.   This process takes $O(t_j+\log n)$
time, where $t_j=|\{p_{1,k},\ldots,p_{1,\ell}\}|$.

To analyze the overall running time of this algorithm we observe that
any point $p_{1,k}\in S_1$ appears in at most two triangles
$p_{0,j-1},p_{0,j},p_{0,j+1}$ and
$p_{0,j},p_{0,j+1},p_{0,j+2}$.  Stated another way,
\[
     \sum_{j=0}^{|S_0|-1} t_j \le 2|S_1|\le 2n \enspace .
\]
Thus, the overall running time of this algorithm is
\[
     T(n) = O(n\log n)+\sum_{j=0}^{|S_0|-1} O(t_j+\log n) = O(n\log n) \enspace ,
\]
as claimed.

\subsection{Removing 2 Outliers}

Next we consider the case $c=2$.  In this case, the optimal solution
$S'$ is of one of three following forms:

\begin{enumerate}
\item $S'$ contains two consecutive points of $S_0$.
\item $S'$ contains two non-consecutive points of $S_0$.
\item $S'$ contains one point of $S_0$ and one point of $S_1$.
\end{enumerate}

The solutions of Type~1 can be found in much the same way as the
algorithm for the case $c=1$.  For each $j\in\{0,\ldots,|S_0|-1\}$ we
compute the difference in area between $\ch(S)$ and
$\ch(S\setminus\{p_{0,j},p_{0,j+1}\})$.  The analysis remains exactly
the same as before except that, now, each point of $S_1$ can appear at
most $3$ times, instead of only 2.  Thus, all solutions of Type~1 can
be evaluated in $O(n\log n)$ time.

The solutions of Type~3 can also be found in a similar way.  For each
$p_{0,j}\in S_0$ we remove $p_{0,j}$ to expose a sequence
$p_{1,k},\ldots,p_{1,\ell}$ of $S_1$ and compute the area of
$\ch(S\setminus\{p_{0,j}\})$.  We then remove each of
$p_{1,k},\ldots,p_{1,\ell}$ in turn (exposing a chain of points from
$S_2$) and compute the area of the resulting convex hull.  To analyze
the cost of all these, we observe that each point $p_{1,j}\in S_1$
appears in at most 2 subproblems because there are at most 2 points in
$S_0$ whose removal causes $p_{1,j}$ to appear on the convex hull.
Similarly, for each point $p_{2,j}\in S_2$ there are at most 2 points
of $S_1$ whose removal causes $p_{2,j}$ to appear on the convex hull.
Thus, each point in $S_1$ appears in at most 2 subproblems and each
point in $S_2$ appears in at most $4$ subproblems.  The overall
running time of this algorithm is therefore bounded by
\[
    O\left(n\log n + |S_0|\log n + 2|S_1|\log n + 4|S_2|\right) = O(n\log n) \enspace ,
\]
as required.

Finally, we consider solutions of Type~2.  To find these we compute,
for each $p_{0,j}\in S_0$ the difference $x_j$ between the area of
$\ch(S\setminus\{p_{0,j}\})$ and $\ch(S)$ using the technique
described for the case $c=1$.  In this way, we reduce the problem to
that of finding two indices $0\le j_1,j_2< |S_0|$ with $j_2\ge j_1+2$
such that $x_{j_1}+x_{j_2}$ is maximum.  We do this by computing the
following quantity
\[
     S_j = \max\{x_{j_1}+x_{j_2} :
       \mbox{$0\le j_1,j_2\le j$ and $j_1 < j_2-1$}\} \enspace ,
\]
that can be computed in $O(|S_0|)$ time using the recurrence
\[
    S_j = \max\{S_{j-1}, x_{j} + \max\{x_{0},\ldots,x_{j-2}\}\}
                \enspace .
\]

Since the best solution of each of the three types can be found in
$O(n\log n)$ time we can find the overall best solution in $O(n\log
n)$ time by keeping the best of the three.

\subsection{Removing $\mathbf{c}$ Outliers}

The solution for the case $c=2$ illustrates all of the ideas used in 
our algorithm.  We begin by enumerating the combinatorial types of
solutions and then compute the best solution of each type.  The
algorithm for computing the best solution of each type is a
divide-and-conquer algorithm whose merge step is accomplished by
solving a dynamic programming problem (as in the Type~2 solutions
described above).

For ease of exposition (to avoid treating $S_0$ as a special case), we
will assume that the optimal solution does not contain both $S_{0,-1}$
and $S_{0,0}$.  Note that this can be enforced by running the
algorithm at most $c$ times, shifting the numerical labelling of the
points on $S_0$ by one.

\subsubsection{The Types of Solutions}

Here we give a mapping between the different types of solutions and
labeled binary trees. We represent the type of a solution as a binary
tree in which each node is labeled with a positive integer and the
sums of all node labels is $c$.  We call such labelled binary trees
\emph{solution trees}. 

The nodes on the rightmost path of a solution tree give the sizes of
consecutive groups of nodes that are removed from $S_0$, where each
group is seperated by at least one element of $S_0$.  Denote the
$m \leq c$ consecutive groups of nodes that are removed from $S_i$ in
arbitrary order by $G_i^1, \dots, G_i^m$. For each consecutive group
$G_0^j$ of nodes that is removed from $S_0$, let $p_{1,k}, \ldots,
p_{1,l}$ denote the vertices on $S_1$ that appear on the boundary of
$CH(S \setminus G_0^j)$. In the binary tree, the rightmost path of the
left subtree of the node representing $G_0^j$ contains nodes
representing the sizes of consecutive groups of nodes that are removed
from the chain $p_{1,k}, \ldots, p_{1,l}$ of $S_1$. This process is
repeated recursively: For each consecutive group $G_i^j$ of nodes that
are removed from $S_i$, let $p_{i+1,k}, \ldots, p_{i+1,l}$ denote the
vertices on $S_{i+1}$ that appear on the boundary of $CH(S \setminus
G_i^j)$. In the binary tree, the rightmost path of the left subtree of
the node representing $G_i^j$ contains nodes representing the sizes of
consecutive groups of nodes that are removed from the chain
$p_{i+1,k}, \ldots, p_{i+1,l}$ of $S_{i+1}$.  An illustration of this
labeling scheme is given in \figref{XXX} (I can do a figure here).

\comment{Note that the mapping between different types of solutions
and labeled binary search trees is not bijective, because for one type
of solutions, there are many labeled binary search trees that
represent that solution. The reason is that the ordering along the
rightmost path of the tree (and recursively, the orderings along the
rightmost paths of all subtrees) is not uniquely defined.  }


\begin{lem}
The number of ordered binary trees with positive integer labels whose
sum does not exceed $c$ is at most $X(c)$.
\end{lem}

\begin{proof}
X.
\end{proof}

\subsubsection{Computing the Solution of a Specific Type}

Here we show how, given the exact combinatorial type of the solution
the optimal solution of that type is computed. More precisely, the
algorithm takes as input a solution tree $T$ as described in the
previous subsection and outputs the optimal solution whose form is
that of $T$.

The algorithm is recursive and operates on a subchain
$p_{i,j},\ldots,p_{i,k}$ of $S_i$ along with a solution tree $T$.  The
algorithm requires that some subset of $\bigcup_{j=0}^{i-1}S_i$ has
already been removed from $S$ so that $p_{i,j},\ldots,p_{i,k}$ are on
the boundary of the convex hull of the current point set.  The
algorithm finds an optimal solution of type $T$ such that the only
points removed from the convex hull of the current point set are in
$p_{i,j},\ldots,p_{i,k}$.

If $d$ is the number of nodes on the rightmost path of $T$, then the
algorithm accomplishes its task by recursively solving $O(d(k-j+1))$
subproblems on the left children of these $d$ nodes and then combining
these solutions using dynamic programming.  The following pseudocode
gives a detailed description of the algorithm's operation with the
exception of the dynamic programming component, which is discussed in
the next subsection.

\newcommand{\lbl}{\mathrm{label}}
\newcommand{\lft}{\mathrm{left}}
\newcommand{\rt}{\mathrm{root}}
\newcommand{\RETURN}[1]{\STATE{\textbf{return} #1}}

\noindent$\textsc{FindOptimalOfType}(T,i,j,k)$
\begin{algorithmic}[1]
\IF{$T$ is empty}
  \RETURN{0}
\ENDIF
\STATE{$d\gets$ the number of nodes on the rightmost path of $T$}
\FOR{$g=1$ to $d$}
  \STATE{$N\gets g$th node on the rightmost path of $T$}
  \STATE{$c_g=\lbl(N)$}
  \FOR{$\ell=j$ to $k-c_g$}
    \STATE{delete $S_{i,\ell},\ldots,S_{i,\ell+c_g-1}$ from $S_{i}$
           exposing $S_{i+1,j'},\ldots,S_{i+1,k'}$ on $S_{i+1}$}
    \STATE{$s\gets$ reduction in area (perimeter) obtained by the deletion of
           $S_{i,\ell},\ldots,S_{i,\ell+c_g-1}$} 
    \STATE{$X_{g,\ell-j}\gets s +
            \textsc{FindOptimalOfType}(\lft(N),i+1,j',k')$}
    \STATE{reinsert $S_{i,\ell},\ldots,S_{i,\ell+c_g-1}$ into $S_{i}$}
  \ENDFOR
\ENDFOR
\RETURN{$\textsc{CombineSolutions}(X,d,k-g)$}
\end{algorithmic}

The call to $\textsc{CombineSolutions}$ in the last line of the
algorithm is a dynamic programming subroutine described in the next
section that runs in $O(d(k-g))$ time.  At the topmost level, the
algorithm is used as follows:

\noindent$\textsc{FindOptimalOfType}(T,c)$
\begin{algorithmic}[1]
\STATE{$m\gets 0$}
\FOR{$j=0$ to $c$}
  \STATE{$m\gets \max\{m,\textsc{FindOptimalOfType}(T,0,j, j-1)\}$}
\ENDFOR
\RETURN{$m$}
\end{algorithmic}

To analyze the cost of \textsc{FindOptimalOfType} it suffices to
determine, for each point $p_{i,j}$, the maximum number of times
$p_{i,j}$ is deleted (in line 8) by the algorithm.  Observe that, for
points $p_{0,j}\in S$, each point is deleted exactly $cg_0$, times,
where $g_0$ is the sum of labels of nodes on the rightmost path of
$T$. 

More generally, let $g_i$ denote the sum of labels of all nodes $N$ of
$T$ for which the path from the root of $T$ to $N$ make exactly $i$
left turns.  Consider some point $p_{i,j}\in S_i$, for $i\ge 1$.  By
Carath\'eodory's Theorem \cite{chapter}, each such point is contained
in some triangle $\Delta_{i,j}=\triangle
p_{i-1,\ell_1},p_{i-1,\ell_2},p_{i-1,\ell_3}$. If $p_{i,j}$ is deleted
by \textsc{FindOptimalOfType} then it is on the boundary of the convex
hull of the current point set.  However, this implies that at least
one of the three vertices of $\Delta_{i,j}$ must be deleted from the
current point set.  Thus, if we define $m_i$ as the maximum number of
times a point of $S_i$ is deleted by \textsc{FindOptimalOfType} then
we have the relationships:
\[ m_0 \le cg_0 \] 
and 
\[ m_i \le 3 m_{i-1} g_i \enspace .\]
Using the fact that $g_i \le c$ and no point of $S_{i}$ for $i> c$ is
ever considered by the algorithm, we obtain the (extremly loose) upper
bound $m_i < (3c)^{c+1}$.


\subsubsection{Combining the Solutions}

Here we show how to combine the solutions by using dynamic programming
to solve the following problem:

Given positive integers $c_1,\ldots,c_d$ and a $d\times m$ positive
real-valued matrix $X$
we want to find indices $1\le i_1,\ldots,i_d \le m-c_d$ such that
\[
    i_j + c_j \le i_{j+1}
\]
for all $1\le j < d$ and such that
\[
      h(i_1,\ldots,i_d)=\sum_{j=1}^d X_{j,i_j}
\]
is maximum.  We solve this by filling out the table:
\[
     D_{j,\ell} = \max\{h(i_1,\ldots,i_j):
      \mbox{$1\le i_1$, $i_j\le \ell$, and $i_{j'}+c_{j'}\le i_{j'+1}$
             for all $1\le j'< j$}  \} \enspace .
\]
for $j=1,\ldots,d$ and $\ell=1,\ldots,m-c_d$.  We can do this in
$O(cn)$ time because the table entries satisfy the recurrence
\[
     D_{j,\ell} = \max\{D_{j,\ell-1},D_{j-1,\ell-c_{j-1}}+X_j \}
\]
where we use the convention that $D_{j,\ell} = 0$ if $j\le 0$ or
$\ell\le 0$.


\section{Conclusions}

The running times of our algorithms depend exponentially on the value
of $c$.  Is it possible to find algorithm that are polynomial in $c$
but that still run in $O(n\log n)$ time for fixed values of $c$?

The outlier removal problems we study in this paper are two special
cases of the following \emph{general outlier removal} problem.  Given
any function $f$ that maps subsets of $\mathbb{R}^2$ onto $\mathbb{R}$
we want to find, for a given set $S$ of $n$ points in $\mathbb{R}^2$ a
subset $S'\subset S$ of size $c$ such that $f(S\setminus S')$ is
minimum.  Functions $f$ of particular interest include:
\begin{enumerate}
\item $f(X)$ is the radius of the smallest disk contain $X$,
\item $f(X)$ is the diameter of $X$ ($f(X)=\max\{\|ab\|:a,b\in X\}$), and
\item $f(X)$ is the variance of $X$ ($f(X)=\sum_{a\in X} \| am \|^2$
where $m=\sum_{a\in X} a/|X|$.
\end{enumerate}
For the first two functions, it is easy to obtain $O(3^c n)$ and
$O(2^cn\log n)$ time algorithms, respectively, using the fact that the
smallest enclosing disk and the diameter are defined by at most 3,
respectively, 2, points of $S$.  Are there are algorithms for these
problems whose running time depends only polynomially on $c$?


\end{document}
