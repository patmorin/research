\documentclass{patmorin}
\usepackage{amsthm,amsmath,graphicx,stmaryrd}
\usepackage{pat}

\DeclareMathOperator{\erf}{erf}
\DeclareMathOperator{\area}{area}
\newcommand{\eps}{\varepsilon}

\title{\MakeUppercase{On the Average Number of Edges in a Theta Graph}}
\author{Pat Morin,\thanks{School of Computer Science, Carleton University}\,\,
         and Sander Verdonschot\footnotemark[1]}



\begin{document}
\maketitle

\begin{abstract}
  The abstract goes here.
\end{abstract}

\section{Introduction}

Theta graphs \cite{keil.gutwin:classes} and Yao graphs \cite{yao:blah}
are important geometric structures that have applications in networking,
and data structures.  These graphs are defined on a planar point set,
$S$ with an integer parameter $k$.  For each $i\in\{1,\ldots, k\}$,
define the cone
\[ 
   C_i=\{u\in \R^2: \angle qou\in [2\pi(i-1)/k,2\pi i/k) \enspace ,
\]
where $q=(1,0)$ and $o=(0,0)$.  In Theta and Yao graphs, each point $u\in
S$ has an edge connecting it to the nearest point, if any, in the cone
$C_i+u$, for each $i\in\{1,\ldots,k\}$. Where these graphs differ is in
their definition of ``nearest''; The Yao graph connects $u$ to the point
in $C_i+u$ that minimizes the Euclidean distance to $u$.  The theta graph
connects $u$ to the point whose orthogonal projection on the axis of $u$
is closest to $u$.  See \figref{theta-vs-yao}. The resulting undirected
graphs are called, the $\theta_k$-graph of $S$, denoted $\theta_k(S)$,
and the $Y_k$-graph, denoted $Y_k(S)$, respectively.

\begin{figure}
  \begin{center}
    \begin{tabular}{cc}
     \includegraphics{theta} & \includegraphics{yao} \\
     $\theta_7$ & $Y_7$
    \end{tabular}
  \end{center}
  \caption{Each vertex in a theta- or Yao-graph connects to the ``nearest''
   point in each cone.}
  \figlabel{theta-vs-yao}
\end{figure}

Theta graphs have two important properties that make them suited for
a wide variety of applications:  They are \emph{sparse}; $\theta_k(S)$
has at most $k|S|$ edges.  They are \emph{spanners}; the length of the
shortest path between any two vertices $u$ and $w$ is at most a constant
(dependant only on $k$ and not on $S$) times the Euclidean distance
between $u$ and $w$.  For any point set, $S$, $\theta_k(S)$ is a spanner
for any $k\ge 4$ \cite{a,b,c,d,e,f} and $Y_k(S)$ is a spanner for $k=4$
and any $k\ge 6$ \cite{a,b,c,d}.

Note that, although $\theta_k(S)$ and $Y_k(S)$ each have at most $k|S|$
edges, they can also have significantly fewer edges.  For example, if
the points of $S$ all lie on a line, then these graphs have only $|S|-1$
edges.  More typical, though, is for these graphs to have somewhere
between $k|S|/2$ and $k|S|$ edges;  each vertex $u\in S$ chooses $k$
edges\footnote{Every vertex in $S$ chooses $k$ edges unless it is near the
``boundary'' of the point set.  More precisely, only the points on the
$(2\pi/k)$-hull \cite{alpha-hull} of $S$ may create fewer than $k$ edges.}
of the graph but sometimes an edge $uw$ is created both by $u$ and $w$.

\subsection{The Model and Results}

In this paper, we study the typical number of edges in $\theta_k$-graphs
and $Y_k$-graphs by studying the average number of edges in two different
models of random point sets.  In the following, and throughout most of
this paper, we focus most of our attention on $\theta_k$-graphs.

We begin by studying (the infinite) $\theta_k$-graphs generate by a
homogeneous Poisson point process with unit intensity over the entire
Euclidean plane.  In this model, we study the average degree of a vertex
in the $\theta$-graph.  For the $\theta_k$-graph, this quantity is at
most $2k$ since each vertex defines $k$ edges of the graph and each edge
has 2 endpoints.  However, in some cases an edge $uw$ is \emph{mutual}
in the sense that the edge is created both by $u$ and by $w$.  If we
let $p_k$ denote the probability that an edge of the $\theta_k$ graph
is is mutual, then the average degree of the $\theta_k$ graph is
\[
    d_k = (2-p_k)k \enspace .
\]
(The second term corrects for the double-counting of mutual edges.)  Thus,
understanding the average degree of a $\theta_k$-graph boils down to
computing $p_k$.

In \secref{even} we show that, for all even integers $k\ge 4$,
\[
    p_k=\frac{\pi\sqrt{3}}{9}\approx 0.6045997883 \enspace .
\]
That is, the probability of an edge being mutual is independent of
$k$. Thus, for all even integers $k\ge 4$, the average degree of a
vertex is
\[
  d_k = \left(2-\frac{\pi\sqrt{3}}{9}\right)k \approx 1.395400212\cdot k \enspace .
\]

In \secref{odd} we show that, for odd values of $k\ge 5$, the situation
is very different.  The mutual edge probability $p_k$ depends on
$k$ in a complicated way that includes trigonometric functions and
square roots.  However, the value of $p_k$ is significantly larger than
$\frac{\pi\sqrt{3}}{9}$ for all odd values of $k$.  Indeed, $p_k$ is a
decreasing function of $k$ and
\[
  p_k\ge \lim_{k\to\infty} p_k = 2\arctan(1/3)\approx 0.6435011088 \enspace .
\]
Thus, for all odd values of $k\ge 5$,
\[
   d_k \le (2-2\arctan(1/3))k \approx 1.356498891 k
\]
Thus, in some sense, odd values of $k$ offer ''more bang for the buck.''

We also study the \emph{i.u.d.\ model}, in which a set, $S$, of $n$
points is independently and uniformly distributed in a square.  In this
model we show that essentially the same bounds hold.  Specifically,
If $m_k$ is the number of edges of $\theta_k(S)$, then
\[
    \E[m_k] \in nd_k/2\pm O(k\sqrt{n\log n}) \enspace \enspace ,
\]
where $d_k$ is the average degree of the $\theta_k$-graph in the Poisson
model.  We also give a concentration result that shows that the number
of edges, $m_k$, is highly concentrated around its expected value.
In particular
\[
    \Pr\{|m_k - nd_k/2| \ge k\sqrt{cn\log n}\} \le n^{-\Omega(c)} \enspace .
\]

\subsection{Related Work}

A plethora of literature exists on theta graphs \cite{S} and
their applications \cite{S}, though most of this work focuses on
worst-case analysis.  One notable exception is the work of Devroye
\etal\ \cite{devroye.gudmundsson.ea:on} who study the maximum degree
of Yao- and theta-graphs and show that, if $S$ is a set of $n$ points
independently and uniformly distributed in a certain unit square, then
$\theta_k(S)$ and $Y_k(S)$ have maximum degree concentrated around
$\Theta((\log n)/\log\log n)$.\footnote{Devroye \etal\ discuss Yao
graphs, although their proofs apply, almost without modification, to
theta graphs.}  In the Poisson model, their result implies that, if we
fix a $\sqrt{n}\times\sqrt{n}$ square and look at the maximum degree of
all vertices contained in this square, then this value is concentrated
around $\Theta((\log n)/\log\log n)$.

In contrast, properties of various other proximity graphs of random
point sets have been studied extensively.  Devroye \etal\ study the
maximum degree of Gabriel graphs \cite{devroye.gudmundsson.ea:on}.
The issue of connectivity and the birth of giant components in the
$r$-disk graph---in which an edge $uw$ is present if and only if the
distance between $u$ and $w$ is at most $r$---has been the subject of
intensive research and there are several books devoted to the topic
\cite{meester.roy:continuum,penrose:random}.


\section{The Poisson Model}

In the Poisson model, the number of points in any region whose
area is $A$ follows a Poisson distribution with parameter $A$.  For
definitions of Poisson processes and distributions see, for example,
Ross \cite[Chapter~2]{ross:introduction}.  For our purposes, the most
important properties of the Poisson process are the following:
\begin{enumerate}
\item The probability  that a particular region $X$ whose area is $A$
   is empty of points is exactly $e^{-A}$.
\item For two disjoint regions $X$ and $Y$, the events ``$X$ is empty
   of points'' and ``$Y$ is empty of points'' are independent.
\end{enumerate}
Our analysis is split into two cases, depending upon whether $k$ is even
or odd.


\subsection{Analysis of $p_k$ for Even $k$}
\seclabel{even}

In this section we determine the value of $p_k$ for even values of $k$.
Surprisingly, the value of $p_k$ in this case does not depend on $k$.

\begin{lem}\lemlabel{even}
 For even integers $k\ge 4$, $p_k=\frac{\pi\sqrt{3}}{9}\approx 0.6045997883$.
\end{lem}

\begin{proof}
  Let $u$ be an arbitrary vertex in a $\theta_k$ graph and let $w$
  be a vertex that $u$ has chosen as a neighbour in one of its cones,
  $C$ ($w$ is the ``closest'' vertex to $u$ in $C$).  Let $T$ be the
  open isosceles triangle defined by $C$ and a line
  through $w$ that is orthogonal to the axis of $C$. See \figref{mutual}.
  Observe that the location of $w$ is uniformly distributed on the
  edge of $T$ opposite $u$;  if this edge has length $\ell$, then $w$
  partitions it into two pieces of length $r$ and $\ell-r$, where $r$
  is uniformly distributed in $[0,\ell]$.

  \begin{figure}
    \centering{\includegraphics{cone}}
    \caption{The edge $uw$ is mutual if and only if $T'\setminus T$ 
       is empty of points.}
    \figlabel{mutual}
  \end{figure}
 
  Let $T'$ be the triangle obtained by reflecting $T$ through the midpoint
  of the edge $uw$ (so that $w$ is a vertex of $T'$). The edge $uw$ is
  mutual if and only if $T'\setminus T$ contains no points.  The area
  of $T'\setminus T$ is
  \[
     A(T'\setminus T) = c(r^2+(\ell-r)^2)  \enspace ,
  \]
  where $\alpha=\alpha(k)$ depends only on $k$.  We now have enough information
  to compute the probability that the edge $uw$ is mutual conditional
  on $\ell$ and $r$:
  \[
    \Pr\{\mbox{$uw$ is mutual} \mid \ell,r\} = \exp(-\alpha(r^2+(\ell-r)^2))
      \enspace .
  \]
  Since $r$ (conditioned on $\ell$) is uniform over $[0,\ell]$, unconditioning
  $r$ gives
  \begin{align*}
    f(\ell) & \equiv \Pr\{\mbox{$uw$ is mutual} \mid \ell\} \\
     & = \int_0^\ell (1/\ell)\exp(-\alpha(r^2+(\ell-r)^2))\,\mathrm{d}r \\
     & = \frac{\sqrt{\pi}}{\ell\sqrt{2\alpha}}
            \cdot\exp(-\alpha\ell^2/2)
            \cdot\erf(\ell\sqrt{\alpha/2})  \enspace ,
%     & = \sqrt{\frac{2\pi}{\sqrt{3}}}\exp(-\sqrt{3}\ell^2/8)
%         \cdot\erf(\sqrt[4]{3}\sqrt{2}\ell/4) \enspace ,
  \end{align*}
  where 
  \[ \erf(x)=\frac{2}{\sqrt{\pi}}\int_0^x e^{-z^2}\,\mathrm{d}z \]
  is the \emph{Gauss error function} \cite{gauss-error}.  

  Next, we remove the conditioning on $\ell$.  The triangle $T$ defines a
  region of area $\alpha\ell^2$ that is empty of points.  Therefore,
  by Property~1 of the Poisson process, the cumulative distribution
  function of $\ell$ is given by
  \[
    P(x) \equiv \Pr\{\ell \le x\} = 1-\exp(-\alpha x^2) \enspace .
  \]
  The probability density function of $\ell$ is therefore given by 
  \[
     p(x) \equiv \frac{d}{dx}P(x) =
     2\alpha x\cdot\exp(-\alpha x^2) \enspace .
  \]
  Finally, we obtain $p_k$ as 
  \begin{align*}
     p_k = \int_0^\infty p(\ell)\cdot f(\ell)\,\mathrm{d}\ell 
     = \frac{\pi\sqrt{3}}{9}
      \approx 0.6045997883  \enspace . & \qedhere
  \end{align*}
\end{proof}

%Thus, for even $k$, the average degree of the $\theta_k$-graph is 
%\[ d_k = \left(2-\frac{\pi\sqrt{3}}{9}\right)k \approx 1.395400212\cdot k \enspace . \]

\subsection{Analysis of $p_k$ for Odd $k$}
\seclabel{odd}

Next, we determine the value of $p_k$ for odd values of
$k\ge 5$.  Although the strategy for doing this is the same as the even
case, the odd case turns out to be considerably more complicated, and
we rely heavily on computer math systems for our calculations.

For the odd case the value of $p_k$ does, indeed depend on $k$.

\begin{lem}\lemlabel{odd}
  For odd $k\ge 5$,
\[
p_k = 
2
\left(\begin{array}{l}
  \arctan\left(
     2\left(\cos\left(\frac{\pi }{k}\right)
       +\cos\left(\frac{3 \pi }{k}\right)\right)^2 / (\alpha\beta) 
  \right) \\
   + \arctan\left(
       4 \left(2 \cos\left(\frac{2 \pi }{k}\right)
       +\sin\left(\frac{2 \pi }{k}\right)^2\right)/(\alpha\beta) 
     \right)
  \end{array}
\right)
%\\
\cot\left(\frac{\pi }{k}\right) 
\beta
%\right)
/
\left(\gamma \alpha\right)\enspace ,
\]
where
\[
\gamma =4+11 \cos\left(\frac{2 \pi }{k}\right)+\cos\left(\frac{6 \pi }{k}\right) \enspace ,
\]
\[
\alpha = 
\sqrt{\frac{\left(27 \cos\left(\frac{\pi }{k}\right)+17 \cos\left(\frac{3 \pi }{k}\right)+3 \cos\left(\frac{5 \pi }{k}\right)+\cos\left(\frac{7 \pi }{k}\right)\right) \csc\left(\frac{\pi }{k}\right)}{\gamma}} \enspace ,
\]
and
\[
\beta = \sqrt{\left(18 \sin\left(\frac{2 \pi }{k}\right)+18 \sin\left(\frac{4 \pi }{k}\right)+11 \sin\left(\frac{6 \pi }{k}\right)+\sin\left(\frac{8 \pi }{k}\right)+\sin\left(\frac{10 \pi }{k}\right)\right)} \enspace .
\]
\end{lem}

\begin{proof}
  The proof proceeds in the same manner as the proof of \lemref{even}.
  Let $u$ be an arbitrary vertex in a $\theta_k$ graph and let $w$ be
  a vertex that $u$ has chosen as a neighbour in one of its cones, $C$.
  Let $T$ be the open isosceles triangle defined by $C$ and a line through
  $w$ that is orthogonal to the axis of $C$. See \figref{mutual-odd}.
  Assume that the side of $T$ opposite $u$ has length $2\ell$.  Using a
  suitable rotation, we may assume that the axis of $C$ is horizontal and,
  by symmetry, we may assume that $w$ is on or above the axis of $C$.
 
  \begin{figure}
    \includegraphics{calcs}
    \caption{The derivation of the $\Pr\{\mbox{$uw$ is mutual}\mid \ell,r\}$
             for odd $k$.}
    \figlabel{mutual-odd}
  \end{figure}
  Under the preceding assumptions, $w$ is then uniformly distributed on
  a vertical segment of length $\ell$ whose endpoints are on the axis
  of $C$ and the upper boundary of $C$.  Suppose that the distance from
  $w$ to the axis of $C$ is $r$.  Then a straightforward, but tedious,
  calculation that mainly uses the law of sines shows that
  \[
      \Pr\{\mbox{$uw$ is mutual}\mid \ell, r\} = \exp(-A-B) \enspace ,
  \]
  where
  \[ 
      A = r^2\left(\frac{\cos(\pi/k)}{2\sin(\pi/k)}+\frac{\sin(\pi/k)}{\cos(\pi/k)}\right)
  \]
  and
  \[
      B = \frac{\left(\frac{\ell\cos(\pi/k)\sin(2\pi/k)}{\sin(3\pi/k)\sin(\pi/k)}-\frac{r\cos(2\pi/k)}{\sin(3\pi/k)}\right)^2\cos(2\pi/k)}{2\cos(\pi/k)}
  \]
  This calculation is illustrated in \figref{mutual-odd} and the
  accompanying worksheet shows the simplifications that lead to the
  expressions for $A$ and $B$.  Integrating over $r$ gives us
  \begin{equation}
    \Pr\{\mbox{$uw$ is mutual}\mid \ell\} = 
      \int_0^\ell (1/\ell)\exp(-A-B)\,\mathrm{d}r . \eqlabel{odd-f}
  \end{equation}
  Like the corresponding integral in the proof of \lemref{even},
  \eqref{odd-f} has a closed-form that includes the Gauss error function.

  In order to remove the conditioning on $\ell$, we need the probability
  density function for $\ell$.  Proceeding as before, we have the
  cumulative distribution function
  \[
     P(x) \equiv \Pr\{\ell\le x\} 
          = 1 - \exp(\ell^2(\sin((\pi-\theta)/2)/\sin(\theta/2))) \enspace ,
  \]
  and the probability density function
  \[
    p(x)\equiv \frac{d}{dx}P(x) = 
     \left(\frac{2x\cos(\pi/k)}{\sin(\pi/k)}\right)
      \exp(x^2\cos(\pi/k)/\sin(\pi/k))
  \]
  Finally, we determine $p_k$ by integrating over $\ell$:
  \[
     p_k = \int_0^\infty p(\ell)\cdot f(\ell)\, \mathrm{d}{\ell} \enspace ,
  \]
  which (after introducing the variables $\alpha$, $\beta$, and $\gamma$)
  yields the expression for $p_k$ given in the statement of the lemma.
\end{proof}

\section{Points in a Unit Square}

Next we argue that results similar to Lemmas~\ref{lem:even} and
\ref{lem:odd}, albeit with lower-order error terms, hold for the
graph $\theta_k(S)$, where $S$ is a set of $n$ points independently
and uniformly distributed in the square $[0,\sqrt{n}]^2$ of area $n$.
Observe that, in this model, the probability that any particular region
of area $A$ contained in $[0,\sqrt{n}]^2$ is empty of points is exactly
$(1-A/n)^n=\exp(-A)-O(1/n)$.  This is consistent with the Poisson model
up to an additive error of $O(1/n)$.

The primary work in this section involves finding values that look
like those in the previous section, but have an additive lower-order
error term.  We will use the notation $x= y\pm a$ denotes that $x$ is
some value in the interval $[y-a,y+a]$.  We will abuse this notation
slightly by writing equations of the form $x\pm a = y\pm b$ when
$[x-a,x+a]\subseteq[y-a,y+a]$.

We will sometimes encounter expressions like $A/(1-x)$, with $0<x<1/2$
which we bound by
\[
   A/(1-x) = A+O(A/x) \enspace .
\]

We will also frequently encouter expressions like $(1-A/n)^{n-c}$, where
$c$ is a constant and $A < n/2$.  We will always bound these as follows:
\begin{align*}
   (1-A/n)^{n-c} 
      & = \frac{(1-A/n)^n}{(1-A/n)^c} \\
      & = \frac{\exp(-A)-O(A/n)}{(1-A/n)^c} \\
      & = \frac{\exp(-A)-O(A/n)}{\sum_{i=0}^c \binom{c}{i}(-A/n)^i} \\
      & = \frac{\exp(-A)-O(A/n)}{1-O(A/n)} \\
      & = (\exp(-A)-O(A/n))(1+O(A/n)) \\
      & \ge \exp(-A) - O(A/n) 
\end{align*}
and, similarly, 
\begin{align*}
   (1-A/n)^{n-c} 
      & = \frac{(1-A/n)^n}{(1-A/n)^c} \\
      & \le \frac{\exp(-A)}{(1-A/n)^c} \\
      & = \exp(-A)(1+O(A/n))  \enspace .
\end{align*}


\subsection{Expected Number of Edges}

In this section, we analyze the expected number of edges of $\theta_k(S)$.
For each point $u\in S$ and each $i\in\{1,\ldots,k\}$, let $e(u,i)$ be
the edge (if any) that $u$ creates in its $i$th cone.  We partition
$[0,\sqrt{n}]^2$ into a a \emph{core}, $C=[2t,\sqrt{n}-2t]^2$,
where $t=\sqrt{ck\log n}$, and a \emph{near-boundary},
$\bar{C}=[0,\sqrt{n}]^2\setminus C$ (see \figref{empty}).

\begin{figure}
  \begin{center}
    \includegraphics{empty}
  \end{center}
  \caption{The support, $[0,\sqrt{n}]^2$, is partitioned into a core, $C$,
    and a near-boundary $\bar{C}$.  A point $u$ in the core almost surely
    has a neighbour in every cone, otherwise $u$ is incident on large
    triangle, $T\subset [0,\sqrt{n}]^2$, that is empty of points.}
  \figlabel{empty}
\end{figure}

The motivation for partitioning into a core and near-boundary is that
(1)~there are not many points in the near-boundary and (2)~points
in the core behave almost exactly like points in the Poisson model.
The following Lemma shows, for example, that points in the core nearly
always have a neighbour in each of their cones.

\newcommand{\eui}{\mathcal{E}_{u,i}}

\begin{lem}\lemlabel{exists}
  For any $u\in S$ and any $i\in\{1,\ldots,k\}$, let $\eui$ denote
  the event ``$e(u,i)$ exists and has height $\ell\le t$.''  Then
  $\Pr\{\eui\mid u\in C\} \ge 1-n^{-\Omega(c)}$.
\end{lem}

\begin{proof}
  Fix some location of $u\in C$ and draw an open isosceles triangle,
  $T$, with apex $u$, whose internal angle at $u$ is $\theta=2\pi/k$
  and whose height is $t$ (see \figref{empty}).  Observe that, since $u$
  is in the core, $T\subset [0,\sqrt{n}]^2$.  Furthermore, the area of $T$
  is 
  \[ 
     A = t^2\sin(\theta/2)/\sin((\pi-\theta)/2)\in \Theta(t^2/k) = \Theta(c\log n) \enspace .
  \]
  Thus, we immediately have
  \begin{align*}
    \Pr\{T\cap S=\emptyset\mid u\in C\} 
       & = (1-A/n)^{n-1} \\
       & \le \exp(-A)(1+O(A/n)) \\
       & \le 2\exp(-A) & \text{(for sufficiently large $n$)}\\
       & = 2\exp(-\Theta(c\log n)) \\
       & = n^{-\Omega(c)} \enspace .
  \end{align*}
  If $\eui$ does not occur, this means that the event described above
  has occured.  Therefore, $\Pr\{\eui\mid u\in C\}\ge 1-n^{-\Omega(c)}$,
  as required.
\end{proof}

\newcommand{\mui}{\mathcal{M}_{u,i}}

Our next lemma shows that edges generated by points in the core have
essentially the same probability of being mutual as they do in the
Poisson model.

\begin{lem}\lemlabel{pk}
    For any $u\in S$ and any $i\in\{1,\ldots,k\}$, let $\mui$ denote the
    event ``$\eui$ and $e(u,i)$ is mutual.'' Then $\Pr\{\mui\mid u\in C\}
    = p_k\pm O((\log n)^2/n)$.
\end{lem}

\begin{proof}
Throughout this proof, all probabilities we compute are conditional on
$u\in C$, even when this is not explicitly stated.  The proof is basically
a reproving of Lemmas~\ref{lem:even} and \ref{lem:odd} that takes care to
deal with boundary effects.  Here, we will prove the case for even $k$
(\lemref{even}) only.  The case for odd $k$ (\lemref{odd}) can be done
the same way.

We first compute the probability conditional on $\eui$ and for fixed
values of $\ell$ and $r$ as described in the proof of \lemref{even}
and illustrated in \figref{mutual}.  The notations $\ell$, $r$, $T$,
and $T'$ all have the same meaning as in the proof of \lemref{even}.
The edge $e(u,i)$ is mutual if and only if the remaining $n-2$ points
in $S\setminus\{u,w\}$---which are already conditioned on not being in
$T$---also fall outside of $T'$.  The probability that this happens is
\begin{align*}
   \Pr\{\mui\mid\eui,\,\ell,\, r\}
        & = \left(\frac{1-\area(T\cup T')/n}{1-\area(T)/n}\right)^{n-2} \\
        & = \left(1-\frac{\area(T\setminus T')/n}{1-\area(T)/n}\right)^{n-2} \\
        & = \left(1-\frac{\alpha(r^2+(\ell-r)^2)/n)}
                       {1-\alpha\ell^2/n}\right)^{n-2} \\
        & = \exp(-\alpha(r^2+(\ell-r)^2)) \pm O(\alpha\ell^2/n) \\
        & = \exp(-\alpha(r^2+(\ell-r)^2)) \pm O(\alpha t^2/n)
\end{align*}
We then remove the conditioning on $r$ by integrating:
\begin{align*}
   f'(\ell) \equiv & \Pr\{\mui\mid\eui,\,\ell\} \\
     & = \int_0^\ell(1/\ell)\left(\exp(-\alpha(r^2+(\ell-r)^2)) 
           \pm O(\alpha t^2/n)\right)\,\mathrm{d}r \\
     & = f(\ell) \pm O(\alpha t^2/n) \enspace ,
\end{align*}
where $f(\ell)$ is the same $f(\ell)$ defined in the proof of \lemref{even}.

To finish, we need the distribution function for $\ell$ conditional on
$\eui$.  The triangle $T$ has area $\alpha\ell^2$ so the probability that
it is empty of points of $S\setminus\{u\}$ is $(1-\alpha\ell^2/n)^{n-1}$.
Therefore, for $0\le x\le t$, we have the cumulative distribution function
\begin{align*}
   P(x) & \equiv \Pr\{\ell \le x\mid \eui\}  \\
      & = \frac{\Pr\{\eui\mbox{ and }\ell\le x\}}
               {\Pr\{\eui\}} \\
      & = \frac{\Pr\{\ell\le x\}}  
               {\Pr\{\eui\}} & \text{(since $0\le x\le t$, so $\ell \le x$ implies $\eui$)} \\
      & = \frac{1-(1-\alpha x^2/n)^{n-1}}{1-(1-\alpha t^2/n)^{n-1}} 
\end{align*}
From this we obtain the density function
\begin{align*}
  p'(x) & \equiv \frac{d}{dx}P(x) \\
        & = \frac{d}{dx}
             \frac{1-(1-\alpha x^2/n)^{n-1}}{1-(1-\alpha t^2/n)^{n-1}} \\
        & = \frac{2\alpha x(n-1)(1-\alpha x^2/n)^{n-2}}
                  {n(1-(1-\alpha t^2/n)^{n-1})} \\
        & = \frac{2\alpha x(n-1)(\exp(-\alpha x^2)\pm O(\alpha x^2/n))}
                  {n(1-n^{-\Omega(c)})} \\
        & = \frac{2\alpha x(n-1)(\exp(-\alpha x^2)\pm O(\alpha x^2/n))}
                  {n-n^{-\Omega(c)}} \\
        & = \frac{2\alpha xn(\exp(-\alpha x^2)\pm O(\alpha x^2/n))}
                  {n-n^{-\Omega(c)}}(1-1/n) \\
        & = \frac{2\alpha x(\exp(-\alpha x^2)\pm O(\alpha x^2/n))}
                  {1-n^{-\Omega(c)}}(1-1/n) \\
        & = 2\alpha x\left(\exp(-\alpha x^2)\pm O(\alpha x^2/n)\right)
                  (1+n^{-\Omega(c)})(1-1/n) \\
        & = 2\alpha x\left(\exp(-\alpha x^2)\pm O((1+\alpha x^2)/n)\right) \\
        & = 2\alpha x\exp(-\alpha x^2)\pm O((1+\alpha x^3)/n) \\
        & = 2\alpha x\exp(-\alpha x^2)\pm O(\alpha^2 t^3/n) \\
        & = p(x)\pm O(\alpha^2 t^3/n) ,
\end{align*}
where $p(x)$ is the same $p(x)$ that appears in the proof of \lemref{even}.
And now we have enough information to finish:
\begin{align*}
    \Pr\{\mui \mid u\in C\} 
         & \ge \Pr\{\eui\mid u\in C\}\cdot \Pr\{\mui\mid \eui\} \\
         & \ge (1-n^{-\Omega(c)})\cdot \Pr\{\mui\mid \eui\} \\
         & = (1-n^{-\Omega(c)})\cdot\int_0^t p'(\ell)f'(\ell)\,\mathrm{d}\ell \\
         & = (1-n^{-\Omega(c)})\int_0^t (p(\ell)\pm O(\alpha^2t^3/n))\cdot(f(\ell)\pm O(\alpha t^2/n))\,\mathrm{d}{\ell} \\
         & = (1-n^{-\Omega(c)})\int_0^t p(\ell)f(\ell)
           \pm O(p(\ell)\alpha t^2/n + f(\ell)\alpha^2t^3/n + \alpha^3t^5/n^2)
            \,\mathrm{d}{\ell} \\
        & = \frac{\pi\sqrt{3}}{9} \pm O(\alpha t^2/n + \alpha^2t^4/n + \alpha^3t^6/n^2) \\
        & =  \frac{\pi\sqrt{3}}{9} \pm O((\log n)^2/n)
\end{align*}
and
\begin{align*}
    \Pr\{\mui \mid u\in C\} 
       & \le \Pr\{\eui\mid u\in C\}\cdot \Pr\{\mui\mid \eui\}
           + (1-\Pr\{\eui\}) \\
       & \le \Pr\{\eui\mid u\in C\}\cdot \Pr\{\mui\mid \eui\} 
           + n^{-\Omega(c)} \\
         & = \frac{\pi\sqrt{3}}{9} \pm O((\log n)^2/n) \enspace . \qedhere
\end{align*} 
\end{proof}

\begin{lem}
 Let $S$ be a set of $n$ points independently and uniformly distributed
 in $[0,1]^2$.  Then the expected number of edges of $\theta_k(S)$ is 
 $nd_k/2\pm O(k\sqrt{nk\log n})$.
\end{lem}

\begin{proof}
  Let $E$ denote the number of (undirected) edges, $D$
  the number of directed edges, and $M$ the number of mutual directed edges
  of $\theta_k(S)$.   Then we have
  \[  
     E = D - M/2 \enspace . 
  \]
  Let $E_C$, $D_C$, and $M_C$ denote the same quantities but only
  counting those edges with at least one endpoint in the core.
  We begin with a lower bound:
  \begin{align*}
   \E[E] & \ge \E[E_C] \\
         & = \E[D_C] - \E[M_C]/2 \\
         & = \sum_{u\in S}\sum_{i=1}^k\Pr\{u\in C\}
              \left(\Pr\{\eui\mid u\in C\}
                - \Pr\{\mui\mid u\in C\}/2 \right) \\
        & = k(\sqrt{n}-4t)^2
              \left(\Pr\{\eui\mid u\in C\}
                - \Pr\{\mui\mid u\in C\}/2 \right) \\
        & \ge k(\sqrt{n}-4t)^2
              \left(1-n^{-\Omega(c)} - p_k/2 - O((\log n)^2/n)\right) \\
        & \ge (kn - 8t\sqrt{n})
              \left(1-n^{-\Omega(c)} - p_k/2 - O((\log n)^2/n)\right) \\
        & = kn(1-p_k/2) - O(t\sqrt{n}) \\
        & = nd_k/2 - O(\sqrt{nk\log n})
  \end{align*} 
  For the upper-bound we proceed as follows:
  \begin{align*}
     \E[E] & \le \E[E_C] + \E[k|S\cap\bar{C}|] \\
           & = \E[E_C] + k(8t\sqrt{n}-16t^2) \\
           & \le \E[E_C] + 4k\sqrt{nck\log n} \\
           & \le nd_k/2 + O((\log n)^2) + 4k\sqrt{nck\log n} \\
           & = nd_k/2 + O(k\sqrt{nk\log n})
  \end{align*}
  where the last step follows from a calculation similar to that
  done in the lower-bound.
%  Let  denote the number of directed edges in $\theta_k(S)$ and let
%  $m_m$ denote the number of mutual edges in $\theta_k(S)$.  The
%
%
%
%  For each $u\in S$ and each $i\in\{1,\ldots,k\}$, let $e(u,i)$ be the
%  edge that $u$ creates in its $i$th cone.  The probability that $e(u,i)$
%  is mutual is
%  \begin{align*}
%    \Pr\{\mbox{$e(u,i)$ is mutual}\} 
%      & = \Pr\{u\in C\}\Pr\{\mbox{$e(u,i)$ is mutual} \mid u\in C\} +
%          \Pr\{u\not\in C\}\Pr\{\mbox{$e(u,i)$ is mutual} \mid u\not\in C\} \\
%      &\ge\Pr\{u\in C\}\Pr\{\mbox{$e(u,i)$ is mutual} \mid u\in C\} 
%      & = (1-r/sqrt{n})^2 p'_k 
%  \end{align*}
\end{proof}

\subsection{Concentration}

Next, we show that the number of edges in this model is tightly
concentrated about its expected value.  We begin with the following
result, which follows immediately from Hoeffding's Inequality, and shows
that the number of points in the core is highly concentrated around its
expected value:
\begin{lem}\lemlabel{coresize}
  $\Pr\left\{\left||S\cap C|-(\sqrt{n}-4t)^2\right| \ge \sqrt{ck\log n}\right\}
  \in n^{-\Omega(c)}$.
\end{lem}

To prove our concentration bound, we make use of a versatile concentration
inequality due to McDiarmid \cite{X}:

\begin{thm}[McDiarmid's Inequality]
Let $X_1,\ldots,X_n$ be independent all taking values in the set
$\mathcal{X}$ and let $f:\mathcal{X}^n\mapsto\R$ be a function such that
\[
    |f(x_1,\ldots,x_i,\ldots,x_n) - f(x_1,\ldots,x_i',\ldots,x_n)|
    \le k \enspace ,
\]
for some $c>0$ and all $x_1,\ldots,x_n,x_i'\in \mathcal{X}$
and all $i\in\{1,\ldots,n\}$.
Then, for all $\epsilon > 0$,
\[
    \Pr\{|f(X_1,\ldots,X_n) - \E[f(X_1,\ldots,X_n)]| \ge \epsilon\}
       \le 2\exp(-2\epsilon^2/(nk^2))
\]
\end{thm}

\begin{lem}
 Let $S$ be a set of $n$ points independently and uniformly distributed
 in $[0,\sqrt{n}]^2$ and let $m_k$ denote the number of edges in $\theta_k(S)$.
 Then $\Pr\{|m_k-\E[m_k]| \ge k\sqrt{cn\log n}\} \le n^{-\Omega(c)}$.
\end{lem}

\begin{proof}
Let $Q$ be a set of $k$ points chosen such that, for any point
$u\in[0,\sqrt{n}]^2$, each of $u$'s $\theta_k$-cones contains exactly one
point in $Q$. ($Q$ could be, for example, the vertices of a sufficiently
large regular $k$-gon. See \figref{q}.)  We begin by studying the
$\theta_k(S\cup Q)$.  This graph is somewhat more nicely behaved since
each vertex in $S$ defines exactly $k$ directed edges.

\begin{figure}
  \begin{center}
    \includegraphics{q}
  \end{center}
  \caption{The set $Q$ ensure that every vertex in $S$ has at least
    one point in each of its $\theta_k$-cones.  This figure shows the
    set $Q$ for $k=5$.}
  \figlabel{q}
\end{figure}

For a set $S=\{u_1,\ldots,u_n\}\subset [0,\sqrt{n}]^2$,
let $f(u_1,\ldots,u_n)$ be the function that counts the number of edges
in $\theta_k(S\cup Q)$.  Observe that, for any $u_1,\ldots,u_n,u_i'\in
[0,1]^2$, we have that
\[
   |f(u_1,\ldots,u_i,\ldots,u_n)-f(u_1,\ldots,u_i',\ldots,u_n)| \le k \enspace .
\]
That is, moving $u_i$ to location $u_i'$ can be though of as removing
$u_i$, resulting in the loss of at most $k$ non-mutual edges emanating
from $u_i$, followed by adding $u_i'$ resulting in the creation of at
most $k$ non-mutual edges emanating from $u_i'$.  Letting $m_k'$ denote
the number of edges in $\Theta_k(S\cup Q)$, we immediately obtain,
from McDiarmid's Inequality,
\[
   \Pr\left\{\left|m_k'-\E[m_k']\right| \ge k\sqrt{cn\log n}\right\} 
       \le 2\exp(-2c\log n) 
       \in n^{-\Omega(c)} \enspace .
\]
To extend this result to $m_k$, the number of edges of $\theta_k(S)$,
we study $\Pr\{|m_k' - m_k|\ge k\sqrt{cn\log n}\}$.  If $|m_k' - m_k|\ge
k\sqrt{cn\log n}$ then the number of points of $S$ in the near-boundary
$\bar{C}$ exceeds $\sqrt{cn\log n}$ or $\theta_k(S\cup Q)$ contains
edges that join points in $Q$ to points in the core, $C$.
\lemref{coresize} shows that the probability of the former event is at most
$n^{-\Omega(c)}$, while \lemref{exists} shows that the probability of
the latter event is at most $n^{-\Omega(c)}$
\end{proof}





\section{Discussion}
\seclabel{summary}

We have given exact closed-form expressions for the average degree of
$\theta_k$ graphs and $Y_k$ graphs for all $k\ge 4$.  It is known that
$\theta_k$ graphs and $Y_k$ graphs with $k=1,2,3$ do not have constant
spanning ratios \cite{S}, so the cases $k\ge 4$ are the most important.
We have also shown that the number of edges in a $\theta_k$-graph or
$Y_k$ graph of $n$ points uniformly distributed in a square is highly
concentrated around its expected value.  These results can be used
to inform practitioners about the optimal choice of $k$ to use in a
particular application.  \tabref{values} gives the numerical values of
$d_k$, $p_k$, and $d_k/k$, for $k\in\{4,\ldots,20\}$.

Some of our results involved extensive calculations that were done
with the help of Mathematica.  There is certainly the possibility of
mistakes, either in the software or by its users.  In order to help
validate our analytical results, the final column in \tabref{values}
also shows the results of the following experiment: 10,000 points were
generated uniformly in the unit square $[0,1]^2$ and their $\theta_k$
and $Y_k$ graph was computed.  The average degree of points in the square
$[1/3,2/3]^2$ was then computed.  The final column of \tabref{values}
shows the average of these values taken over all 1000 repetitions of
this experiment.  In all cases, it agrees with our experimental results
in at least 2 decimal places.

\begin{table}
   \begin{center}
     \begin{tabular}{ccccc}
       $k$ & $p_k$ & $d_k$ & $d_k/k$ & $\hat{d}_k$ \\
     \end{tabular}
   \end{center}
   \caption{Numeric values of $p_k$ and $d_k$.}
   \tablabel{values}
\end{table}

\section*{Acknowledgement}

The authors of this paper are partly funded by NSERC and CFI.

\bibliographystyle{plain}
\bibliography{template}





\end{document}


