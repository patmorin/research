\documentclass[charterfonts,lotsofwhite]{patmorin}
\usepackage[noend]{algorithmic}

\input{pat}
\newcommand{\td}{\mathrm{depth}}
\newcommand{\lp}{\mathrm{LP}}

\title{\MakeUppercase{Output-Sensitive Algorithms for Tukey Depth and
        Related Problems}}
\author{David Bremner \and
	John Iacono \and
	Stefan Langerman \and
	Pat Morin \and
	Others?}
\date{}
\begin{document}
\maketitle

\begin{abstract}
The \emph{Tukey depth} (Tukey 1975) of a point $p$ with respect to a
finite set $S$ of points is the minimum number of elements of $S$
contained in any closed halfspace that contains $p$.  Algorithms for
computing the Tukey depth of a point in various dimensions are
considered.  The running times of these algorithms depend on the value
of the output, making them suited to situations such as outlier
removal when the value of the output is typically small.
\end{abstract}

\section{Introduction}

Let $S$ be a set of $n$ points in $\R^d$.
The \emph{Tukey depth}, or \emph{halfspace depth} of a point $p\in\R^d$ with
respect to $S$ can be defined in several equivalent ways \cite{t75}:
\begin{eqnarray}
\td(p,S) & = & \min\{ |h\cap S| :
	             \mbox{$h$ is a closed halfspace containing $p$} \} \\ 
                     \eqlabel{tuk-orig}
            & = & \min\{ |h\cap S| :
                      \mbox{$h$ is a closed halfspace with $p$ on its boundary} \} \\ 
                       \eqlabel{tuk-boundary}
            & = & \min\{ |S'| :
                      \mbox{$p$ is outside the convex hull of 
                           $S\setminus S'$} \}
                      \eqlabel{tuk-hull}
\end{eqnarray}

In this paper we consider algorithms for computing the Tukey depth of
a point $p$ with respect to a set $S$, whose running time is dependent
on the value, $k$, of the output. In particular, we present:

\begin{enumerate}
\item A simple $O(n + k\log k)$ time algorithm for points in $\R^2$
(\secref{2d}).  The most complicated data structure used in this
algorithm is a binary heap.

\item An $O(n + (n-k)\log(n-k))$ time algorithm to find the largest
clique in a circular-arc graph, where $k$ is the size of the clique
found (\secref{max-clique}).  This problem is a generalization of the
Tukey depth problem in $\R^2$.

\item An $O(n\log n + k^2\log n)$ time algorithm for points in $\R^3$
and an $O(n + k^{11/4}n^{1/4}\log^{O(1)}n)$ time algorithm for points
in $\R^4$ (\secref{3-4-d}).  These algorithms rely on results of Chan
on linear programming with violated constraints \cite{c05} which in
turn rely on sophisticated range searching data structures
\cite{m92,r99} and/or dynamic convex hull data structures \cite{bj02}.

\item A simple $O(d^k \lp(n,d-1))$ time algorithm for points in
$\R^d$, where $\lp(n,d)$ denotes the time required to determine the
feasibility of a linear program having $n$ constraints and $d$
variables (\secref{d-d}).  Not surprisingly, this algorithm is also
based on linear programming with violated constraints and is obtained
by presenting a fixed-parameter tractable algorithm for a
parameterization of the NP-hard \textsc{MaximumFeasibleSubsystem}
problem.
\end{enumerate}

For the remainder of this paper we use the following notations: For
points $p,q\in\mathbb{R}^d$, $p_i$ denotes the $i$th coordinate of
$p$, $\|p\|=(\sum_{i=1}^d p_i^2)^{1/2}$, and $p\cdot
q=\sum_{i=1}^d p_iq_i$.  The unit sphere in $\R^{d+1}$ is denoted by
$\Sp^d =\{ p\in\R^{d+1} : \|p\|=1\}$. The top side of this sphere is
denoted by $\Sp^d_+ =\{ p\in\Sp^{d} : p_{d+1} > 0 \}$, the bottom
side is denoted by $\Sp^d_- =\{ p\in\Sp^{d} : p_{d+1} < 0 \}$ and the
equator is denoted by $\Sp^d_0 =\{ p\in\Sp^{d} : p_{d+1} = 0 \}$ .



\section{An Algorithm for Points in $\R^2$}
\seclabel{2d}

In this section we give a simple $O(n + k\log k)$ time algorithm to
compute the Tukey depth of a point $p\in\R^2$ with respect to
a set $S$ of $n$ points in $\R^2$.  The algorithm begins by
partitioning $\R^2$ into 4 quadrants $Q_0,\ldots,Q_3$ around $p$.
The algorithm then simultaneously begins computing the 4 quantities
$\td_0(p,S),\ldots,\td_3(p,S)$ where 
\begin{equation}
     \td_i(p,S) = \min\{|h\cap S| : \mbox{$h$ is a halfspace containing
$Q_i$} \} \enspace . \eqlabel{four-min}
\end{equation}
Clearly, $\td(p,S) = \min\{\td_i(p,S): 0\le i \le 3 \}$ since any
halfspace containing $p$ contains at least one of the four quadrants.
In the remainder of this section we will describe how to compute
$k_i=\td_i(p,S)$ in $O(n + k_i\log k_i)$ time.  Since the
computation can stop once $\td_i(p,S)$ has been computed for
the index $i$ that minimizes \eqref{four-min}, running the computation
of $k_0,\ldots,k_3$ in parallel yields an $O(n +
k\log k)$ time algorithm, where $k=\td(p,S)$.

Let $S_i=S\cap Q_i$. To compute $\td_i(p,S)$ we create two binary
heaps $H_{i-1}$ and $H_{i+1}$ that store the elements of $S_{i-1}$,
respectively $S_{i+1}$, in counterclockwise, respectively, clockwise,
order around $p$.\footnote{Here and in the remainder of this section
$S_i$ is treated implictly as $S_{i\bmod 4}$.} 
Creating these two heaps takes $O(n)$ time using the
standard bottom-up algorithm to construct a binary heap
\cite[Chapter~6]{clrs01}.
Next we extract elements one at a time from each of $H_{i-1}$ and
$H_{i+1}$ until either (a)~one of the heaps is empty or (b)~we extract
two elements $q$ from $H_{i-1}$ and $r$ from $H_{i+1}$ such that the
angle $\angle spq > \pi$.  Suppose we have extracted $\ell$ elements
each from $H_{i-1}$ and $H_{i+1}$ when this occurs.  Then it is easy
to verify that 
\[  
  |S_i| + \ell - 1 \le \td_i(p,S) \le |S_i| + 2\ell \enspace .
\]

Next, we continue to extract as many elements as possible from each of
$H_{i-1}$ and $H_{i+1}$ up to a maximum of an additional $\ell$
elements each. The total time required to extract these at most
$4\ell$ from the two heaps is $O(\ell\log n)$.  By sorting and
scanning all the elements extracted from the heap plus the elements of
$S_i$ we can then compute $\td_i(p,S)$ in an additional
\[
     O((|S_i|+\ell)\log n) = O(k_i\log n)
\] 
time.  This yields an a total running time of 
\[  
   O(n + k_i\log n) = O(n + k_i\log k_i) \enspace ,
\]
as required.  This completes the proof of:

\begin{thm}\thmlabel{2-d}
The Tukey depth of a point $p$ with respect to a set $S$ of $n$ points
in $\R^2$ can be computed in $O(n + k\log k)$ time, where
$k$ is the value of the output.
\end{thm}

\section{An Algorithm for \textsc{Max-Clique} in Circular-Arc Graphs}
\seclabel{max-clique}

The problem of computing Tukey depth in $\R^2$ can be viewed as a
problem on a set of circular arcs.  By \eqref{tuk-boundary}, computing
the Tukey depth of $p$ is equivalent to finding a unit normal vector
$v$ such that the halfspace with $p$ on its boundary and having inner
normal $v$ contains as few points of $S$ as possible.  Note that the
set of unit normals in $\R^2$ is homeomorphic to the unit circle
$\Sp^1$ and that each point $q\in S$ defines a circular arc of $\Sp^1$
such that all choices of $v$ in this circular arc yield a halfspace
that does not contain $q$.  Thus, the Tukey depth problem reduces to
the problem of finding a vector $v$ that is contained in the largest
number of circular arcs. The partitioning into 4 quadrants used in for
the algorithm of \thmref{2-d} works because all the circular arcs are
actually half circles.  In this section we extend the results of the
previous section to the case of arbitrary circular arcs.

Let $C$ be a set of $n$ circular arcs of the unit circle $\Sp^1$.  We
describe an $O(n+(n-k)\log (n-k))$ time algorithm to find a point
$v\in\Sp^1$ that is contained in the largest number of elements of
$C$.  Here $k$ is the number of arcs of $C$ that contain $p$.  Let
$p_1,\ldots,p_{2n}$ denote the $2n$ endpoints of the arcs in $C$, as
they occur in counterclockwise order on $\Sp^1$.  We use the notation
$[a,b]$ to denote the circular arc of $\Sp^1$ that begins at $a$ and
proceeds counterclockwise to $b$.  Together, the following two
observations imply that all the points of very high depth are
clustered together.

\begin{obs}\obslabel{close}
Let $q\in[p_i,p_{i+1}]$ be a point contained in $k$ arcs of $C$.
Then, for any $0\le r\le n$, every point $q'\in[p_{i-r},p_{i+r}]$ is
contained at least $k-r$ arcs of $C$.
\end{obs}

\begin{obs}\obslabel{far}
Let $q\in[p_i,p_{i+1}]$ be a point contained in $k$ arcs of $C$.
Then, for any $n-k \le r\le n$, every point $q'\notin[p_{i-r},p_{i+r}]$ 
is contained in at most $2n-k-r$ arcs of $C$.
\end{obs}

At a high level our algorithm is fairly simple.  Suppose we are given
a value $k$ and only wish to find the point $p\in\Sp^1$
contained in $k$ arcs of $C$.

We begin by taking a regular sample $s_1,\ldots,s_{2t}$ of
$p_1,\ldots,p_{2n}$ so that any arc $[s_i,s_{i+1}]$ between two
consecutive sample points contains at most $n/t$ points of
$p_1,\ldots,p_{2n}$.  We then compute, for each sample point $s_i$ the
number of arcs from $C$ that contain $s_i$.  By \obsref{close}, if
there exists any point $p\in \Sp^1$ contained in $k$ arcs of $C$
then the two sample points $s_j$ and $s_{j+1}$ on either side of $p$
are \emph{high depth samples} that are each contained in at least
$k-n/t$ arcs of $C$.  Furthermore, by \obsref{far}, the only high
depth samples are contained in the interval $[p_{i-r},p_{i+r}]$ for
$r=2(n-k)+n/t$.  

If we choose $t=\sqrt{n}$ then $r=O(n-k+\sqrt{n})$.  Thus, by
computing an arc $[p_a,p_b]$ that contains all high depth samples we
can then find the point $p$ contained in the largest number of arcs of
$C$ by applying the standard ``sort-and-scan'' algorithm on the
$O(n-k+\sqrt{n})$ endpoints of the arcs of $C$ that fall in the arc 
$[p_a,p_b]$.  The running
time of the ``sort-and-scan'' algorithm is $O(m\log m)$ where $m$ is
the number of points which, in this case gives a running time of 
\[
   O((n-k+\sqrt{n})\log(n-k+\sqrt n)) = O(n + (n-k)\log (n-k)) \enspace ,
\]
as required.

In implementating the above ideas, several issues
arise:

\begin{enumerate}

\item The value of $k$ is not known in advance.  However, we do not
need the exactly value of $k$ and the value of $k$ can be estimated to
within an additive error of $\sqrt{n}$ by computing, for each sample
point $s_i$, the number of arcs of $C$ that contain $s_i$ (see
Issue~3, below) and using the maximum of these values as an estimate
for $k$.

\item We can not obtain a perfectly regular sample
$s_0,\ldots,s_{2\sqrt{n}}$ of $p_1,\ldots,p_{2n}$ in $O(n)$ time.
However, we do not require a perfectly regular sample.  By taking a
random sample of size $c\sqrt{n}\log n$ for an appropriate constant
$c$ we obtain a set of samples $s_0,\ldots,s_{c\sqrt{n}\log n}$ such
that, with high probability, no arc $[s_{i},s_{i+1}]$ contains more
than $\sqrt{n}$ endpoints of arcs of $C$ \cite{m98}.

\item We can not compute, in $O(n)$ time, for each sample point $s_i$,
the number of arcs of $C$ that contain $s_i$.  However, random
sampling helps again here.  Let $d(s_i)$ denote the number of elements
of $C$ that contain $s_i$. By taking a random sample $C'\subseteq C$,
$|C'|=\sqrt{n}$ we can determine, with high probability, for each $s_i$ a
number $d_i$ such that
\[
        d(s_i) - O(n^{4/5})\le d_i \le
           d(s_i) + O(n^{4/5}) \enspace .
\]
By storing the $\sqrt{n}$ elements of $C'$ in an interval tree \cite{ps85} and
then querying this interval tree with the $c\sqrt{n}\log n$ sample
elements the numbers $d_1,\ldots,d_{c\sqrt{n}\log n}$ can be computed
in $O(\sqrt{n}\log^2 n)$
time.  
\end{enumerate}

None of the above issues have any significant effect on the running
time of the overall algorithm, which is still dominated by the final
``sort-and-scan'' step on a problem of size $O(n-k+\sqrt{n})$.  This
yields:

\begin{thm}
Let
$C$ be a set of $n$ circular of $\Sp^1$.  Then, for any constant
$c$ there exists a randomized algorithm that runs in $O(n+(n-k)\log
(n-k))$ expected time and with probability at least $1-O(n^{-c})$
finds a point $p\in\Sp^1$ contained in the largest number of arcs of
$C$.
\end{thm}


\section{Algorithms for Points in $\R^3$ and $\R^4$}
\seclabel{3-4-d}

The previous section showed how the problem of computing the Tukey
depth of a point in $\R^2$ is equivalent to the problem of finding a
point contained in the largest number of halfcircles on the unit
circle $\Sp^1$.  A similar statement is true in $\R^d$:  Each point
$q\in S$ defines an open halfsphere $q^*=\{ v\in\Sp^{d-1} : v\cdot q <
0\}$.  That is, all vectors in $q^*$ are the inner normals of hyperplanes
that contain $p$ but do not contain $q$.  Thus, the problem of
determining the Tukey depth of $p$ reduces to the problem of finding
the point contained in the largest number of halfspheres in $S^*=\{q^*
: q\in S\}$.

We observe that this problem can be solved by solving three problems in
$\R^{d-1}$.  Each open halfsphere $q^*\in S^*$ is the intersection of
an open halfspace $q^\#$ with $\Sp^{d-1}$.  Consider the intersection
of $q^\#$ with the hyperplane $H_+=\{(x_1,\ldots,x_d):x_d=1\}$.  By
central projection, there is a 1-1 correspondence between points in
$\Sp^{d-1}_+$ and $H_+$ and this projection has the property that
$r\in\Sp^{d-1}_+$ is in $q^*$ if and only if the projection of $r$ is
in $q^\#\cap H_+$.  Thus, finding the point in $\Sp^{d-1}_+$ contained
in the largest number of halfspheres is equivalent to finding a point
in $H_+$ contained in the largest number of halfspaces.  A similar
statement holds regarding $\Sp^{d-1}_-$ using the hyperplane
$H_-=\{(x_1,\ldots,x_d):x_d=-1\}$.  Finally, finding the point in
$\Sp^{d-1}_0$ contained in the smallest number of halfspheres is a
$(d-1)$-dimensional Tukey depth problem. 

The above discussion shows that computing the Tukey depth of a point
in $\R^d$ reduces to one Tukey depth problem in $\R^{d-1}$ and two
instances of the problem \textsc{MaximumFeasibleSubsystem} in
$\R^{d-1}$: Given set $K$ of $n$ halfspaces in $\mathbb{R}^{d-1}$,
find the subset $K'$ of $K$ of minimum cardinality such that $\cap
(K\setminus K')$ is non-empty.  The current best results for
\textsc{MaximumFeasibleSubsystem} in small dimensions are due to Chan
\cite{c05}.  Using two instances of his algorithm for
\textsc{MaximumFeasibleSubsystem} in $\R^2$, respectively, $\R^3$, and
running them in parallel gives:

\begin{thm}
The Tukey depth of a point $p$ with respect to a set $S$ of $n$ points
in $\R^3$ can be computed in $O(n\log n + k^2\log n)$ time, where
$k$ is the value of the output.
\end{thm}


\begin{thm}
The Tukey depth of a point $p$ with respect to a set $S$ of $n$ points
in $\R^4$ can be computed in $O(n\log n + k^{11/4}n^{1/4}\log^{O(1)}
n)$ time, where $k$ is the value of the output.
\end{thm}

\section{An Algorithm for Points in $\R^d$}
\seclabel{d-d}

Finally, we consider the general case of point sets in $\R^d$.  
In the previous section we showed that computing the Tukey depth of
a point $p$ with respect to a point set $S$ of $n$ points in $\R^d$
can be reduced to two instances of \textsc{MaximumFeasibleSubsystem}
in $\R^{d-1}$ and one Tukey depth computation in $\mathbb{R}^{d-1}$.  Here we give a fixed-parameter tractable \cite{df98}
algorithm for \textsc{MaximumFeasibleSubsystem}.  The algorithm uses
linear programming as a subroutine in the following way:  Given a
collection $K$ of halfspaces in $\R^{d-1}$, an algorithm for linear
programming can be used to either
\begin{enumerate}
\item Determine a point $p\in\cap K$ if such a point exists or,
\item report a subset $B\subseteq K$, $|B|\le d$, such that $\cap B=\emptyset$.
\end{enumerate}
Let $\textsc{IIS}(K)$ denote a routine that outputs, in the latter
case, the set
$B$ or outputs, in the former case, the empty set.
Then the following algorithm solves the
\textsc{MaximumFeasibleSubsystem} decision problem:

\noindent$\textsc{MFS}(K,k)$
\begin{algorithmic}[1]
\STATE{\COMMENT{$\star$ determine if there exists $K'\subseteq K$, $|K'|\le
k$, such that $\cap(K\setminus K')\neq\emptyset$ $\star$} }
\STATE{$B\gets\textsc{IIS}(K)$}
\IF{$B=\emptyset$}
   \STATE{\textbf{return} true}
\ENDIF
\IF{$k=0$}
   \STATE{\textbf{return} false}
\ENDIF
\FOR{each $h\in K'$}
   \IF{$\textsc{MFS}(K\setminus\{h\},k-1)=\mathrm{true}$}
      \STATE{\textbf{return} true}
   \ENDIF
\ENDFOR
\STATE{\textbf{return} false}
\end{algorithmic}

Correctness of the above algorithm is easily established by induction
on the value of $k$.  The running time of the algorithm is given by
the recurrence
\[
    T(n,k) \le \lp(n,d-1)+ dT(n-1,k-1) \enspace ,
\]
where $\lp(n,d)$ denotes the running time of an algorithm for solving
a linear programming with $n$ constraints and $d$ variables.  This
recurrence readily resolves to $O(d^k\lp(n,d-1))$.  

Using this as a subroutine for Tukey depth computation we obtain an
algorithm whose running time is given by the recurrence
\[
    S(n,d,k) \le O(d^k\lp(n,d-1)) + S(n,d-1,k)
\]
which resolves to $O((d+1)^k\lp(n,d-1))$.  Running this algorithm for
$k=0,1,2,\ldots$ completes the proof of:

\begin{thm}\thmlabel{d-d}
The Tukey depth of a point $p$ with respect to a set $S$ of $n$ points
in $\R^d$ can be computed in $O((d+1)^k\lp(n,d-1))$ time, where $k$ is
the value of the output and $\lp(n,d)$ is the time to solve a linear
program with $n$ constraints and $d$ variables.
\end{thm}

\bibliographystyle{plain}
\bibliography{tukey}


\end{document}

