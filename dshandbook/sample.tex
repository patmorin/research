\chapter{Computer Science and Engineering: The Discipline and
Its Impact}


\begin{chapterauthors}
\chapterauthor{Allen B. Tucker, Jr.}{Bowdoin College} 
\chapterauthor{Peter Wegner}{Brown University}
\end{chapterauthors}

\section{Introduction}
\label{sec1}

\noindent 
\looseness-1The discipline and profession of computer science and~\cite{article-minimal}
engineering (CS\&E) has undergone dramatic changes in its short
50-year life. As the field has matured, new areas of research
and development have emerged and joined with older areas to
revitalize the discipline. In the 1930s, fundamental
mathematical concepts of computing were developed by Turing and
Church. Early computers implemented by von \nobreak{Neumann}, Eckert,
Atanasoff, and others in the 1940s led to the birth of
commercial computing in the 1950s and to numerical programming
languages like Fortran, commercial languages like COBOL, and
artificial-intelligence languages like LISP. In the 1960s the
rapid development and consolidation of the subjects of~\cite{article-shibu}
algorithms, data structures, databases, and operating systems
formed the core of what we now call traditional computer science;
the 1970s  saw the emergence of software engineering, structured
programming, and object-oriented programming. The emergence of
personal computing and networks in the 1980s set the stage for
dramatic advances in computer graphics, software technology, and
parallelism. This Handbook aims to characterize computing in the
1990s, incorporating the explosive growth of networks like the
World Wide Web and the increasing importance of areas like
human--computer interaction, computational science, and other
subfields that would not have appeared in such an
% encyclopedia
%even ten years ago. This para is in Section~\ref{sec1}.

This introductory chapter reviews the evolution\cite{article-suresh} of CS\&E during
the last two decades. It introduces those fundamental
contemporary themes that form the nucleus of the subject matter
and methodologies of the discipline, identifying the social
context and scientific challenges that will continue to stimulate
rapid growth and evolution of CS\&E  into the next century.
Finally, it provides an overview of the discipline of CS\&E,
serving as a conceptual introduction to the ten major sections
and 122 chapters and appendices that constitute the entire Handbook. These ten
sections, corresponding to ten major subject areas, reflect a
useful classification of the subject matter in CS\&E:

\begin{itemize}
\item
 Algorithms and Data Structure
\item
 Architecture
\item
 Artificial Intelligence and Robotics
\item
 Computational Science
\item
Database and Information Retrieval
\item
 Graphics
\item
 Human--Computer Interaction
\item
 Operating Systems and Networks
\item
 Programming Languages
\item
 Software Engineering
\end{itemize}

Section 1.2 of this chapter presents a brief history of the
computing industry and the parallel development of the computing
curriculum. Section 1.3 frames the practice of CS\&E in terms of
four major conceptual paradigms: theory, abstraction, design, and
the social context. Section 1.4 identifies the ``grand challenges''
that promise to extend the field's vitality and reshape its
definition for the next generation and beyond, and section 1.5
summarizes the contents of the ten sections of the Handbook.

definition for the next generation and beyond, and section 1.5
summarizes the contents of the ten sections of the Handbook.

definition for the next generation and beyond, and section 1.5
summarizes the contents of the ten sections of the Handbook.

definition for the next generation and beyond, and section 1.5
summarizes the contents of the ten sections of the Handbook.

\begin{figure}
\centerline{\centerline{\includegraphics{04-01.eps}}}
\caption{The doubling program in the GOTO language. The doubling program in the GOTO language. The doubling program in the GOTO language.}
\end{figure}

This Handbook is designed as a professional reference for
researchers and practitioners in the field. Readers interested
in exploring specific subject topics may prefer to move directly
to the appropriate section of the Handbook. To facilitate rapid
inquiry, the Handbook contains a Table of Contents and three
indexes (Subject, Who's Who, and Key Algorithms and Formulas)
for immediate access to specific topics at various levels of detail.

\section{Growth of the Industry and the Profession}

\noindent 
The computer industry has experienced tremendous growth and
change over the last several decades, and most recently some
retrenchment. The transition that began in the 1980s, from
centralized mainframes to a decentralized networked
microcomputer--server technology, was accompanied by the rise and
fall of major corporations. The old monopolistic, vertically
integrated industry epitomized by IBM's comprehensive client services
gave way to a highly competitive industry
 in which the major players changed almost
overnight. In 1992 alone, emergent companies like Dell and
Microsoft had spectacular profit gains of 77\% and 53\%. In
contrast, traditional companies like IBM and DEC suffered
combined record losses of \$7.1 billion in the same year
[Economist 1993]. The exponential decrease in computer cost and
increase in power by a factor of two every eighteen months,
known as Moore's law, shows no signs of abating, though
underlying physical limits must eventually be reached.

\begin{example}
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment.
\end{example}

This is normal text. This is normal text. This is normal text. This is normal text. 
This is normal text. This is normal text. This is normal text. This is normal text. 
This is normal text. This is normal text. This is normal text. This is normal text. 

\begin{example}
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
\end{example}

\looseness-1Overall, the rapid 18\% annual growth rate that the computer
industry had enjoyed in earlier decades gave way in the early
1990s to a 6\% growth rate, caused in part by a saturation of the
personal computer market. Another reason for this slowing of
growth is that the performance of computers (speed, storage
capacity) has improved at a rate of 30\% per year in relation to
their cost. Today, it is not unusual for a desktop computer 
to run at hundreds of\, times the speed and capacity of a typical 
mainframe computer of the 1980s, and at a fraction of the cost. However, 
it is not clear whether this slowdown in growth represents a temporary plateau 
or whether a new round of fundamental technical innovations in areas
such as networking and human--computer interaction might again
propel the computer industry to more spectacular rates of growth.\footnote{Here goes another one}

\begin{figure}
\centerline{\includegraphics{04-01.eps}}
\caption{The doubling program in the GOTO language. The doubling program in the GOTO language. The doubling program in the GOTO language.}
\end{figure}

\looseness-1Overall, the rapid 18\% annual growth rate that the computer
industry had enjoyed in earlier decades gave way in the early
1990s to a 6\% growth rate, caused in part by a saturation of the
personal computer market. Another reason for this slowing of
growth is that the performance of computers (speed, storage
capacity) has improved at a rate of 30\% per year in relation to
their cost. Today, it is not unusual for a desktop computer 
to run at hundreds of\, times the speed and capacity of a typical 
mainframe computer of the 1980s, and at a fraction of the cost. However, 
it is not clear whether this slowdown in growth represents a temporary plateau 
or whether a new round of fundamental technical innovations in areas
such as networking and human--computer interaction might again
propel the computer industry to more spectacular rates of growth.

\begin{example}
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment. 
This inside the Example Environment. This inside the Example Environment.
\end{example}

\begin{solution}
This goes inside the solution. This goes inside the solution. This goes inside the solution. 
This goes inside the solution. This goes inside the solution. 
This goes inside the solution. This goes inside the solution. This goes inside the solution. 
\end{solution}

\looseness-1Overall, the rapid 18\% annual growth rate that the computer
industry had enjoyed in earlier decades gave way in the early
1990s to a 6\% growth rate, caused in part by a saturation of the
personal computer market. Another reason for this slowing of
growth is that the performance of computers (speed, storage
capacity) has improved at a rate of 30\% per year in relation to
their cost. Today, it is not unusual for a desktop computer 
\begin{solution}
This goes inside the solution. This goes inside the solution. This goes inside the solution. 
This goes inside the solution. This goes inside the solution. 
This goes inside the solution. This goes inside the solution. This goes inside the solution. 
\end{solution}
\begin{solution}
This goes inside the solution. This goes inside the solution. This goes inside the solution. 
This goes inside the solution. This goes inside the solution. 
This goes inside the solution. This goes inside the solution. This goes inside the solution. 
\end{solution}
To run at hundreds of\, times the speed and capacity of a typical 
mainframe computer of the 1980s, and at a fraction of the cost. However, 
it is not clear whether this slowdown in growth represents a temporary plateau 
or whether a new round of fundamental technical innovations in areas
such as networking and human--computer interaction might again
propel the computer industry to more spectacular rates of growth.
or whether a new round of fundamental technical innovations in areas
such as networking and human--computer interaction might again
propel the computer industry to more spectacular rates of growth.
or whether a new round of fundamental technical innovations in areas
such as networking and human--computer interaction might again
propel the computer industry to more spectacular rates of growth.
or whether a new round of fundamental technical innovations in areas
such as networking and human--computer interaction might again
propel the computer industry to more spectacular rates of growth.



\begin{table}
\tabletitle{This is an Example of Table Title This is an Example of Table Title This is an Example
of Table Title This is an Example of Table Title}
\begin{tabular}{@{}lll lll@{}}
Item 1 & Item 2 & Item 3 & Item 4 & Item 5 & Item 6 \\
\toprule
item 1 & item 2 & Item 3 & item 1 & item 2 & Item 3\\
item 1 & item 2 & Item 3 & item 1 & item 2 & Item 3\\
item 1 & item 2 & Item 3 & item 1 & item 2 & Item 3\\
item 1 & item 2 & Item 3 & item 1 & item 2 & Item 3\\
item 1 & item 2 & Item 3 & item 1 & item 2 & Item 3\\
\end{tabular}
\begin{tablefooter}
\hangindent=3pt \raggedright
{\it Source:} Couch, L.W.,
II, 1997, {\it Digital and Analog Communication Systems,}
5th ed., Prentice
Hall, Upper Saddle River, NJ, pp. 231-232.  With permission.

\hangindent=3pt \raggedright
{\it Source:} Couch, L.W.,
II, 1997, {\it Digital and Analog Communication Systems,}
5th ed., Prentice
Hall, Upper Saddle River, NJ, pp. 231-232.  With permission.
\end{tablefooter}
\end{table}


\subsection{This is B Head Curriculum Development}
\noindent
The computer industry's evolution has been strongly affected by
the evolution of both theory and practice in the last several
years. Changes in theory and practice are intertwined with the
parallel evolution of the field's undergraduate and graduate
curricula during the last three decades, and those curricula
have, in turn, defined the conceptual and methodological
framework for understanding the discipline itself.

\subsubsection{This is C Head}
The computer industry's evolution has been strongly affected by
the evolution of both theory and practice in the last several
years. Changes in theory and practice are intertwined with the
parallel evolution of the field's undergraduate and graduate
curricula during the last three decades, and those curricula
have, in turn, defined the conceptual and methodological
framework for understanding the discipline itself.\footnote{This is the second footnote}

\paragraph{Curriculum Development}%
\noindent
The first coherent and widely cited curriculum for CS\&E was
developed in 1968 by the ACM Curriculum Committee on Computer
Science [ACM 1968]  in response to widespread demand for
systematic undergraduate and graduate programs [Rosser 1966].
``Curriculum 68'' defined computer science as comprising three
main areas: information structures and processes, information
processing systems, and methodologies. The first area included
programming languages, data structures, and formal models of
computation; the second computer architecture, compilers, and
operating systems; the third numerical mathematics, file
management, text processing, graphics, simulation, information
retrieval, artificial intelligence, process control, and
instructional systems. Curriculum 68 used this taxonomy to
define computer science as a discipline and to provide concrete
recommendations and guidance to colleges and universities in
\begin{equation}
\alpha+\beta=\gamma+\bm{a}+\bm{\alpha}
\end{equation}

\subparagraph*{This is 5th Head It should be coded with a star}%
developing undergraduate, master's, and Ph.D. programs to
respond to the widespread demand for computer scientists in
research, education, and industry. Curriculum 68 stood as a
robust and exemplary model for degree programs at all levels
for a decade or more.

In 1978, a new ACM Curriculum Committee on Computer Science
developed a revised and updated undergraduate curriculum [ACM
1978]. The ``Curriculum 78'' report responded to the rapid
evolution of the discipline and practice of computing and to a
demand for a more detailed elaboration of the computer science
(as distinguished from the mathematical) elements of the courses
that would comprise the core curriculum. Around the same time,
the IEEE Computer Society developed a model curriculum for
engineering-oriented undergraduate programs in CS\&E [IEEE-CS
1976]. Updated and published in 1983 by the Computer Society as
a ``Model Program in Computer Science and Engineering'' [IEEE-CS
1983], this curriculum was designed not only to define a course
of study for computer science programs in engineering schools
but also to meet a more extensive set of engineering accreditation criteria.

In 1988, the ACM Task Force on the Core of Computer Science and
the IEEE Computer Society [ACM 1988] cooperated in developing a
fundamental redefinition of the discipline of CS\&E. Called
``Computing as a Discipline,'' this report aimed to provide a
contemporary foundation for undergraduate curriculum design by
responding to the changes in computing research, development,
and industrial applications in the previous decade. This report
also acknowledged some fundamental methodological changes in the
field. No longer could the ``computer science $=$ programming''
model hope to encompass the richness of the field. Instead,
three perspectives---{\it theory, abstraction,} and {\it design}---were
used to characterize how various kinds of computer professionals
and researchers did their work. These three points of view,
those of\, the theoretical mathematician or scientist (theory),
the experimental or applied scientist (abstraction, or
modeling), and the engineer (design), were essential
components of research and development throughout all the nine
major subject areas (similar to the ten Handbook areas) into
which the field was divided.
\begin{equation}
\alpha+\beta=\gamma
\end{equation}
\begin{equation}
\alpha+\beta=\gamma
\end{equation}
``Computing as a Discipline'' led directly to the formation of a
joint ACM/IEEE-CS Curriculum Task Force, which developed a
comprehensive model for undergraduate curriculum design in the
1990s called ``Curricula 91'' [ACM/IEEE 1991]. Acknowledging that
undergraduate computer science programs could be effectively
supported in colleges of engineering, arts and sciences, and
liberal arts, Curricula 91 proposed a core curriculum of common
knowledge that undergraduate majors in any of these programs
should cover. This core curriculum also contained sufficient
theory, abstraction, and design content that students would
become familiar with the fundamentally different but
complementary ways of ``doing'' CS\&E. It also ensured that
students would gain a broad exposure to the nine major subject
areas, and their social and ethical context. A significant
laboratory component ensured that undergraduates gained
significant abstraction (experimentation) and design experience.



\enlargethispage{-1pc}
\subsection{Growth of Academic Programs}

Fueling the rapid evolution of curricula in CS\&E during the last
three decades was an enormous growth in demand, by industry and
academia, for computer professionals, researchers, and
scientists at all levels. In response, the number of CS\&E
Ph.D.-granting programs in the U.S. grew from 12 in 1964 to 132
in 1994. During the period 1966--1993, the annual number of
bachelor's degrees awarded grew from 89 to 24,580, master's
degrees grew from 238 to 10,349, and Ph.D. degrees grew from 19
to 969 [ACM 1968, Andrews 1995].

\begin{figure}
\centerline{\includegraphics{04-01.eps}}
\caption{The doubling program in the GOTO language. The doubling program in the GOTO language. The doubling program in the GOTO language.}
\end{figure}


Figure {\thechapter}.1 shows the number of bachelor's and master's degrees
awarded by U.S. colleges and universities in CS\&E from 1966 to
1993. The number of bachelor's degrees peaked at 42,195
in 1986, and then declined, leveling off to a fairly steady
25,000 by 1993. In contrast, master's degree production in
computer science has grown steadily throughout the same period
and shows no signs of leveling off. The rapid falloff in
bachelor's degree production in 1986 may be attributed to the
saturation of industry demand for programmers, while the steady
growth of master's degrees in recent years may reflect a
recognition by industry that an undergraduate computer science
degree by itself, while providing good preparation for some
positions, is not adequate for many of the newly emerging
positions in the technology industry.



\looseness-1Figure {\thechapter}.2 shows the number of~U.S. Ph.D. degrees in computer
science and computer engineering during the same 1966--1993
period [Andrews 1995]. The annual number of Ph.D.'s in computer
science in the U.S. grew from 19 in 1966 to 878 in 1993, while
the overall number of Ph.D.'s in computer science and computer
engineering peaked at 1113 in 1992 and
leveled off at 969 in 1993 and 1005 in 1994 [Andrews 1995].

Production of M.S. and Ph.D. degrees in computer science and
engineering continued to grow into the 1990s, fueled by
continuing demand from industry for graduate-level talent and
continuing stong demand in academia to staff growing
undergraduate and graduate research programs in CS\&E. However,
there is also a widely held belief that the period of growth in
Ph.D. production in CS\&E has now leveled off and reached a steady
state with respect to demand from industry and academia.

\enlargethispage{-1pc}
\subsection[Academic R\&D and Growth of Industry Positions]{Academic R\&D and Growth of Industry Positions}

University and industrial research and development (R\&D)
investments in CS\&E grew rapidly in the period 1986--1993. Figure
{\thechapter}.3 shows that academic research and development in computer
science nearly doubled, from \$321 million to \$597 million, during
this time period, a growth rate somewhat higher than that of
academic R\&D in the related fields of electrical engineering and
mathematics. During this same period, the overall growth of
academic R\&D in engineering and the social sciences also nearly
doubled, while that in the physical sciences grew by only about
65\%. In 1993, about 68\% of the total support for academic R\&D
came from federal and state sources, while 7\% came from industry
and 18\% came from the institutions themselves [NSF 1995a].

Figure {\thechapter}.4 shows the growth between 1980 and 1990 in the number of
persons with at least a bachelor's degree who were employed in
nonacademic (industry and government) computer science
positions. Overall, the total number of computer scientists and
systems analysts grew by 150\%, from 194,100 in 1980 to 485,200
in 1990. In 1990, there were 9400 Ph.D.'s in nonacademic computer
science and systems analyst positions (of course, many of these
Ph.D.'s were not in computer science) [NSF 1995b]. An informal
survey conducted by the Computing Research Association (CRA)
suggests that slightly more than half of the domestically
employed new Ph.D.'s accepted positions in industry or government
in 1994, and the rest accepted academic positions in colleges
and universities. This survey also suggests that nearly a third
of the total number of 1994 CS\&E Ph.D.'s accepted positions abroad
[Andrews 1995].

%\begin{figure}%%{R}{0}%1
%%%\epsfscale600
%\centerline{\epsfig{figure=fig1.4.eps}}
%\caption{Nonacademic computer scientists and engineers: 1980 and
%1990.}
%\end{figure}

\looseness-1Figure {\thechapter}.4 also provides some comparative growth information for
other professions, again using 1980 and 1990 census data and
considering only persons with bachelor's degrees or higher. We
see that only the operations and systems researchers' growth of
250\% was greater than that of computer scientists, while most
professions' growth rates were significantly lower. Overall, the
total number of nonacademic scientists and engineers grew from
2,136,200 in 1980 to 3,512,800  in 1990, an increase of 64.4\% [NSF 1995b].

\section{Perspectives in Computer Science and Engineering}

\noindent 
Computer science and engineering is a multifaceted discipline
that can be viewed from at least four different perspectives.
Three of the perspectives---theory, abstraction, and design---underscore 
the point that computer scientists and engineers
approach their work and their subject areas from different
intellectual viewpoints. A fourth perspective---the social and
professional context---acknowledges that computing directly
affects the quality of people's lives, and that computing
professionals must be prepared to understand and confront the
social issues that arise from their work.

\begin{enumerate}
\item
The theory of CS\&E draws from principles of mathematics and
\item
logic as well as from the formal methods of the physical,
\item
biological, behavioral, and social sciences. It normally
\item
includes the use of advanced mathematical ideas and methods
\item
includes the use of advanced mathematical ideas and methods
\item
includes the use of advanced mathematical ideas and methods
\item
includes the use of advanced mathematical ideas and methods
\item
includes the use of advanced mathematical ideas and methods
\item
includes the use of advanced mathematical ideas and methods
\item
includes the use of advanced mathematical ideas and methods
\item
includes the use of advanced mathematical ideas and methods
\item
includes the use of advanced mathematical ideas and methods
\item
includes the use of advanced mathematical ideas and methods
\item
includes the use of advanced mathematical ideas and methods
\item
includes the use of advanced mathematical ideas and methods
\end{enumerate}

taken from subfields of mathematics such as algebra, analysis,
and statistics. Theory includes the use of various proof and
argumentation techniques, like induction and contradiction, to
establish properties of formal systems that justify and explain
underlying models and paradigms supporting computer science;
examples are Church's thesis, the study of algorithmically
unsolvable problems, and the study of upper and lower bounds on
the complexity of various hard algorithmic problems. Fields like
algorithms and to a lesser extent artificial intelligence,
computational science, and programming languages have more
mature theoretical models than human--computer interaction or
graphics, but all ten areas considered here have underlying
theories to a greater or lesser extent.

Abstraction in CS\&E includes the use of scientific inquiry,
modeling, and experimentation to test the validity of hypotheses
about computational phenomena. Computer professionals in all ten
areas of the discipline use abstraction as a fundamental tool of
inquiry---many would argue that computer science is the science
of building and examining abstract computational models of
reality. Abstraction arises in computer architecture, where the
Turing machine serves as an abstract model for complex real
computers, and in programming languages, where simple semantic
models like the lambda calculus are used as a framework for
studying complex languages. It appears in the design of heuristic
and approximation algorithms for problems whose optimal
solutions are computationally intractable. It is surely used in
graphics, where models of 3D objects are constructed
mathematically, given properties of lighting, color, and surface
texture, and projected in a realistic way on a two-dimensional
video screen.

%%\enlargethispage{-1pc}

Design is a process used to describe the essential structure of
complex systems as a prelude to their implementation. It also
encompasses the use of traditional engineering methods,
including the classical life-cycle model, to implement efficient
and effective computational systems in hardware and software. It
includes the use of tools like cost/benefit analysis of
alternatives, risk analysis, and fault tolerance that ensure
that computing applications are brought to market effectively.
Design is a central preoccupation of architects and software
engineers developing hardware systems and software applications.
Like abstraction, it is an important activity in computational
science, database and information retrieval, human--computer
interaction, operating systems and networks, and the other areas
considered here.

The social and professional context includes many issues that
arise at the computer--human interface, such as liability for
hardware and software errors, security and privacy of databases
and networks, intellectual property issues (patent and
copyright), and equity issues (universal access to the
technology and the profession). Computing professionals in all
subject areas must consider the ethical context in which their
work occurs and the special responsibilities that attend their
work. The next preliminary chapter discusses these issues, and
several other chapters address topics in which specific social
and professional issues come into play. For example, security
and privacy issues in databases, operating systems, and networks
are discussed in Chapters 49 and 89. Risks in software are
discussed in several chapters of section X of the Handbook.

%%\enlargethispage{-1pc}
\section{Broader Horizons: HPCC and Grand Challenge Applications}

\noindent 
The 1992 report ``Computing the Future'' (CTF) [CSNRCTB 1992],
written by a group of leading computer professionals in response
to a request by the Computer Science and Technology Board
(CSTB), identifies the need for CS\&E to broaden its research
agenda and its educational horizons. The view that the research
agenda should be broadened initially caused concerns among
researchers that funding and other incentives might
overemphasize short-term at the expense of long-term goals. This
Handbook reflects the broader view of the discipline in its
inclusion of computational science, graphics, and computer--human
interaction among the major subfields of computer science.

CTF aimed to bridge the gap between suppliers of research in
CS\&E and consumers of research such as industry, the Federal
government, and funding agencies like NSF, DARPA, and DOE. It
addresses fundamental challenges to the field and suggests
responses that encourage greater interaction between research
and computing practice. Its overall recommendations focus on
three priorities:

\begin{enumerate}
\item[1.]
To sustain the core effort that creates the theoretical and
experimental science base on which applications build.

\item[2.]
To broaden the field to reflect the centrality of computing
in science and society.

\item[3.]
To improve education at both the undergraduate and graduate levels.
\end{enumerate}

CTF includes recommendations to federal policy makers and
universities regarding research and education:

\begin{unnumlist}
\item
{\it Recommendations to federal policy makers regarding research:}
The High-Performance Computing and Communication (HPCC)
program passed by Congress in 1989 [OST 1989] should be fully supported.
%\begin{itemize}
%\item
% The High-Performance Computing and Communication (HPCC)
%program passed by Congress in 1989 [OST 1989] should be fully supported.
%\item
% Application-oriented computer science and engineering research
%should be strongly encouraged through special funding programs.
%\end{itemize}

\item
{\it Recommendations to federal policy makers regarding research:}
The High-Performance Computing and Communication (HPCC)
program passed by Congress in 1989 [OST 1989] should be fully supported.
%\begin{itemize}
%\item
% Academic research should broaden its horizons, embracing
%application-oriented and technology-transfer research as well as
%core  applications.
%\item
% Laboratory research with experimental as well as theoretical
%content should be supported.
%\end{itemize}
\item
{\it Recommendations to federal policy makers regarding research:}
The High-Performance Computing and Communication (HPCC)
program passed by Congress in 1989 [OST 1989] should be fully supported.
%\begin{itemize}
%\item
% Basic and human resources research of HPCC and other areas
%should be expanded to address educational needs.
%\end{itemize}
\item
{\it Recommendations to federal policy makers regarding research:}
The High-Performance Computing and Communication (HPCC)
program passed by Congress in 1989 [OST 1989] should be fully supported.
%\begin{itemize}
%\item
% Broaden graduate education to include requirements and
%incentives to study application areas.
%\item
% Reach out to women and minorities to broaden the talent pool.
%\end{itemize}
\end{unnumlist}


Though this report was motivated by the desire to provide a
rationale for the HPCC program, its message that computer
science must be responsive to the needs of society is much
broader. The years since publication of CTF have seen a swing
away from pure research towards application-oriented research
that is reflected in this Handbook. However, it is important to
maintain a balance between short-term applications and long-term
research in core disciplines.

Though this report was motivated by the desire to provide a
rationale for the HPCC program, its message that computer
science must be responsive to the needs of society is much
broader. The years since publication of CTF have seen a swing
away from pure research towards application-oriented research
that is reflected in this Handbook. However, it is important to
maintain a balance between short-term applications and long-term
research in core disciplines.

Though this report was motivated by the desire to provide a
rationale for the HPCC program, its message that computer
science must be responsive to the needs of society is much
broader. The years since publication of CTF have seen a swing
away from pure research towards application-oriented research
that is reflected in this Handbook. However, it is important to
maintain a balance between short-term applications and long-term
research in core disciplines.

Though this report was motivated by the desire to provide a
rationale for the HPCC program, its message that computer
science must be responsive to the needs of society is much
broader. The years since publication of CTF have seen a swing
away from pure research towards application-oriented research
that is reflected in this Handbook. However, it is important to
maintain a balance between short-term applications and long-term
research in core disciplines.

Though this report was motivated by the desire to provide a
rationale for the HPCC program, its message that computer
science must be responsive to the needs of society is much
broader. The years since publication of CTF have seen a swing
away from pure research towards application-oriented research
that is reflected in this Handbook. However, it is important to
maintain a balance between short-term applications and long-term
research in core disciplines.

Though this report was motivated by the desire to provide a
rationale for the HPCC program, its message that computer
science must be responsive to the needs of society is much
broader. The years since publication of CTF have seen a swing
away from pure research towards application-oriented research
that is reflected in this Handbook. However, it is important to
maintain a balance between short-term applications and long-term
research in core disciplines.

Though this report was motivated by the desire to provide a
rationale for the HPCC program, its message that computer
science must be responsive to the needs of society is much
broader. The years since publication of CTF have seen a swing
away from pure research towards application-oriented research
that is reflected in this Handbook. However, it is important to
maintain a balance between short-term applications and long-term
research in core disciplines.

\enlargethispage{-1pc}
The HPCC program encourages universities, research programs, and
industry to develop specific capabilities to address the ``grand
challenges'' of the future. Realizing these grand challenges
requires both fundamental and applied research, including the
development of high-performance computing systems whose speed is
two to three orders of magnitude greater than that of current
systems, advanced software technology and algorithms that enable
scientists and mathematicians to effectively address these grand
challenges, networking to support R\&D for a gigabit National
Research and Educational Network (NREN), and human resources that
expand basic research in all areas relevant to high-performance computing.

The grand challenges themselves were identified in HPCC as those
fundamental problems in science and engineering with potentially
broad economic, political, or scientific impact that can be
advanced by applying high-performance computing technology and
that can be solved only by high-level collaboration among
computer professionals, scientists, and engineers. A list of
grand challenges developed by agencies like NSF, DOD, DOE, and
NASA in 1989 includes:

\begin{itemize}
\item
 Prediction of weather, climate, and global change.
\item
 Challenges in materials sciences.
\item
 Semiconductor design.
\item
 Superconductivity.
\item
 Structural biology.
\item
 Design of drugs.
\item
 Human genome.
\item
 Quantum chromodynamics.
\item
 Astronomy.
\item
 Transportation.
\item
 Vehicle dynamics and signature.
\item
 Turbulence.
\item
 Nuclear fusion.
\item
 Combustion systems.
\item
 Oil and gas recovery.
\item
 Ocean science.
\item
 Speech.
\item
 Vision.
\item
 Undersea surveillance for antisubmarine warfare.
\end{itemize}

More recently, an HPCC budget request identifies the following
items as the ``National Challenges'' that face American CS\&E and
related professions:

\begin{itemize}
\item
 Digital libraries.
\item
 Crisis and emergency management.
\item
 Educational and lifelong learning.
\item
 Electronic commerce.
\item
 Energy management.
\item
 Environmental monitoring and waste management.
\item
 Health care.
\item
 Manufacturing processes and products.
\item
 Public access to government information.
\end{itemize}

As an outcome of HPCC and CTF,\, two new subject areas,
``computational science'' [Stevenson 1994] and ``organizational
informatics'' [Kling 1993] emerged to influence the structure of
the original nine subject areas identified in the report
``Computing as a Discipline.'' In this Handbook, we view
computational science as an extension of the area of numerical
and symbolic computation. This area includes as a central
element the fundamental interaction between computation and
scientific research. For instance, fields like computational
astrophysics, computational fluid dynamics, and computational
chemistry all emphasize applications of computing in science and
engineering, algorithms, and special considerations for computer
architecture. Much of the research and early accomplishments of
the emerging computational science field is reported in section IV of
this Handbook.

%%\enlargethispage{-1pc}
Organizational informatics, on the other hand, emphasizes
applications of computing in business and management,
information systems and networks, as well as their
implementation, risks, and human factors. Some of these
intersect in major ways with human--computer interaction, while
others fall more directly within the realm of management
information systems (MIS), which is usually treated as a
separate discipline from computer science and engineering. Thus,
in this Handbook, we do not attempt to cover all of
organizational informatics as a separate subject area within
CS\&E. Rather, we include many of its concerns within section VII on
Human--Computer Interaction.

In addition, the growth of computer graphics and networks in the
last few years provides strong arguments for their inclusion as
major subject areas in the discipline. This Handbook
distinguishes {\it graphics} from {\it human--computer interaction}, of
which it had been a subarea in ``Computing as a Discipline.''
Finally, the area of {\it operating systems and networks} in this
Handbook has evolved out of what had been called {\it operating
systems} in ``Computing as a Discipline,'' in recognition of the
rapid growth of distributed computing in the last few years.

\section{Organization and Content}

\noindent 
In the 1940s computing was identified with number crunching, and
numerical analysis was considered a central tool. Hardware,
logical design, and information theory emerged as important
subfields in the early 1950s. Software and programming emerged
as important subfields in the mid 1950s and soon dominated
hardware as topics of study in computer science. In the 1960s
computer science could be comfortably classified into theory,
systems (including hardware and software), and applications.
Software engineering emerged as an important subdiscipline in
the late 1960s. The 1980 Computer Science and Engineering
Research Study [Arden 1980] classified the discipline into nine subfields:
\begin{itemize}
\item
 Numerical computation.
\item
 Theory of computation.
\item
 Hardware systems.
\item
 Artificial intelligence.
\item
 Programming languages.
\item
 Operating systems.
\item
 Database management systems.
\item
 Software methodology.
\item
 Applications.
\end{itemize}

This Handbook's classification into ten subfields is quite
similar to that of the COSERS study, suggesting that the
discipline of CS\&E is stabilizing:
\begin{itemize}
\item
 Algorithms and data structures.
\item
 Architecture.
\item
 Artificial intelligence.
\item
 Computational science.
\item
 Database and information retrieval.
\item
 Graphics.
\item
 Human--computer interaction.
\item
 Operating systems and networks.
\item
 Programming languages.
\item
 Software engineering.
\end{itemize}

This Handbook's classification has discarded numerical analysis
and added the new areas of human--computer interaction and
graphics. The other eight areas appear in both classifications
with some name changes (theory of computation has become
algorithms and data structures, applications has become
computational science, hardware systems has become architecture,
operating systems has added networks, and database has added
information retrieval as important new directions).

Though the high-level classification has remained stable, the
content of each area has evolved and matured. We examine below the
scope of each area and the topics within each area treated in
the Handbook.

\subsection{Algorithms and Data Structures}

The subfield of algorithms and data structures is interpreted
broadly to include core topics in the theory  of computation as
well as data structures and practical algorithm techniques. Its
thirteen chapters provide a comprehensive overview that spans
both theoretical and applied topics in the analysis of
algorithms. Chapter 3 introduces fundamental concepts such as
computability and undecidability and formal models such as
Turing machines and Chomsky grammars, while Chapter 4 reviews
techniques of algorithm design like divide and conquer, dynamic
programming, recurrence relations, and greedy heuristics.

Chapter 5 covers data structures both descriptively and in
terms of their space--time complexity, while Chapter 6
reviews methods and techniques of computational geometry, and
Chapter 7 presents the rich area of randomized objects.
Pattern matching and text compression algorithms are examined in
Chapter 8, graph and network algorithms in Chapter 9, and
algebraic algorithms in Chapter 10. Chapter 11 examines topics
in complexity like P vs. NP, NP-completeness, and circuit
complexity, while Chapter 12 examines parallel algorithms, and
Chapter 13 considers combinatorial optimization. Chapter 14
concludes section I with a case study in VLSI layout that makes use
of partitioning, divide and conquer, and other algorithm
techniques common in VLSI design.

\subsection{Architecture}

Computer architecture is the design of efficient and effective
computer hardware at all levels, from the most fundamental
concerns of logic and circuit design to the broadest concerns of
parallelism and high-performance computing. The chapters in section II
span all these levels, providing a sampling of the
principles, accomplishments, and applications of modern computer
architectures.

Chapters 15 and 16 introduce the fundamentals of logic design
components, including elementary circuits, Karnaugh maps,
programmable array logic, circuit complexity and minimization
issues, arithmetic processes, and speedup techniques. The
architecture of\, buses is covered in  Chapter 17, while the
principles of memory architecture are addressed in Chapter 18.
Topics there include associative memories, cache design,
interleaving, and memories for pipelined and vector processors.

Chapter 19 concerns the design of effective and efficient computer
arithmetic units. Chapter 20 extends the design horizon by
considering the various models of parallel architectures,
including the performance of contemporary machines that fall
into the SIMD, MISD, and MIMD categories.

\subsection{Artificial Intelligence and Robotics}

Artificial intelligence (AI) is the study of the computations
that make it possible to simulate human perception, reasoning,
and action. Current efforts are aimed at constructing
computational mechanisms that process visual data, understand
speech and written language, control robot motion, and model
physical and cognitive processes. Robotics is a complex field,
drawing heavily from AI as well as other areas of science and engineering.

AI includes techniques for automated learning, planning, and
representing knowledge. Chapter 21 opens this section with a
discussion of deductive learning. The use of decision trees and
neural networks in learning and other areas is the subject of
Chapters 22 and 23, while Chapter 24 introduces genetic algorithms.

Chapter 25 focuses on the area of computer vision. Chapter
26 addresses issues related to the mechanical understanding
of spoken language. Chapter
27 presents the rationale and uses of planning and scheduling
models in AI research. Chapter 28 describes the principles of
knowledge representation and their applications in natural-language
 processing (NLP).

Artificial-intelligence work requires a number of distinct tools
and models. These include the use of fuzzy, temporal, and other
logics, as described in Chapter 29. The use of a variety of
specialized search techniques to address the combinatorial
explosion of alternatives in many AI problems is the subject of
Chapter 30. Many AI applications must handle the notion of
uncertainty.  Chapter 31 discusses the modeling of decision
making under uncertainty, while the related idea of qualitative
modeling is discussed in Chapter 32.

Chapter 33 concludes section III with a thorough discussion of the
principles and major results in the field of robotics: the
design of effective devices that simulate mechanical, sensory,
and intellectual functions of humans in specific task domains
such as factory production lines.

\enlargethispage{-0.7pc}
\subsection{Computational Science}

The emerging area of computational science unites computational
simulation, experimental investigations, and theoretical
pursuits as three fundamental modes of scientific discovery. It
uses scientific visualization, made possible by computational
simulation, as a window into the analysis of physical phenomena
and processes, providing a virtual microscope/telescope for
inquiry and investigation at an unprecedented level of detail.

Section IV focuses on the challenges and opportunities offered
by computers in aiding scientific analysis and engineering
design. Chapter 34 introduces the section by presenting the
fundamental subjects of computational geometry and grid
generation. The design of graphical models for scientific
visualization of complex physical and biological phenomena is
the subject of Chapter 35.

Each of the remaining chapters in this section covers the
computational science challenges and discoveries in a particular
scientific or engineering field. Chapter 36 presents the
computational aspects of structural mechanics, while Chapter 37
does the same for fluid dynamics. Computational reacting flow is
the subject of Chapter 38, while Chapter 39 summarizes the
progress in the area of computational electromagnetics. Chapter
40 addresses the grand challenge of computational ocean
modeling. This section closes with a discussion of computational
biological modeling in Chapter 41.

\subsection{Database and Information Retrieval}

The subject area of database and information retrieval addresses
the general problem of storing large amounts of data in such a
way that they are reliable, up to date, and efficiently
retrieved. This problem is prominent in a wide range of
applications in industry, government, and academic research.
Availability of such data on the Internet and in forms other than
text (e.g., audio and video) makes this problem increasingly complex.

At the foundation are the fundamental data models (relational,
hierarchical, entity--relationship, network, and
object-oriented) discussed in Chapter 42. The conceptual,
logical, and physical levels of designing a database for high
performance in a particular application domain are discussed in
Chapter 43.performance in a particular application domain are discussed in
Chapter 43.


A number of basic issues surround the design of database models
and systems. These include choosing from alternative access
methods (Chapter 44), optimizing database queries (Chapter 45),
controlling concurrency (Chapter 46), and benchmarking database
workloads and performance (Chapter 47).

The design of heterogeneous databases and interoperability is
discussed in Chapter 48. The issue of database security and
privacy protection, in stand-alone and networked environments, is
the subject of Chapter 49. The special considerations involved
in storing and retrieving information from text databases are
covered in Chapter 50.

A special topic in database research is the study of deductive
(rule-based) databases, addressed in Chapter 51. Chapter 53
closes section V with a case study on SQL, a widely used database
query language standard.

\subsection{Graphics}

Computer graphics is the study and realization of complex
processes for representing physical and conceptual objects
visually on a computer screen. These processes include the
internal modeling of objects, rendering, hidden-surface
elimination, color, shading, projection, and representing motion.
An overview of these processes and their interaction is
presented in Chapter 54.

Fundamental to all graphics applications are the processes of
modeling and rendering. Modeling is the design of an effective
and efficient internal representation for geometric objects
(points, lines, polygons, solids, fractals, and their
transformations), which is the subject of Chapters 55 and 56.
Rendering, the process of representing the objects in a
three-dimensional scene on a two-dimensional screen, is
discussed in Chapter 57. Among its special challenges are the
elimination of hidden surfaces, color, illumination, and shading.

The reconstruction of scanned images is another important area
of computer graphics. Sampling, filtering, reconstruction, and
antialiasing are the focus of Chapter 58. The representation
and control of motion, or animation, is another complex and
important area of computer graphics. Its special challenges are
presented in Chapter 59.

Chapter 60 discusses volume data sets, and Chapter 61 looks at
the emerging field of virtual reality and its particular
challenges for computer graphics. Chapter 62 concludes section VI
with a discussion of Renderman as a case study of a particularly
effective application of the principles of computer graphics in
the real world.

\enlargethispage{-1pc}
\subsection{Human--Computer Interaction}

This area, the study of how humans and computers interact, has
the goal of improving the quality of the interaction and the
effectiveness of those who use technology. This includes the
conception, design, implementation, risk analysis, and effects
of user interfaces and tools on those who use them in their work.

Chapter 63 opens section VII with a discussion of methods of
overall system modeling, including users and modes of use.
Modeling the organizational environments in which technology
users work is the subject of Chapter 64. Usability engineering
is the focus of Chapter 65, while user interface design methods
are discussed in Chapter 66. The impact of international
standards for user interfaces on the design process is the main
concern of Chapter 67.

Specific devices, tools, and techniques for effective
user-interface design form the basis for the next few chapters
in this section. Chapters 68 and 69 discuss, respectively, the
characteristics of input devices like the mouse and keyboard and
output devices like computer screens and multimedia audio
devices. Chapter 70 focuses on design techniques for effective
interaction with users through these devices. The special
concerns for integrating multimedia with user interaction are
presented in Chapter 71. Lower-level concerns for the design of
interface software technology are addressed in Chapter 72. The
programming and software development process for user-interface
implementation is discussed in Chapter 73.
The effective presentation of documentation, training, and help
facilities for users is a perennial concern for software
designers, and its current status is reviewed in Chapter 74.
%Chapter 95 concludes this section with a case study of human--computer
%interaction that reviews its effective uses in education.

\subsection{Operating Systems and Networks}

Operating systems form the software interface between the
computer and its applications. Section VIII covers their
analysis and design, their performance, and their special
challenges in a networked computing environment. Chapter 75
briefly traces the historical development of operating systems
and introduces the fundamental terminology, including process
scheduling, memory management, synchronization, I/O management,
and distributed systems.

The process is a key unit of abstraction in operating-system
design. Chapter 76 discusses the dynamics of processes and
threads. Strategies for process and device scheduling are
presented in Chapter 77. The special requirements  for
operating systems in real-time and embedded system environments
are the subject of Chapter 78. Algorithms and techniques for
process synchronization and interprocess communication are the
subject of Chapter 79.

Memory and input/output device management is also a central
concern of operating  systems. Chapter 80 discusses the concept
of virtual memory, from its early incarnations to its uses in
present-day systems and networks. The different types and access
methods for secondary storage and file systems are covered in
Chapter 81.

Extending operating system functionality across a networked
environment adds another level of complexity to the design
process. Chapter 82 presents an overview of network
organization and topologies, while Chapter 83 describes network
routing protocols. The topology and functionality of
internetworking, with the Internet as prime example, are presented in
Chapter 84. 
%Special topics in network design include the need
%for high-capacity networks to transmit voice and video data in
%real time, as discussed in Chapter 107.

The influence of networked environments on the design of
distributed operating systems is considered in Chapter 85.
Distributed file and memory systems are discussed in Chapter
86, while distributed and multiprocessor scheduling are the
focus of attention in Chapter 87. Finally, the forward-looking
notion of dynamically partitioning a computing task across a
network of heterogeneous computers is the topic of Chapter 88.

Operating systems and networks, especially the Internet, must make
provisions for ensuring system integrity in the event of
inappropriate access, unexpected malfunction and breakdown, and
violations of security or privacy principles. Chapter 89
introduces some of the security and privacy issues that arise in
a networked environment. Models for system security and
protection are the subject of Chapter 90, while Chapter 91
discusses authentication, access control, and intrusion
detection. Chapter 92 focuses on security issues that arise in
networks, while a case discussion of some noteworthy malicious
software and hacking events appears in Chapter 93.

%%\enlargethispage{-1pc}
\subsection{Programming Languages}

In section IX the design space of programming languages is partitioned
into paradigms, mechanisms for compiling, and run-time
management, and the theoretical areas of foundational models,
type systems, and semantics are examined. Overall, this section provides a
good balance between considerations of language paradigms,
implementation issues, and 

Chapter 94 considers traditional language and implementation
questions for imperative programming languages like Fortran, C,
Pascal, and Ada 83. Chapter 95 considers topics in functional
programming like lazy and eager evaluation, and Chapter 96
examines object-oriented concepts like classes, inheritance,
encapsulation, and polymorphism. Chapter 97 considers
declarative programming in the logic/constraint programming
paradigm, while Chapter 98 considers issues in
concurrent/distributed programming as well as parallel models of
computation. Compilers and interpreters for sequential languages
are considered in Chapter 99, while compilers for parallel
architectures and dataflow languages are considered in Chapter
100. The issues surrounding run-time environments and memory
management for compilers and interpreters are addressed in
Chapter 101.

Chapters 102, 103, and 104 deal with foundations and
theoretical models. Chapter 102 deals with foundational
calculi like the lambda calculus and the pi calculus and with the
influence of input/output automata, Petri nets, and other models
of computation on language design. Chapter 103 examines issues
of type theory in programming, including static versus dynamic
type checking, type safety, and polymorphism. Chapter 104
examines models of programming-language semantics, including
denotational, operational, and axiomatic models.

%%\enlargethispage{-1pc}
\subsection{Software Engineering}

Section X on software engineering examines formal specification,
design, verification and testing, project management, and other
aspects of the software life cycle. Chapter 105 considers models
of the software life cycle such as the waterfall and spiral
models as well as specific phases of the life cycle. Chapter
106 examines software qualities like maintainability,
portability, and reuse that are needed for high-quality software
systems, while Chapter 107 considers formal models,
specification languages, and the specification process.

Chapter 108 deals with the traditional and
object-oriented design processes, featuring a case study in
top-down functional design. Chapter 109 on verification and
validation deals with the use of systematic techniques like
verification and testing for quality assurance, while Chapter
110 examines testing models as well as risk and reliability issues.

Chapter 111 considers methods of project design such as chief
programmer teams and rapid prototyping, as well as project
scheduling and evaluation. Chapter 112 considers software tools
like compilers, editors, and CASE tools and surveys graphical
environments. Chapter 113 on interoperability considers
architectures for communicating among heterogeneous software
components such as OMG's Common Object Request Broker
Architecture (CORBA) and Microsoft's Common Object Model (COM).

\GH{Glossary}
\begin{gloss}
\item[Term 1]
This is definition of Term 1.
This is definition of Term 1.
This is definition of Term 1.
This is definition of Term 1.
\item[Term 2]
This is definition of Term 2.
This is definition of Term 2.
This is definition of Term 2.
This is definition of Term 2.
\item[Term 3]
This is definition of Term 3.
This is definition of Term 3.
This is definition of Term 3.
This is definition of Term 3.
\item[Term 4]
This is definition of Term 4.
This is definition of Term 4.
This is definition of Term 4.
This is definition of Term 4.
\item[Term 5]
This is definition of Term 5.
This is definition of Term 5.
This is definition of Term 5.
This is definition of Term 5.
\item[Term 6]
This is definition of Term 6.
This is definition of Term 6.
This is definition of Term 6.
This is definition of Term 6.
\item[Term 7]
This is definition of Term 7.
This is definition of Term 7.
This is definition of Term 7.
This is definition of Term 7.
\end{gloss}

\section{Conclusion}

\noindent 
In 1997, the ACM celebrates its 50th anniversary. The first 50
years of CS\&E are characterized by dramatic growth and
evolution. While it is safe to affirm today that the field has
reached a certain level of maturity, it would be foolish to
assume that it will remain unchanged in the future. Already,
conferences are calling for new visions that will enable the
discipline to continue its rapid evolution into the twenty-first
century. This Handbook is designed to convey the modern spirit,
accomplishments, and direction of CS\&E as we see it in 1996. It
interweaves theory with practice, highlighting ``best practices''
in the field as well as current research directions. It provides
today's answers to well-formed questions posed by professionals
and researchers across the ten major subject areas. Finally, it
identifies key professional and social issues that lie at the
intersection of the technical aspects of CS\&E and its impact in
the world.

The future holds great promise for the next generations of
computer scientists and engineers. These people will solve
problems that have only recently been conceived, such as those
suggested by the HPCC as ``grand challenges.'' To address these
problems, and to extend these solutions in a way that benefits
the lives of significant numbers of the world's population, will
require substantial energy, commitment, and real investment on
the part of institutions and professionals throughout the world.
The challenges are complex, and the solutions are not likely to
be obvious.


\bibliographystyle{alpha}
\bibliography{example}


%\begin{thebibliography}{}
%\bibitem{}
%ACM Curriculum Committee on Computer Science 1968. Curriculum 68:
%recommendations for the undergraduate program in computer
%science. {\it Commun. ACM} 11(3):151--97, Mar.
%
%\bibitem{}
%ACM Curriculum Committee on Computer Science 1978. Curriculum 78:
%recommendations for the undergraduate program in computer
%science. {\it Commun. ACM} 22(3):147--166, Mar.
%
%\bibitem{}
%ACM Task Force on the Core of Computer Science: Denning,
%P., Comer, D., Gries, D., Mulder, M., Tucker, A., and Young, P., 1988.
%{\it Computing as a Discipline}. Abridged version, {\it Commun. ACM}, Jan. 1989. 
%
%\bibitem{}
%ACM/IEEE Joint
%Curriculum Task Force 1991. Computing Curricula 1991. ACM Press.
%Abridged version, {\it Commun. ACM}, June 1991, and {\it IEEE Comput.}
%Nov. 1991.
%
%\bibitem{}
%Andrews, G. R., 1995. CRA Taulbee Survey: PhDs Holding Steady.
%Computing Research Assoc.
%
%\bibitem{}
%Arden, B., ed. 1980. {\it What Can be Automated\,?}
%Computer Science and Engineering Research (COSERS) Study. MIT Press, Boston, MA.
%
%\bibitem{}
%CSNRCTB 1992. Computer Science and National Research Council
%Telecommunications Board. {\it Computing the Future: A Broader Agenda
%for Computer Science and Engineering}. National Academy Press, Washington, DC.
%
%\bibitem{}
%Economist 1993. The computer industry: reboot system and start
%again. {\it Economist}, Feb. 27.
%
%\bibitem{}
%IEEE-CS 1976. Education Committee of the IEEE Computer Society.
%{\it A Curriculum in Computer Science and Engineering}. IEEE Pub.
%EH0119-8, Jan. 1977.
%
%\bibitem{}
%IEEE-CS 1983. Educational Activities Board. {\it The 1983 Model
%Program in Computer Science and Engineering. Tech. Rep. 932}.
%Computer Society of the IEEE, Dec. 
%
%\bibitem{}
%Kling, R. 1993. Organizational analysis in computer science. {\it Inform. Soc.}
%Mar.--June.
%
%\bibitem{}
%NSF 1995a. National Science Foundation. {\it Survey of Scientific and
%Engineering Expenditures at Universities and Colleges}. NSF,
%Arlington, VA. 
%
%\bibitem{}
%NSF 1995b. National Science Foundation. {\it Nonacademic Scientists
%and Engineers: Trends from the 1980 and 1990 Censuses}. NSF
%95-306. Arlington, VA.
%
%\bibitem{}
%OST 1989. Office of\, Science and Technology. {\it The Federal High
%Performance Computing and Communication Program.} Executive
%Office of the President, Washington, DC. 
%
%\bibitem{}
%Rosser, J. B. et al. 1966. {\it Digital Computer Needs in Universities
%and Colleges}. Publ. 1233, National Academy of Sciences, National
%Research Council, Washington, DC.
%
%\bibitem{}
%Stevenson, D. E. 1994. Science, computational science, and
%computer science. {\it Commun. ACM}, Dec.
%\end{thebibliography}
