\documentclass{article}
\usepackage{fullpage}
\setlength{\parskip}{1ex}
\newcommand{\problem}[1]{\section*{#1}}
\newcommand{\polylog}{\log^{O(1)}}

\title{Notes on Simultaneous Planar Point Location}

\begin{document}
\maketitle

\section{Introduction}

Let $S_1,\ldots,S_k$ each be sets of lines in the plane.  Each set
$S_i$ contains $n$ parallel lines, but the lines in $S_j$ are not
parallel to the lines in $S_i$, for $i\neq j$.  The problem is to
preprocess $S_1,\ldots,S_k$ into a data structure so that for any
query point $q$ we can return, for each $1\le i\le k$, the line in
$S_i$ that is directly above $q$. 

This problem is a generalization of 1-dimensional iterated search,
which can be solved optimally (using $O(kn)$ space and $O(k+\log n)$
query time) using fractional cascading \cite{cg86}.  It is also a
special case of 2-dimensional iterated point location: Given $k$
planar subdivisions $S_1,\ldots,S_k$ each of size $O(n)$ preprocess
them so that for any query point $q$ we can determine, for each $1\le
i\le k$, which face of $S_i$ contains $q$. The time-space tradeoff
based on cuttings (below) works also for this generalized problem.
There seems to be no obvious existing lower bound result to imply that
an $O(kn)$ space $O(k+\log n)$ query time data structure should not
exist even for the general point-location problem.  Like fractional
cascading, such a solution could (if general enough) lead to improved
query times for many multi-level range searching data structures for
which the secondary structure is a planar subdivision.

Finally, we note that this problem is even of interest when $k$ is
small, in which case the problem is to minimize the exact number of
point-line comparisons used by the data structure.  For $k=1$ the
trivial data structure is optimal since $\log_2 (n+1)$ is a lower
bound on the number of comparisons and binary search achieves this.
For $k=2$ the trivial data structure is also optimal since the
arrangement of the $2n$ lines has $(n+1)^2$ cells so $2\log_2 (n+1)$
comparisons are necessary.  However, for $k=3$ the arrangement only
has $O(n^2)$ cells so the only lower bound on the number of tests
required is $2\log_2 n + o(\log n)$.  A first open problem is to find
a linear size data structure that uses $c\log_2 n + o(\log n)$
comparisons with $c<3$ for the case $k=3$. 


\section{Trivial Solutions}

This problem has two trivial solutions.  Sorting each $S_i$ gives a
data structure of optimal size $O(kn)$ with query time $O(k\log n)$.
At the other extreme, we can compute the arrangement of
$\bigcup_{i=1}^k S_i$, preprocess it for point location and label each
cell with the solution.  This gives an $O(k^3n^2)$ space data
structure with optimal query time $O(k + \log n)$.  (The space can
probably be reduced to $O(k^2n^2)$ by using a walking trick, like in
Bose, Lubiw and Munro \cite{blm02}.)

\section{A Time-Space Tradeoff Using Cuttings}

Here is a time-space tradeoff using cuttings \cite{m98}. Take a
$\frac{x}{n}$-cutting of the input lines.  This gives a triangulation
of the plane consisting of $c(kn)^2/x^2$ triangles, each of which
intersects at most $x$ of the input lines.  With each triangle
$\Delta$ of the cutting, we store a trivial data structure for the
sets $S_1^\Delta,\ldots,S_k^\Delta$, where each $S_i^\Delta$ is the
subset of $S_i$ that intersects $\Delta$ plus the (at most) one line
of $S_i$ that passes directly above $\Delta$.  This data structure
uses space $O(k(kn)^2/x^2)$.  To perform a query in this data
structure we do an $O(\log (n/x))$ time point location query in the
cutting to locate the triangle $\Delta_q$ that contains $q$ and then
use the trivial data structure for $\Delta_q$ to complete the query in
$O(k\log x)$ time.  Thus, queries take time $O(\log(n/x) + k\log x)$.
A particular interesting choice of $x$ is obtained with $x=n^{d/k}$.
In this case, the space becomes $O(k(kn)^{2-2d/k}))$ and the query
time becomes $O(k + d\log n)$.  (One of the $k$ factors in the space
can gotten rid of by using hierarchichal cuttings.)

\section{A Time-Space Tradeoff Using Biased Search Trees}

Consider the case $k=3$.  Suppose $S_1$ contains diagonal lines, $S_2$
contains vertical lines and $S_3$ contains horizontal lines. Define
the \emph{weight} of a diagonal slab as the number of intersections
that occur in that slab.  Select $r-1$ equally spaced elements of
$S_1$ in order to define $r$ diagonal \emph{superslabs}.  Store these
slabs in a weight-biased search tree based on their weight.  The time
to determine which diagonal slab a query point lies in is then $\log
(n^2/I) + \log (n/r) + O(1)$, where $I$ is the number of intersections
that occur in the superslab.  Now, for each superslab we store the $n$
vertical slabs in a weight-biased search tree where the weight of a
vertical slab is the number of horizontal lines that intersects that
vertical slab within its enclosing diagonal superslab.  The total
weight in this tree is $I$ and the time to search for a node is $\log
(I/H)$ where $H$ is the number of horizontal lines that intersects
that vertical slab inside its enclosing superslab. Notice that the set
of $H$ horizontal lines that intersect that slab is a contiguous
subset of the $H$ horizontal lines and can be specified as two indices
into an array.  Given these indices, the location of the query point
in $S_3$ can be found in an additional $\log H + O(1)$ time.

Thus, the total query time is $\log (n^2/I) + \log(I/H) + \log H +
\log (n/r)+O(1)= 2\log n+\log(n/r)+O(1)$ and the total space is
$O(nr)$.  Taking, for example $r=\sqrt{n}$ given $O(n^{3/2})$ space
and $2.5\log n + O(1)$ query time.

This solution generalizes to arbitrary values of $k$ in a
straightforward way, giving about the same tradeoff as the solution
based on cuttings.

\section{A Near-Linear Space Solution}

Let $m=kn$. In the dual, our $m$ lines become $m$ points, all of which
lie on $k$ vertical lines.  Given a query line, we are asked to find
the lowest point on each of the $k$ vertical lines that is above our
query line.  Alternatively, we can join consecutive points on the
lines to get a set of $m+k$ vertical line segments ($2k$ of these are
infinite) and our query asks for the set of all segments intersected
by a query line.  (The upper endpoints of these segments are the
answers to our query.)

Matou\v{s}ek \cite[Lemma~6.3]{m92} describes a data structure that
stores a set of $n$ line segments, is of size $O(n\polylog n)$, can be
constructed in $O(n\polylog n)$ time, and that can return the set of
line segments intersected by any query line in $O(\sqrt{n}\polylog n+
k)$ time.  Using this data structure gives a near-linear space data
structure that answers our queries in $O(\sqrt{nk}\polylog n + k)$.

Does this solution generalize to the case where we have $k$ planar
subdivisions?  We can store the segments of our subdivisions in a
segment tree so that we can extract, in $O(\log n)$ time a set of
$O(\log n)$ canonical subsets of line segments that overlap the
$x$-coordinate of our query point.  Now, if we dualize each canonical
subset we get a set of points coming from $k$ color classes and we can
connect the points of each color class into $k$ $y$-monotone chains.
Now, storing these chains in Matou\v{s}ek's structure (as above)
allows us to find all the (at most $k$) segments intersecting our
query line in $O(\sqrt{|S|}\polylog n + k)$ time, where $S$ is the
canonical subset in question.  Unfortunately, we have $O(\log n)$
canonical subsets, so we get an overall query time of
$O(\sqrt{n}\polylog n + k\log n)$.  Can we use fractional cascading
within each color class to get rid of the $\log n$ factor on the
second term?


\bibliographystyle{plain}
\bibliography{simul}
\end{document}
