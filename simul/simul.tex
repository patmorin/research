\documentclass{article}
\usepackage{fullpage}
\setlength{\parskip}{1ex}
\newcommand{\problem}[1]{\section*{#1}}

\title{Notes on Simultaneous Planar Point Location}

\begin{document}
\maketitle

\section{Introduction}

Let $S_1,\ldots,S_k$ each be sets of lines in the plane.  Each set
$S_i$ contains $n$ parallel lines, but the lines in $S_j$ are not
parallel to the lines in $S_i$, for $i\neq j$.  The problem is to
preprocess $S_1,\ldots,S_k$ into a data structure so that for any
query point $q$ we can return, for each $1\le i\le k$, the line in
$S_i$ that is directly above $q$. 

This problem is a generalization of 1-dimensional iterated search,
which can be solved optimally (using $O(kn)$ space and $O(k+\log n)$
query time) using fractional cascading \cite{cg86}.  It is also a
special case of 2-dimensional iterated point location: Given $k$
planar subdivisions $S_1,\ldots,S_k$ each of size $O(n)$ preprocess
them so that for any query point $q$ we can determine, for each $1\le
i\le k$, which face of $S_i$ contains $q$. The time-space tradeoff
based on cuttings (below) works also for this generalized problem.
There seems to be no obvious existing lower bound result to imply that
an $O(kn)$ space $O(k+\log n)$ query time data structure should not
exist even for the general point-location problem.  Like fractional
cascading, such a solution could (if general enough) lead to improved
query times for many multi-level range searching data structures for
which the secondary structure is a planar subdivision.

Finally, we note that this problem is even of interest when $k$ is
small, in which case the problem is to minimize the exact number of
point-line comparisons used by the data structure.  For $k=1$ the
trivial data structure is optimal since $\log_2 (n+1)$ is a lower
bound on the number of comparisons and binary search achieves this.
For $k=2$ the trivial data structure is also optimal since the
arrangement of the $2n$ lines has $(n+1)^2$ cells so $2\log_2 (n+1)$
comparisons are necessary.  However, for $k=3$ the arrangement only
has $O(n^2)$ cells so the only lower bound on the number of tests
required is $2\log_2 n + o(\log n)$.  A first open problem is to find
a linear size data structure that uses $c\log_2 n + o(\log n)$
comparisons with $c<3$ for the case $k=3$. 


\section{Trivial Solutions}

This problem has two trivial solutions.  Sorting each $S_i$ gives a
data structure of optimal size $O(kn)$ with query time $O(k\log n)$.
At the other extreme, we can compute the arrangement of
$\bigcup_{i=1}^k S_i$, preprocess it for point location and label each
cell with the solution.  This gives an $O(k^3n^2)$ space data
structure with optimal query time $O(k + \log n)$.  (The space can
probably be reduced to $O(k^2n^2)$ by using a walking trick, like in
Bose, Lubiw and Munro \cite{blm02}.)

\section{A Time-Space Tradeoff Using Cuttings}

Here is a time-space tradeoff using cuttings \cite{m98}. Take a
$\frac{x}{n}$-cutting of the input lines.  This gives a triangulation
of the plane consisting of $c(kn)^2/x^2$ triangles, each of which
intersects at most $x$ of the input lines.  With each triangle
$\Delta$ of the cutting, we store a trivial data structure for the
sets $S_1^\Delta,\ldots,S_k^\Delta$, where each $S_i^\Delta$ is the
subset of $S_i$ that intersects $\Delta$ plus the (at most) one line
of $S_i$ that passes directly above $\Delta$.  This data structure
uses space $O(k(kn)^2/x^2)$.  To perform a query in this data
structure we do an $O(\log (n/x))$ time point location query in the
cutting to locate the triangle $\Delta_q$ that contains $q$ and then
use the trivial data structure for $\Delta_q$ to complete the query in
$O(k\log x)$ time.  Thus, queries take time $O(\log(n/x) + k\log x)$.
A particular interesting choice of $x$ is obtained with $x=n^{d/k}$.
In this case, the space becomes $O(k(kn)^{2-2d/k}))$ and the query
time becomes $O(k + d\log n)$.  (One of the $k$ factors in the space
can be traded for an $n^\epsilon$ factor using a hierarchy of
cuttings.) 

\section{A Time-Space Tradeoff Using Biased Search Trees}

Consider the case $k=3$.  Suppose $S_1$ contains diagonal lines, $S_2$
contains vertical lines and $S_3$ contains horizontal lines. Define
the \emph{weight} of a diagonal slab as the number of intersections
that occur in that slab.  Select $r-1$ equally spaced elements of
$S_1$ in order to define $r$ diagonal \emph{superslabs}.  Store these
slabs in a weight-biased search tree based on their weight.  The time
to determine which diagonal slab a query point lies in is then $\log
(n^2/I) + \log (n/r) + O(1)$, where $I$ is the number of intersections
that occur in the superslab.  Now, for each superslab we store the $n$
vertical slabs in a weight-biased search tree where the weight of a
vertical slab is the number of horizontal lines that intersects that
vertical slab within its enclosing diagonal superslab.  The total
weight in this tree is $I$ and the time to search for a node is $\log
(I/H)$ where $H$ is the number of horizontal lines that intersects
that vertical slab inside its enclosing superslab. Notice that the set
of $H$ horizontal lines that intersect that slab is a contiguous
subset of the $H$ horizontal lines and can be specified as two indices
into an array.  Given these indices, the location of the query point
in $S_3$ can be found in an additional $\log H + O(1)$ time.

Thus, the total query time is $\log (n^2/I) + \log(I/H) + \log H +
\log (n/r)+O(1)= 2\log n+\log(n/r)+O(1)$ and the total space is
$O(nr)$.  Taking, for example $r=\sqrt{n}$ given $O(n^{3/2})$ space
and $2.5\log n + O(1)$ query time.

This solution generalizes to arbitrary values of $k$ in a
straightforward way, giving about the same tradeoff as the solution
based on cuttings.

\section{A Linear Space Solution}

Let $m=kn$. In the dual, our $m$ lines become $m$ points, all of which
lie on $k$ vertical lines.  Given a query line, we are asked to find
the lowest point on each of the $k$ vertical lines that is above our
query line.  Alternatively, we can join consecutive points on the
lines to get a set of $m+k$ vertical line segments ($2k$ of these are
infinite) and our query asks for the set of all segments intersected
by a query line.  (The upper endpoints of these segments are the
answers to our query.)

Partition our $m$ points into 6 sets using one vertical line to split
the sets of vertical lines into 2 equal pieces and one vertical plus
one horizontal line to split the points into $4$ equal pieces.  This
splits our intervals into 6 sets of size total size $m+k$ and maximum
size $m/4+k/2$.  Recursively build a partition tree this way.  

The total number of extra intervals that are created by splitting is
given by the recurrence
\[
   S_{m,k} \le k + \sum_{i=1}^6 S_{m_i,k_i}
\]
subject to
\[ m_i\le m/4 \]
\[ k_i\le k/2 \]
\[ \sum m_i=m \]
\[ \sum k_i \le 2k \enspace , \] 
which is bounded by $O(2^{\log_4 m})=O(\sqrt{m})$.  Check! Thus the
total space is $O(m+\sqrt{m}) = O(m)$.

The query time of this data structure is given by the recurrence
\[
  Q_{m,k} \le \sum_{i=1}^4 Q_{m_i,k_i}
\]
subject to the constraints
\[ m_i\le m/4 \]
\[ k_i\le k/2 \]
\[ \sum m_i\le 3m/4 \]
\[ \sum k_i\le 3k/2 \enspace , \] 
which is bounded by $O(k+n^{\log_4 3})=O(k+n^{0.79})$.  Check!

\section{A Heavyweight Solution}

An $O(n)$ space, $O(\sqrt{n} + k)$ query time solution can
be obtained using Matou\v{s}ek's efficient partition trees.  In his
triangle finding/assignment algorithm, assign the $n/r$ points to the
triangle he wants, but leave the bottom (at most $k$ points) in the
set.  This causes at most $k\sqrt{r}$ points to appear in more than
one triangle.  We then get a recurrence for the space of the form
\[
    S_{m,k} = \sum_{i=1}^r S_{m_i+k_i,k_i}
\]
subject to 
\[ m_i \le 2n/r \enspace , \]
\[ \sum m_i=m \enspace , \]
and
\[ \sum k_i \le k\sqrt{r} \enspace . \] 
The base cases of this recurrence are:
$S_{m,1} = O(m)$ and $S_{1,k}=O(k)$

\bibliographystyle{plain}
\bibliography{simul}
\end{document}
