\documentclass[lotsofwhite]{patmorin}
\usepackage{graphicx,amsthm,amsfonts}

\usepackage[noend]{algorithmic}

\input{pat}


\title{
\MakeUppercase{Algorithms for Optimal Outlier Removal}%
\thanks{School of Computer Science. Carleton University. This work was partly funded by NSERC.}}

\author{Rossen Atanassov \and
	Prosenjit Bose \and
	Mathieu Couture \and
	Anil Maheshwari \and
	Pat Morin \and
	Michel Paquette \and
	Michiel Smid \and
	Stefanie Wuhrer
}

\date{}

\newcommand{\ch}{\mathrm{conv}}
\newcommand{\lbl}{\mathrm{label}}
\newcommand{\lft}{\mathrm{left}}
\newcommand{\rt}{\mathrm{root}}
\newcommand{\RETURN}[1]{\STATE{\textbf{return} #1}}

\newcommand{\ntypes}{C(2c)}
\newcommand{\timepertype}{(3c)^c n}
\newcommand{\runtime}{n\log n + \left({4c\choose 2c}(3c)^cn\right)}
\newcommand{\Oruntime}{O\left(\runtime\right)}

\begin{document}

\maketitle

\begin{abstract}
We consider the problem of removing $c$ points from a set $S$ of $n$
points so that the remaining point set is optimal in some sense.
Definitions of optimality we consider include having minimum diameter,
having minimum area (perimeter) bounding box, having minimum area
(perimeter) convex hull.  For constant values of $c$, all our
algorithms run in $O(n\log n)$ time.
\end{abstract}

\section{Introduction}

Motivated by the problem of removing outliers in a data set, this
paper considers the following problem: Let $S$ be a set of $n$ points
in $\mathbb{R}^2$ and let $f:2^{\mathbb{R}^2}\mapsto \mathbb{R}$ be a
function mapping point sets onto real values.  We consider the problem
of selecting a subset $S'\subseteq S$, $|S'|=c$ such that
$f(S\setminus S')$ is minimum.  The objective functions $f$ that we
consider are:
\begin{enumerate}
\item $f(X)$ is the diameter of $X$,
\item $f(X)$ is the area/perimeter of the smallest axes-parallel
rectangle containing $X$, and
\item $f(X)$ is the area/perimeter of the convex hull of $X$.
\end{enumerate}  

We call these problems the \emph{$f$-based $c$ outlier removal problems}.
We are particularly interested in the case when $c$ (the number of
outliers) is small.

\subsection{Previous Work.} 

The outlier removal problems stated above and similar problems are
fairly well-studied problems in the field of computational geometry.
However, most work thus far has focused on the case when $c$ is
large.\footnote{One notable exception to this statement is the work on
linear programming with $c$ violations, which includes the problem of
finding a subset $S'$ of $S$, $|S'|=c$ such that the radius of the
smallest disk containing $S\setminus S'$ is minimum.  For this
problem, Matou\v{s}ek gives an $O(n\log n + c^3 n^{\epsilon})$ time
algorithm \cite{m95} and Chan \cite{c05} gives an $O(n\beta(n)\log n +
c^2n^\epsilon)$ time algorithm, where $\epsilon >0$ is an arbitrarily
small constant and $\beta(\cdot)$ is related to the inverse Ackermann
function.} More specifically, most research has been on the problem of
finding a $k$ point subset (a $k$-cluster) $X\subseteq S$, $|X|=k$,
such that $f(X)$ is minimum. These are the same problems studied in
the current paper with $k=n-c$ except that our focus is on large
values of $k$ (small $c$) and most existing research focuses on
designing efficient algorithms for small values of $k$.

\paragraph{Minimum Diameter.} The problem of finding a subset of $S$ of size
$k$ with minimum diameter has been studied by Aggarwal \etal\
\cite{aiks89} who give an $O(k^{2.5}n\log k+n\log n)$ time algorithm.
Using a different approach, Eppstein and Erickson \cite{ee94} improve
the running time to $O(n\log n + k^2 n\log^2 k)$.

\paragraph{Minimum-Perimeter/Area Enclosing Rectangle.} Aggarwal
\etal\ \cite{aiks89} also give an $O(k^2n\log n)$ time algorithm to
find the subset of $S$ with the minimum-perimeter enclosing
axes-parallel rectangle.  Eppstein and Erickson \cite{ee94} improve
the running time to $O(n\log n + k^2 n)$.  Segal and Kedem \cite{sk98}
present an algorithm for this problem that runs in $O(n+k(n-k)^2)$
time using $O(n)$ space, provided $\frac{n}{2}<k\le n$. Their
algorithm can also find the minimum area rectangle.

\paragraph{Minimum-Perimeter/Area Convex Hull.} The problem of finding a
subset of $S$ of size $k$ that has the least perimeter convex hull was
first considered over 20 years ago by Dobkin \etal\ \cite{ddg83} who
gave an $O(k^2n\log n + k^5 n)$ time algorithm.  This algorithm can be
improved to run in $O(k^2 n\log n + k^4 n)$ time using techniques of
Aggarwal \etal\ \cite{aiks89}.  Eppstein and Erickson \cite{ee94} hold
the record with a running time of $O(n\log n + k^3 n)$.

\comment{
The algorithms mentioned above are all based on the fact that the $k$
points that define the solution are a subset of the $k'$ points that
define some cell in the order-$k'$ \voronoi\ diagram \cite{obs92},
where $k'=O(k)$ depends on the particular function $f$. This allows
these problem to be solved, once the order-$k$ \voronoi\ diagram is
computed, by considering $O(k'n)$ subproblems each of size
$k'$.}

The problem of finding a subset of $S$ of size $k$ that has the
minimum area convex hull was considered by Eppstein \etal\
\cite{eorw92} and later by Eppstein \cite{e93} who give $O(kn^{3})$
and $O(n^2\log n + k^3n^2)$ time algorithms for this problem,
respectively. \comment{The second algorithm (by Eppstein) uses the
first algorithm along with the fact that the $k$ points that define
the solution are among the $2k-4$ vertical nearest neighbours of one
of the $n\choose 2$ line segments determined by pairs of points in
$S$.  This allows the problem to be solved by considering $O(n^2)$
subproblems each of size $O(k)$.}

\comment{
An algorithm running in $O(k^2n\log n)$ time using $O(kn)$ space
to find an axes-parallel rectangle of
minimum perimeter that encloses $k$ points of $S$ is presented in
\cite{aiks89}. Eppstein and Erickson \cite{ee94} show that this problem can be solved in $O(n\log n+ k^2n)$ time using $O(kn)$ space, 
and the space complexity is further improved to $O(n)$ in Datta \etal\
\cite{dlss95}.  Segal and Kedem
\cite{sk98} present an algorithm for this problem which runs in
$O(n+k(n-k)^2)$ time using $O(n)$ space, provided $\frac{n}{2}<k\le
n$. Their algorithm can also find the minimum area rectangle.

The problem of finding a subset of $S$ of size $k$ that has the least
perimeter convex hull was first considered over 20 years ago by Dobkin
\etal\ \cite{ddg83} who gave an $O(k^2n\log n + k^5 n)$ time
algorithm.  This algorithm can be improved to run in $O(k^2 n\log n +
k^4 n)$ time using techniques of Aggarwal \etal\ \cite{aiks89}.  Both
algorithms are based on the fact that the $k$ points that define the
solution are a subset of the $k'$ points that define some cell in the
order $k'$ \voronoi\ diagram, where $k'=\ceil{\pi (k-1)}$.  This
allows the problem to be solved by considering $O(k'n)=O(kn)$ subproblems
each of size $k'=O(k)$.

The problem of finding a subset of $S$ of size $k$ that has the
minimum area convex hull was considered by Eppstein \etal\
\cite{eorw92} and later by Eppstein \cite{e93} who give $O(kn^{3})$
and $O((k^3+\log n) n^2)$ time algorithms for this problem,
respectively.  The second algorithm (by Eppstein) uses the first
algorithm along with the fact that the $k$ points that define the
solution are among the $2k-4$ vertical nearest neighbours of one of
the $n\choose 2$ line segments determined by pairs of points in $S$.
This allows the problem to be solved by considering $O(n^2)$
subproblems each of size $O(k)$.

Note that finding a subset $X\subseteq S$ of size $k$ whose convex hull
has minimum area generalizes the problem of determining if $S$
contains $k$ collinear points (in which case $S$ has a subset of size
$k$ whose convex hull has area 0).  For the case $k=3$, this problem is
one of the original \textsc{3-Sum}-hard problems \cite{go95} and is
conjectured to have an $\Omega(n^2)$ lower-bound in many models of
computation. However, for large values of $k$, the problem seems to
become easier, and Guibas \etal\ \cite{gor96} have an algorithm that
reports all lines containing at least $k$ points of $S$ in
$O((n^2/k)\log(n/k))$ time.  Notice that, for $k=\Omega(n)$, this
gives an $O(n)$ time algorithm, which offers hope that outlier removal
problems should have fast solutions for sufficiently small values of
$c$.
}

\subsection{New Results.}

For fixed values of $k$, the results described above give $O(n\log n)$
or $O(n^2\log n)$ time algorithms for finding the $k$ point subset of
$S$ that minimize $f$.  However, when $k$ is close to $n$ even the
fastest of the algorithms cited above require $\Omega(n^3)$ time.  

In the current paper we consider specifically the case when $k=n-c$.
For Problem~1 (diameter) we obtain an $O(n\log n + cn + c^6\log^2 c)$
time algorithm.  For problem~2 (minimum area/perimeter bounding
rectangle) we obtain an $O(n + c^3)$ time algorithm.  For Problem~3
(minimum area/perimeter convex hull) we obtain an $\Oruntime$ time
algorithm.  We also show, by giving $\Omega(n\log n)$ lower bounds for
both Problems~1 and 3 that, for constant values of $c$, our algorithms
are optimal.

The remainder of the paper is organized as follows: \secref{diameter}
presents an algorithm for the diameter-based $c$ outlier removal
problem.  \secref{box} present algorithms for the (bounding box)
area/perimeter-based $c$ outlier removal problems.  \secref{hull}
presents algorithms for (convex hull) area/perimeter-based $c$
outlier removal problems.  An abstract of the results in \secref{hull}
has appeared in the proceedings of the 18th Canadian Conference on
Computational Geometry \cite{amw06}.

\section{Minimizing Diameter}
\seclabel{diameter}

The \emph{diameter} of a set $X$ is defined as $\max\{\|pq\|:p,q\in
X\}$.  In this section we consider the \emph{diameter-based $c$ outlier
removal problem} of finding a subset $S'\subseteq S$, $|S'|=c$ such
that the diameter of $S\setminus S'$ is minimum over all choices of
$S'$.  We begin by showing that this problem has an $\Omega(n\log n)$
lower bound even for the case $c=1$.

\subsection{The Lower Bound}

\begin{thm}
In the algebraic decision tree model of computation the diameter-based
1 outlier removal problem has 
an $\Omega(n\log n)$ lower bound.
\end{thm}

\begin{proof}
Computing the diameter of a set $S$ of $n$ points in $\mathbb{R}^2$
has an $\Omega(n\log n)$ lower bound in the algebraic decision tree
model \cite{ps85}.  We simply observe that the point $x$ that defines
the optimal solution is one of the two points that define the diameter
of $S$. Thus, given $x$ we can compute the diameter of $S$ in $O(n)$
time by computing the distance from $x$ to every other point of $S$.
It must therefore take $\Omega(n\log n)$ time to determine $x$. 
\end{proof}


\subsection{The Algorithm}

Next we give an algorithm for the diameter-based $c$ outlier removal
problem.  We do this by first considering a more general problem in
$\mathbb{R}^{n \times n}$ and then use the resulting algorithm to find
a set $\tilde{S}$ of $O(c^2)$ points with the property that any
optimal set $S'$ for $S$ is also an optimal set for $\tilde{S}$. 

Let $A$ denote an $n\times n$ symmetric matrix of non-negative real
numbers such that 
\begin{enumerate}
\item $A_{i,i} = 0$ for all $1\le i\le n$.

\item For all $1\le i<j\le n$, 
     $A_{i,j} = A_{k,\ell}$ if and only if $k=i$ and 
     $\ell=j$ or $k=j$ and $i=\ell$.
\end{enumerate}
Let $A_{i,\star}$, respectively, $A_{\star,i}$ denote the $i$th row,
respectively, column, of $A$.  For a set $I$ of indices we denote by
$A\setminus I$ the submatrix of $A$ obtained by deleting $A_{i,\star}$
and $A_{\star,i}$ for every $i\in I$ from $A$.  We consider the
problem of selecting a set $T$ of $c$ indices, such that the largest
value in $A\setminus T$ is minimum over all choices of $T$.  We begin
by showing that the algorithm \textsc{DeepSet} described below selects
a set $\tilde{T}$ of $(c+1)^2$ indices that are a superset of some
optimal set $T$.

In the following, \emph{marking} an index $i$ means adding $i$ to
$\tilde{T}$ and \emph{deleting} an index $i$ means removing row $i$
and column $i$ from $A$.  In words, Algorithm $\textsc{DeepSet}(A,c)$
finds the maximum entry $A_{i,j}$ of $A$, marks the indices of the
$c+1$ largest entries in $A_{i,\star}$ and $A_{\star,j}$, and finally deletes
$i$ and $j$.  The algorithm repeats this process $c+1$ times.  In
pseudocode, Algorithm $\textsc{DeepSet}(A,c)$ is given 
below:

\noindent
\begin{minipage}{\textwidth}
\noindent$\textsc{DeepSet}(A,c)$
\begin{algorithmic}[1]
\FOR{$g=1$ to $c+1$}
  \STATE{$A_{i,j}\gets$ maximum entry of $A$}
  \STATE{$x\gets$ $(c+1)$-st largest entry in $A_{i,\star}$}
  \STATE{$\tilde{T}\gets 
     \tilde{T} \cup \{ k : A_{i,k} \ge x \}$ 
          \COMMENT{* mark $c+1$ largest entries in row/column $i$ *}}
  \STATE{$x\gets$ $(c+1)$-st largest entry in $A_{j,\star}$}
  \STATE{$\tilde{T}\gets 
     \tilde{T} \cup \{ k : A_{k,j} \ge x \}$
          \COMMENT{* mark $c+1$ largest entries in row/column $j$ *}}
  \STATE{$A\gets A \setminus \{i,j\}$ \COMMENT{* delete $i$ and $j$ *}}
\ENDFOR
\RETURN{$\tilde{T}$}
\end{algorithmic}
\end{minipage}
\vspace{\parskip}

\begin{lem}\lemlabel{diameter}
Let $T$ be a set of $c$ indices such that the largest value in
$A\setminus T$ is minimum over all choices of $T$.  Then
Algorithm $\textsc{DeepSet}(A,c)$ returns a superset
$\tilde{T}\supseteq T$.
\end{lem}

\begin{proof}
To prove the lemma we first impose an order on the elements of
$T=\{t_1,\ldots,t_c\}$, such that the maximum element of $A \setminus
\{t_1,\ldots,t_{i-1}\}$ is in $A_{t_{i},\star}$ (and symmetrically in
$A_{\star,t_{i}}$).  This ordering always exists, otherwise
$T$ is not optimal.  Let $T_i = \{t_1,\ldots,t_i\}$ and let
$\tilde{T}_i$ denote the set of indices contained in $\tilde{T}$ after
the execution of the $i$-th iteration of the algorithm
$\textsc{DeepSet}$.  Let $D_i$ denote the set of $2i$ indices that
have been deleted after the $i$th iteration of the algorithm
\textsc{DeepSet}.  For convenience we use the convention
$T_0=\tilde{T}_0=D_0=\emptyset$.  The following claim is easily
established by induction on $i$:

\begin{clm}\clmlabel{deepset-max}
The maximum value in $A\setminus D_i$ is less than or equal to the
maximum value in $A\setminus T_i$.
\end{clm}

Next we prove, by induction on $i$, that $\tilde{T}_{i}\supseteq T_i$.
The base case, $i=0$, is trivial.  For the inductive step, we show
that $\tilde{T}_i \supseteq T_i$ if $\tilde{T}_{i-1} \supseteq
T_{i-1}$.  Let $A_{k,\ell}$ be the maximum element of $A \setminus
T_{i-1}$.  Recall that, by the ordering we have chosen for $T$, this
implies that $T_i=T_{i-1}\cup\{t_i\}$ where $t_i\in\{k,\ell\}$.  We
will show that both $k$ and $\ell$ are in $\tilde{T}_i$. Three cases
are possible: 

\begin{enumerate}

\item $k \not \in \tilde{T}_{i-1}$ and $\ell \not \in
\tilde{T}_{i-1}$.  Since the marked elements are a superset of the
deleted elements, $A_{k,\ell}$ is an element of $A \setminus D_{i-1}$.
Therefore, by \clmref{deepset-max}, $A_{k,\ell}$ is the largest
element in $A\setminus D_{i-1}$.  Thus, $k$ and $\ell$ are marked (and
deleted) during the $i$th iteration of \textsc{DeepSet} so
$\{k,\ell\}\subseteq\tilde{T}_i$. 

\item $k \in \tilde{T}_{i-1}$ and $\ell \in \tilde{T}_{i-1}$.  Then
$\{k,\ell\}\subseteq \tilde{T}_{i-1}\subseteq \tilde{T}_i$.

\item Without loss of generality $k \in \tilde{T}_{i-1}$ and $\ell \not
\in \tilde{T}_{i-1}$. Two cases are possible.

\begin{enumerate}

\item $k$ was marked and deleted during the first $i-1$ iterations of
algorithm $\textsc{DeepSet}$. Hence, the indices of the $c+1$ largest
entries in $A_{k,\star}$ are in $\tilde{T}_{i-1}$ and none of these
indices is $\ell$.  On the other hand, $T_{i-1}$ contains only $i-1 <
c+1$ indices and none of these is $k$.  Thus, it must be that
$A\setminus T_{i-1}$ contains a value 
$A_{k,\ell'}>A_{k,\ell}$, but this contradicts the ordering of $T$.

\item The index $k$ was marked, but not deleted, during the first
$i-1$ iterations of algorithm $\textsc{DeepSet}$.  Thus, the same
argument used in Case~1 above implies that $\{k,\ell\}\subseteq
\tilde{T}_i$.

\end{enumerate}
\end{enumerate}
This completes the proof of \lemref{diameter}.
\end{proof} 

Carefully inspecting the proof of \lemref{diameter} shows that it
actually implies the following slightly stronger statement (because
$\tilde{T}_{c+1}$ contains the indices of the largest element in
$A\setminus T_c$).

\begin{lem}
Let $\tilde{A}$ be the submatrix of $A$ induced by the row and column
indices in the set $\tilde{T}$ produced by Algorithm \textsc{DeepSet}.
Then the value of the optimal solution for $\tilde{A}$ is equal to the
the value of the optimal solution for $A$.
\end{lem}

We can use the algorithm $\textsc{DeepSet}$ to reduce a problem of
size $n$ to one of size $O(c^2)$.  The set $S$ implicitly defines an
$n\times n$ \emph{distance matrix} $A$ where $A_{i,j}$ is the distance
from the $i$th point in $S$ to the $j$th point in $S$.  Note that $A$
is a symmetric matrix of non-negative real numbers with zero values
along the diagonal.  To ensure that $A$ also has the second property
we perform comparisons between the element of $A$ lexicographically
using the key $(A_{i,j}, i, j)$ for the element $A_{i,j}$.  In this
way we can run algorithm $\textsc{DeepSet}$ on $A$ to obtain a
superset of the indices of points that need to be removed to minimize
the diameter of $S$.

\begin{lem}
There exists an $O(n\log n + cn + c^6\log^2 c)$ time algorithm to
solve the diameter-based $c$ outlier removal problem.
\end{lem}


\begin{proof}
To execute algorithm $\textsc{DeepSet}$ on the matrix $A$ implicitly
defined by $S$, we first preprocess $S$, in $O(n\log n)$ time, using
the deletion-only convex hull structure of Hershberger and Suri
\cite{hs92}, which allows the deletion of a point in $O(\log n)$ time
and makes it possible to find the diameter in $O(n)$ time \cite{s78}.

Denote the two points forming the diameter of $S$ by $p$ and $q$.
After the preprocessing described above, $p$ and $q$ can be found, and
deleted, in $O(n)$ time.  Next, using an $O(n)$ time selection
algorithm we mark the $c+1$ furthest points from $p$ and $q$.
Repeating this $c+1$ times we obtain, in $O(cn)$ time a set
$\tilde{S}$ of $O(c^2)$ marked points such that the optimal solution
$S'$ for $S$ is also the optimal solution for $\tilde{S}$.

Once we have computed $\tilde{S}$ we apply the algorithm of Eppstein
and Erickson \cite{ee94} to find the set $S'$ in $O(c^2 (c^2)^2\log^2
(c^2)) = O(c^6\log^2 c)$ time.  These three steps (preprocessing,
finding $\tilde{S}$ and finding $S'$) take a total time of $O(n\log n
+ cn + c^6 \log^2 c)$, as promised.
\end{proof}

\paragraph{Remark.} The \textsc{DeepSet} algorithm can be extended to
handle slightly more general problems for which the matrix $A$ is not
necessarily symmetric.  The only modification needed for this
extension that the indices of the $c+1$ largest entries in
$A_{i,\star}$ and in $A_{\star,i}$ as well as $A_{j,\star}$ and
$A_{\star,j}$ should be marked.  This modification at most doubles the
size of the resulting set $\tilde{T}$ of marked indices.

\section{Minimizing the Enclosing Rectangle}
\seclabel{minimizing-rectangle}
\seclabel{box}

In this section we propose a simple algorithm for the following
\emph{(bounding box) area/perimeter-based $c$ outlier removal
problem}: given a set $S$ of $n$ points in the plane, find an
axes-parallel closed rectangle $R$ of minimum area/perimeter that has
exactly $c$ points of $S$ in its exterior.  Our algorithm first
computes a set of $O(c)$ candidate points and then uses the algorithm
of Segal and Kedem \cite{sk98} to compute the desired rectangle.  The
main steps of our algorithm are given by the following pseudocode:

\noindent
\begin{minipage}{\textwidth}
$\textsc{FindOptimalRectangle}(S)$
\begin{algorithmic}[1]
\STATE{Find a subset $K\subseteq S$ consisting of 
$c$ leftmost, $c$ rightmost, $c$ topmost and $c$ bottommost points in
$S$.}
\STATE{Compute the smallest axes-parallel bounding box $B$ for points in $S\setminus K$, 
and then delete all these points.}
\STATE{Insert $c$ points at the bottom-left corner of $B$.  Also
insert $c$-points at the top-right corner of $B$.  Let the set of
newly inserted points be $I$.}
\STATE{Compute the minimum area/perimeter axes-parallel rectangle $R$ that 
encloses exactly $c+|K|$ points out of $2c+|K|$ points in the set $K\cup I$
using the algorithm in
\cite{sk98}.}
\end{algorithmic}
\end{minipage}

\begin{lem}\label{bounding-box-obs}\lemlabel{box}
 The bounding box $B$ is in the interior of the rectangle $R$ reported
 by $\textsc{FindOptimalRectangle}$.
\end{lem}
\begin{proof}
The proof is by contradiction. 
Assume that the box $B$ is not completely in
the interior of $R$. Then at least one of the points in the set $I$ is in the
exterior of $R$. Let $p$ be one such point. Imagine the coordinate
system with its origin at $p$.
Notice that  $R$ does not overlap with at least one of the following four
halfspaces: (1) $y\ge 0$ (2) $x\ge 0$ (3) $y\le 0$  (4) $x\le 0$.  
Each of these half spaces contains more than c points (including p).
Hence there are more than $c$ points in the exterior of $R$, a contradiction.
\end{proof}

\begin{thm}
There exists an $O(n+c^3)$ time algorithm to solve the 
(bounding box) area/perimeter-based $c$ outlier removal problem.
\end{thm}

\begin{proof}
Correctness follows from \lemref{box}. As for the complexity
analysis, Steps 1--3 take $O(n)$ time. Since $|K|\le 4c$, Step 4
requires $O(c^3)$ time \cite{sk98}. Hence the overall
time complexity of the algorithm is $O(n+c^3)$.
\end{proof}

\section{Minimizing the Convex Hull}
\seclabel{hull}

In this section we consider the following \emph{(convex hull)
area/perimeter-based $c$ outlier removal problems}:  Given a set $S$
of $n$ points, find a subset $S'\subseteq S$, $|S'|=c$ such that the
area/perimeter of the convex hull of $S\setminus S'$ is minimum over
all choices of $S'$.  Throughout this section, we use $\ch(X)$ to
denote the convex hull of the point set $X$. We start by giving an
$\Omega(n\log n)$ lower bound, even for the case when $c=1$.


\subsection{The Lower Bound}


\begin{thm}
In the algebraic decision tree model of computation, the (convex hull)
area/perimeter-based 1 outlier removal problem has an 
$\Omega(n\log n)$ lower bound.
\end{thm}

\begin{proof}
The proof is by a reduction from the problem \textsc{Set-Equality}, of
determining whether two sets $A$ and $B$ of real numbers are equal,
which has an $\Omega(n\log n)$ lower bound in the algebraic decision
tree model.  The \textsc{Set-Equality} problem can be mapped to an
outlier removal problem on the point multiset $S=S_A \uplus S_B$ where
$S_A=\{(x,x^2): x\in A\}$, $S_B=\{(x,x^2):x\in B\}$ and $\uplus$
denotes multiset union. The sets $A$ and $B$ are equal if and only if
for every $p\in S$, $\ch(S)=\ch(S\setminus\{p\})$. 
\end{proof}

\subsection{The Algorithm}
\seclabel{algorithm}

In this subsection we present an algorithm to solve the (convex hull)
area/perimeter-based $c$ outlier removal problem.  Throughout this
subsection we will simply discuss the area-based problem.  The bulk of
the computational work in the algorithm is done by a dynamic
programming subroutine that handles area or perimeter equally well.
We start with some geometric preliminaries.

\subsubsection{Preliminaries} 
\seclabel{preliminaries}

The \emph{convex layers} $S_0,\ldots,S_k$ of $S$ are defined as
follows: $S_0$ is the subset of $S$ on the boundary of $\ch(S)$.
$S_i$, for $i\ge 1$ is the subset of $S$ on the boundary of
$\ch(S\setminus\bigcup_{j=0}^{i-1} S_j)$.  The convex layers of $S$
can be computed in $O(n\log n)$ time \cite{c85,hs92} or, more simply,
the first $c$ convex layers can be computed in $O(cn\log n)$ time by
repeated applications of any $O(n\log n)$ time convex hull algorithm.
For the remainder of this paper we will use the notation $p_{i,j}$ to
denote the $(j\bmod |S_i|)$th point of $S_i$, and use the convention
that $p_{i,0},\ldots,p_{i,|S_i|-1}$ occur in counterclockwise order on
the boundary of $\ch(S_i)$.

Once the first $c+1$ convex layers $S_0,\ldots,S_c$ have been
computed, we can find, in $O(c^2 n)$ time, for each point $p_{i,j}$ on
layer $i$ and for each layer $i'> i$ and $i'\le c$ the two points
$p_{i',k}$ and $p_{i',\ell}$ such that the line through $p_{i,j}$ and
$p_{i',k}$ (respectively $p_{i,j}$ and $p_{i',\ell}$) is tangent to
$S_{i'}$.  This is accomplished by a simple walk around $S_i$,
updating tangents $p_{i',k}$ and $p_{i',\ell}$ as we proceed.

Consider a point $p_{0,j}\in S_0$ and refer to \figref{point-removal}.
If we remove $p_{0,j}$ from $S$ then a (possibly empty) sequence
$p_{1,k},\ldots,p_{1,\ell}$ of $S_1$ appears on the boundary of
$\ch(S\setminus\{p_{0,j}\})$.  When this happens we say that
$p_{1,k},\ldots,p_{1,\ell}$ is \emph{exposed}.  This exposed sequence
can be obtained from the preprocessing described above by using two
tangents $p_{1,k}$ and $p_{1,\ell}$ joining $p_{0,j-1}$ and
$p_{0,j+1}$ to $S_1$.  Finding the two tangent points takes $O(1)$
time and traversing the sequence takes $O(t_j)$ time, where
$t_j=\ell-k+1$.

\begin{figure}
\begin{center}\includegraphics{point-removal}\end{center}
\caption{Removing a point $p_{0,j}$ from $S_0$ exposes a chain
$p_{1,\ell},\ldots,p_{1,k}$ of $S_1$.}
\figlabel{point-removal}
\end{figure}

Once we have removed a point $p_{0,j}$ from $S_0$, if we know the area
(or perimeter) of $\ch(S)$ we can compute the area (or perimeter) of
$\ch(S\setminus\{p_{0,j}\})$ in $O(t_j)$ time.  We do this by
computing the area of the triangle $\triangle
p_{0,j-1}p_{0,j}p_{0,j+1}$ and subtracting from it the area of
$\ch(\{p_{0,j-1},p_{0,j+1}\}\cup\{p_{1,k},\ldots,p_{1,\ell}\})$.  This
gives us the difference in area (perimeter) between $\ch(S)$ and
$\ch(S\setminus\{p_{0,j}\})$.

In this section we present our algorithm for solving the
perimeter-based and area-based outlier removal problems. Our solution
to both problems is to enumerate all the combinatorial types of
solutions of size $c$.  For each such solution type, we then use a
combination of divide-and-conquer and dynamic programming to find the
optimal solution of that particular solution type.  Before presenting
the general algorithm, it will be helpful to discuss the special cases
$c=1$ and $c=2$ to illustrate the principles involved.

\subsubsection{Removing 1 Outlier}

The case $c=1$ asks us to remove 1 point of $S$ so that the convex
hull of the resulting set has minimum area.  This can be solved as
follows: We first compute the two convex layers $S_0$ and $S_1$ in
$O(n\log n)$ time and preprocess them for the tangent queries
described in the previous section.  We then determine, for each point
$p_{0,j}\in S_0$ the difference in area between $\ch(S)$ and
$\ch(S\setminus\{p_{0,j}\})$ using the method described in the
previous section.  This process takes $O(1+t_j)$ time, where $t_j$ is
the number of vertices of $S_1$ exposed by the removal of $p_{0,j}$.
We output the point $p_{0,j}$ that gives the largest difference in
area.

To analyze the overall running time of this algorithm we observe that
any particular point $p_{1,k}\in S_1$ appears in at most two triangles
$\triangle p_{0,j-1},p_{0,j},p_{0,j+1}$ and
$\triangle p_{0,j},p_{0,j+1},p_{0,j+2}$.  Stated another way,
\[
     \sum_{j=0}^{|S_0|-1} t_j \le 2|S_1|\le 2n \enspace .
\]
Thus, the overall running time of this algorithm is
\[
     T(n) = O(n\log n)+\sum_{j=0}^{|S_0|-1} O(1+t_j) = O(n\log n) \enspace ,
\]
as claimed.

\subsubsection{Removing 2 Outliers}

Next we consider the case $c=2$.  In this case, the optimal solution
$S'$ has one of three following forms:

\begin{enumerate}

\item $S'$ contains two consecutive points $p_{0,j}$ and $p_{0,j+1}$
of $S_0$.

\item $S'$ contains two non-consecutive points $p_{0,j_1}$ and
$p_{0,j_2}$ of $S_0$ (with $j_2\not\in\{j_1-1,j,j_1+1\}$).

\item $S'$ contains one point $p_{0,j}$ of $S_0$ and one point
$p_{1,j'}$ of $S_1$.

\end{enumerate}

The solutions of Type~1 can be found in much the same way as the
algorithm for the case $c=1$.  For each $j\in\{0,\ldots,|S_0|-1\}$ we
compute the difference in area between $\ch(S)$ and
$\ch(S\setminus\{p_{0,j},p_{0,j+1}\})$.  The analysis remains exactly
the same as before except that, now, each point of $S_1$ can appear in
at most $3$ area computations, instead of only 2.  Thus, all solutions
of Type~1 can be evaluated in $O(n\log n)$ time.

The solutions of Type~3 can also be found in a similar manner.  For
each point $p_{0,j}\in S_0$ we remove $p_{0,j}$ to expose a sequence
$p_{1,k},\ldots,p_{1,\ell}$ of $S_1$ and compute the area of
$\ch(S\setminus\{p_{0,j}\})$.  We then remove each of
$p_{1,k},\ldots,p_{1,\ell}$ in turn (exposing a chain of points from
$S_2$) and compute the area of the resulting convex hull.  To analyze
the cost of all these, we observe that each point $p_{1,j}\in S_1$
appears in at most 2 subproblems because there are at most 2 points in
$S_0$ whose removal causes $p_{1,j}$ to appear on the convex hull.
Similarly, for each point $p_{2,j}\in S_2$ there are at most 2 points
of $S_1$ whose removal causes $p_{2,j}$ to appear on the convex hull.
Thus, each point in $S_1$ appears in at most 2 subproblems and each
point in $S_2$ appears in at most $4$ area computations.  The overall
running time of this algorithm is therefore bounded by
\[
    O\left(n\log n + |S_0| + 2|S_1| + 4|S_2|\right) = O(n\log n) \enspace ,
\]
as required.

Finally, we consider solutions of Type~2.  To find these we compute,
for each $p_{0,j}\in S_0$ the difference $x_j$ between the area of
$\ch(S\setminus\{p_{0,j}\})$ and $\ch(S)$ using the technique
described for the case $c=1$.  In this way, we reduce the problem to
that of finding two indices $0\le j_1,j_2< |S_0|$ with $j_2\ge j_1+2$
such that $x_{j_1}+x_{j_2}$ is maximum.  This can be accomplished by
computing the quantity
\[
     D_j = \max\{x_{j_1}+x_{j_2} :
       \mbox{$0\le j_1,j_2\le j$ and $j_2 \ge j_1+2$}\} \enspace ,
\]
that can be computed in $O(|S_0|)$ time using the dynamic-programming 
recurrence
\[
    D_j = \max\{D_{j-1}, x_{j} + \max\{x_{0},\ldots,x_{j-2}\}\}
                \enspace .
\]

Since the best solution of each of the three types can be found in
$O(n\log n)$ time we can find the overall best solution in $O(n\log
n)$ time by keeping the best of the three.

\subsubsection{Removing $\mathbf{c}$ Outliers}

The solution for the case $c=2$ illustrates all of the ideas used in 
our algorithm.  We begin by enumerating the combinatorial types of
solutions and then compute the best solution of each type.  The
algorithm for computing the best solution of each type is a
divide-and-conquer algorithm whose merge step is accomplished by
solving a dynamic programming problem (as in the Type~2 solutions
described above).

For ease of exposition (to avoid treating $S_0$ as a special case), we
describe an algorithm to find the optimal solution with the
restriction that it does not include both $p_{0,-1}$ and $p_{0,0}$.
To find the true optimal solution we can run this algorithm at most
$c$ times, shifting the numerical labelling of the points on $S_0$ by
one each time.

\subsubsection{The Types of Solutions}

We represent the type of a solution as a rooted ordered binary tree in
which each node is labeled with a positive integer and the sum of all
node labels is $c$.  We call such trees \emph{solution trees}.  The
following lemma tells us that, for small values of $c$, there are not
too many solution trees:
 
\begin{lem}\lemlabel{catalan}
The number of solution trees is at most $O(C(2c))$, where
$C(r)={2r\choose r}/(r+1)$ is the $r$th Catalan number.
\end{lem}

\begin{proof} Given a solution tree $T$, we convert it to an
unlabelled rooted binary tree as follows: First, for each node $N$ of
$T$ whose label is $\ell$, we color $N$ black, leave $N$'s left child
unchanged and replace $N$'s right child with a (right) path of
$\ell-1$ \emph{white} nodes, the last node of which has $N$'s original
right child as its right child.  Note that this gives us a binary
tree with exactly $c$ nodes in which no white node has a left child.
Next, for each black node we add a leaf, if necessary, to guarantee
that each black node has a left child.  This gives us an unlabelled
rooted ordered binary tree $T'$ with at most $2c$ nodes.

Observe that, given only $T'$, we can recover $T$ and its labels since
we can recognize white nodes by the fact that they have no left child.
Thus, the number of solution trees is at most equal to the number of
unlabelled rooted ordered binary trees with at most $2c$ nodes.  The
number of such trees is 
\[
  \sum_{i=1}^{2c} C(i) = O(C(2c))
\]
\cite{knuth-graham-patashnik},
as required.
\end{proof}

Solution trees are interpreted as follows (refer to
\figref{solution-tree} for an example): Any solution removes some
elements of $S_0$ and the elements removed come in $d$ groups
$G_0^1,\ldots,G_0^d$ of consecutive elements with each group separated
by at least one element of $S_0$.  The sizes of these groups are given
by the labels of the nodes on the rightmost path in $T$, in the order
in which they occur.  That is, the $j$th node, $N_0^j$ on the
rightmost path of $T$ has the label $|G_0^j|$. 

\begin{figure}
\begin{center}
\begin{tabular}{ccc}
\includegraphics{soltree-a} & 
\includegraphics{soltree-b} &
\includegraphics{soltree-c} \\
(a) & (b) & (c)
\end{tabular}
\end{center}
\caption{Examples of (a)~a point set $S$, (b)~a solution
$S\setminus\{S'\}$, and (c)~the solution tree for $S'$.}
\figlabel{solution-tree}
\end{figure}

For some group $G_0^j$, let $p_{1,k}, \ldots, p_{1,\ell}$ denote the
points of $S_1$ that appear on the boundary of $\ch(S\setminus
G_0^j)$.  Any solution removes some subset $p_{1,k},\ldots,
p_{1,\ell}$ of elements from $S_1$.  Again, this subset can be
partitioned into groups of consecutive elements with any two groups
separated by at least one element of $S_1$.  In the solution tree $T$,
the sizes of these groups are given, in the order in which they occur,
by the labels of the rightmost path in the subtree of $T$ rooted at
the left child of $N_0^j$.

This process is repeated recursively: Let
$S_{<i}=\bigcup_{j=0}^{i-1}S_i$ and let $S_{<i}'=S_{<i}\cap S'$.  For
each consecutive group $G_i^j$ of nodes that are removed from $S_i$,
let $p_{i+1,k}, \ldots, p_{i+1,\ell}$ denote the vertices on $S_{i+1}$
that appear on the boundary of $CH(S \setminus (S_{<i}'\cup G_i^j))$.
In the solution tree $T$, the rightmost path of the left subtree of
the node representing $G_i^j$ contains nodes representing the sizes of
consecutive groups of nodes that are removed from the chain
$p_{i+1,k}, \ldots, p_{i+1,l}$ of $S_{i+1}$.  In this way, any
solution $S'$ to the outlier removal problem that does not remove both
$p_{0,0}$ and $p_{0,-1}$ maps to a unique solution tree.

\comment{Note that the mapping between different types of solutions
and labeled binary search trees is not bijective, because for one type
of solutions, there are many labeled binary search trees that
represent that solution. The reason is that the ordering along the
rightmost path of the tree (and recursively, the orderings along the
rightmost paths of all subtrees) is not uniquely defined.  }


\subsubsection{Computing the Solution of a Specific Type}

In this section we describe an algorithm that takes as input a
solution tree $T$ and outputs the value of the optimal solution $S'$
whose solution tree is $T$.

The algorithm we describe is recursive and operates on a subchain
$p_{i,j},\ldots,p_{i,k}$ of $S_i$ along with a solution (sub)tree $T$.  The
algorithm requires that some subset of $\bigcup_{j=0}^{i-1}S_i$ has
already been removed from $S$ so that $p_{i,j},\ldots,p_{i,k}$ are on
the boundary of the convex hull of the current point set.  The
algorithm finds an optimal solution of type $T$ such that the only
points removed from the convex hull of the current point set are in
$p_{i,j},\ldots,p_{i,k}$.

Let $d$ denote the number of nodes on the rightmost path of $T$.  The
algorithm accomplishes its task by recursively solving $O(d(k-j+1))$
subproblems on the left children of these $d$ nodes and then combining
these solutions using dynamic programming.  The following pseudocode
gives a detailed description of the algorithm's operation with the
exception of the dynamic programming component, whose description and
analysis is discussed in the next subsection.  Note that the algorithm
below only computes the maximum amount of area (perimeter) that can be
removed from $\ch(S)$ by a solution $S'$ whose solution tree is $T$.  To
obtain the points in $S'$ the algorithm can be augmented using
the standard trick of remembering, whenever the algorithm takes the
maximum of two values, which of the two values produced the maximum.
The details of this are standard and omitted here.

\noindent\begin{minipage}{5.5in}
$\textsc{FindOptimalOfType}(T,i,j,k)$
\begin{algorithmic}[1]
\IF{$T$ is empty}
  \RETURN{0}
\ENDIF
\STATE{$d\gets$ the number of nodes on the rightmost path of $T$}
\FOR{$g=1$ to $d$}
  \STATE{$N_g\gets g$th node on the rightmost path of $T$}
  \STATE{$c_g=\lbl(N_g)$}
  \FOR{$\ell=j$ to $k-c_g+1$}
    \STATE{delete $S_{i,\ell},\ldots,S_{i,\ell+c_g-1}$ from $S_{i}$
           exposing $S_{i+1,j'},\ldots,S_{i+1,k'}$ on $S_{i+1}$}
    \STATE{$s\gets$ reduction in area (perimeter) obtained by the deletion of
           $S_{i,\ell},\ldots,S_{i,\ell+c_g-1}$} 
    \STATE{$X_{g,\ell-j+1}\gets
            s+\textsc{FindOptimalOfType}(\lft(N_g),i+1,j',k')$}
    \STATE{reinsert $S_{i,\ell},\ldots,S_{i,\ell+c_d-1}$ into $S_{i}$}
  \ENDFOR
\ENDFOR
\RETURN{$\textsc{CombineSolutions}(X,d,k-j+1,c_1,\ldots,c_d)$}
\end{algorithmic}
\end{minipage}

The call to $\textsc{CombineSolutions}$ in the last line of the
algorithm is a dynamic programming subroutine described in the next
section that runs in $O(d(k-g))$ time.  The \textsc{CombineSolutions}
subroutine computes the optimal locations of the groups of points
represented by $N_1,\ldots,N_d$ in $T$.  At the topmost level, the
algorithm is called as $\textsc{FindOptimalOfType}(T,0,0,|S_0|-1)$.

To analyze the cost of \textsc{FindOptimalOfType} it suffices to
determine, for each point $p_{i,j}$, the maximum number of times
$p_{i,j}$ is deleted (in line 8) by the algorithm.  All other work
done by the algorithm can be bounded in terms of this quantity.  For
points $p_{0,j}\in S_0$, each point is deleted exactly $g_0$, times,
where $g_0$ is the sum of labels of nodes on the rightmost path of
$T$. 

More generally, let $g_i$ denote the sum of labels of all nodes $N$ of
$T$ for which the path from the root of $T$ to $N$ make exactly $i$
left turns. (These nodes correspond to groups that are deleted from
$S_i$).  Consider some point $p_{i,j}\in S_i$, for $i\ge 1$.  By
Carath\'eodory's Theorem \cite{eckhoff93}, each such point is contained
in some triangle $\Delta_{i,j}=\triangle
p_{i-1,\ell_1},p_{i-1,\ell_2},p_{i-1,\ell_3}$. If $p_{i,j}$ is deleted
by \textsc{FindOptimalOfType} then it is on the boundary of the convex
hull of the current point set.  However, this implies that at least
one of the three vertices of $\Delta_{i,j}$ must be deleted from the
current point set.  Thus, if we define $m_i$ as the maximum number of
times a point of $S_i$ is deleted by \textsc{FindOptimalOfType} then
we have the relationships:
\[ 
    m_i \le \left\{\begin{array}{ll}
            g_0 & \mbox{if $i=0$} \\
            3 m_{i-1} g_i & \mbox{if $1\le i< c$} \\
            0 & \mbox{otherwise}      
        \end{array}\right.
\] 
Using the fact that $g_i \le c$, we obtain the (extremely loose) upper
bound $m_i \le (3c)^{i+1}$.  
This implies that the points of $S_c$
(which are never deleted) appear in at most $3m_{c-1}$ subproblems.
Putting all this together we obtain:

\begin{lem}\lemlabel{recursion}
The algorithm \textsc{FindOptimalOfType} finds the optimal solution
whose solution tree is $T$ in $O((3c)^c n)$ time.
\end{lem}

\subsubsection{Combining the Solutions}

One aspect of the algorithm that we have not yet described is how the
subroutine \textsc{CombineSolutions} works.  This subroutine is given
positive integers $c_1,\ldots,c_d$ and a $d\times m$ positive
real-valued matrix $X$ and must find 
indices $1\le i_1,\ldots,i_d \le m-c_d$ such that
\[
     i_{j+1} \ge i_j + c_j + 1
\]
for all $1\le j < d$ and such that the sum
\[
      h(i_1,\ldots,i_d)=\sum_{j=1}^d X_{j,i_j}
\]
is maximum.  In the terminology of the previous section, the value $d$
is the number of nodes in the rightmost path of $T$, $m=k-j+1$, and
the indices
$i_1,\ldots,i_d$ correspond to the indices of the
first element of each group on the chain $p_{i,j},\ldots,p_{i,k}$
considered by the algorithm.
We solve this problem by filling out the $d\times m$ dynamic
programming table:
\[
     D_{j,\ell} = \max\{h(i_1,\ldots,i_j):
      \mbox{$1\le i_1,\ldots,i_j\le \ell$, and $i_{j'+1} \ge i_{j'}+c_{j'}+1$
             for all $1\le j'< j$}  \} 
\]
for $j=1,\ldots,d$ and $\ell=1,\ldots,m-c_j+1$.  We can do this in
$O(dm)$ time because the table entries satisfy the recurrence
\[
     D_{j,\ell} = \max\{D_{j,\ell-1},D_{j-1,\ell-c_{j-1}-1}+X_{j,\ell} \}
\]
where we use the convention that $D_{j,\ell} = 0$ if $j=0$ and
$D_{j,\ell}=-\infty$ if $\ell<0$.  This yields the last lemma required
by the algorithm:

\begin{lem}\lemlabel{combine}
The function \textsc{CombineSolutions} can be implemented in
$O(dm)$ time.
\end{lem}

This (finally) completes the proof of:
\begin{thm}
There exists an 
$\Oruntime$ time
algorithm to solve
the (convex hull) area/perimeter-based $c$ outlier removal problem.
\end{thm}

\section{Conclusions}
\seclabel{conclusions}

We have given algorithms for removing $c$ outliers to optimize various
criteria. For any constant value of $c$, all our algorithms run in
$O(n\log n)$ time.  It is interesting to note that our simplest and
fastest algorithms, running in $O(n)$ time, are for methods based on
bounding boxes, which are not invariant to rotations of the input.  At
the next level is the diameter-based method, which is invariant to
rotations of the input, but not invariant to non-uniform scaling.  The
most complicated of our algorithms is the algorithm based on convex
hull area, whose results are invariant to any affine transformations
of the input.

We conclude with a few directions for further research:

\begin{enumerate}

\item Our algorithm for minimizing the diameter of $S\setminus S'$
extends readily to point sets $S$ in $\mathbb{R}^3$.  Using an
$O(n\log n)$ diameter-finding algorithm \cite{cs88,r01} and the
fastest algorithms for \textsc{Vertex-Cover} \cite{ckj01} we obtain an
algorithm with running time $O(cn\log n + c^4 1.27^{(c^2)})$.  Is
there an algorithm whose running time depends only polynomially on
$c$?

\item The running time of our algorithm for minimizing the
area/perimeter of the convex hull has a superpolynomial dependence on
the value of $c$. Does there exist an algorithm that is polynomial in
$c$ but that still runs in $O(n\log n)$ time for any fixed value of
$c$?

\end{enumerate}

\bibliographystyle{plain}
\bibliography{outliers}

\end{document}
